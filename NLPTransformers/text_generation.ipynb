{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f6ced2-12ae-4117-8f09-78842c060119",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "Converting the model's probabilistic output to text requires a *decoding method*, which introduces a few challenges that are unique to text generation:\n",
    "\n",
    "- The decoding is done *iteratively* and thus involves significanlty more compute thatn simpy passing inputs once through the forwarf pass of a model.\n",
    "- The *quality* and *diversity* of the generated text depend on the choice of decoding method and associated hyprparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bed7cf-df57-4e22-8bb6-c706d82b5d9a",
   "metadata": {},
   "source": [
    "## Greedy Search Decoding\n",
    "\n",
    "The simplest decoding method to get discrete tokens from a model's continuous output is to greedily select the token with the highest probability at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46648f8-56f5-4c65-894d-1e290ce4d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Load 1.5B-parameter version of GPT2 with a language model head:\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ef8b9-1d92-447e-b35f-ea7ffa77ba6c",
   "metadata": {},
   "source": [
    "Let's generate text!\n",
    "At each timestep, we pick out the model's logits for the las token in the prompt and wrap them with a softmax to get the probability distribution.\n",
    "Then, pick the next token with the highest prob, add it to the input sequence, and run the process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca4abd4-d5a7-43b0-82c6-9c67ffb6e5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (8.53%)</td>\n",
       "      <td>only (4.96%)</td>\n",
       "      <td>best (4.65%)</td>\n",
       "      <td>Transformers (4.37%)</td>\n",
       "      <td>ultimate (2.16%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>popular (16.78%)</td>\n",
       "      <td>powerful (5.37%)</td>\n",
       "      <td>common (4.96%)</td>\n",
       "      <td>famous (3.72%)</td>\n",
       "      <td>successful (3.20%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most popular</td>\n",
       "      <td>toy (10.63%)</td>\n",
       "      <td>toys (7.23%)</td>\n",
       "      <td>Transformers (6.60%)</td>\n",
       "      <td>of (5.46%)</td>\n",
       "      <td>and (3.76%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most popular toy</td>\n",
       "      <td>line (34.38%)</td>\n",
       "      <td>in (18.20%)</td>\n",
       "      <td>of (11.71%)</td>\n",
       "      <td>brand (6.10%)</td>\n",
       "      <td>line (2.69%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most popular toy line</td>\n",
       "      <td>in (46.28%)</td>\n",
       "      <td>of (15.09%)</td>\n",
       "      <td>, (4.94%)</td>\n",
       "      <td>on (4.40%)</td>\n",
       "      <td>ever (2.72%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most popular toy line in</td>\n",
       "      <td>the (65.99%)</td>\n",
       "      <td>history (12.42%)</td>\n",
       "      <td>America (6.91%)</td>\n",
       "      <td>Japan (2.44%)</td>\n",
       "      <td>North (1.40%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most popular toy line in the</td>\n",
       "      <td>world (69.26%)</td>\n",
       "      <td>United (4.55%)</td>\n",
       "      <td>history (4.29%)</td>\n",
       "      <td>US (4.23%)</td>\n",
       "      <td>U (2.30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most popular toy line in ...</td>\n",
       "      <td>, (39.73%)</td>\n",
       "      <td>. (30.64%)</td>\n",
       "      <td>and (9.87%)</td>\n",
       "      <td>with (2.32%)</td>\n",
       "      <td>today (1.74%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input           Choice 1  \\\n",
       "0                               Transformers are the       most (8.53%)   \n",
       "1                          Transformers are the most   popular (16.78%)   \n",
       "2                  Transformers are the most popular       toy (10.63%)   \n",
       "3              Transformers are the most popular toy      line (34.38%)   \n",
       "4         Transformers are the most popular toy line        in (46.28%)   \n",
       "5      Transformers are the most popular toy line in       the (65.99%)   \n",
       "6  Transformers are the most popular toy line in the     world (69.26%)   \n",
       "7  Transformers are the most popular toy line in ...         , (39.73%)   \n",
       "\n",
       "            Choice 2               Choice 3               Choice 4  \\\n",
       "0       only (4.96%)           best (4.65%)   Transformers (4.37%)   \n",
       "1   powerful (5.37%)         common (4.96%)         famous (3.72%)   \n",
       "2       toys (7.23%)   Transformers (6.60%)             of (5.46%)   \n",
       "3        in (18.20%)            of (11.71%)          brand (6.10%)   \n",
       "4        of (15.09%)              , (4.94%)             on (4.40%)   \n",
       "5   history (12.42%)        America (6.91%)          Japan (2.44%)   \n",
       "6     United (4.55%)        history (4.29%)             US (4.23%)   \n",
       "7         . (30.64%)            and (9.87%)           with (2.32%)   \n",
       "\n",
       "              Choice 5  \n",
       "0     ultimate (2.16%)  \n",
       "1   successful (3.20%)  \n",
       "2          and (3.76%)  \n",
       "3         line (2.69%)  \n",
       "4         ever (2.72%)  \n",
       "5        North (1.40%)  \n",
       "6            U (2.30%)  \n",
       "7        today (1.74%)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = \"Transformers are the\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        # Select logits of the first batch and the last token and apply softmax\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        # Store tokens with highest probabilites\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "\n",
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b337e-7a9b-40c3-b7ac-be51e98c18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the bulit-in generate()\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
