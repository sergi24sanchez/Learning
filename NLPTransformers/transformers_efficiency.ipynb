{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afffb5b1-366a-4a69-853e-0d52501863bd",
   "metadata": {},
   "source": [
    "# Chapter 8. Making Transformers Efficient in Production\n",
    "\n",
    "## Intent Detection as a Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d860dd-724f-4856-a08f-66d0079133ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdf5c6f-e622-445d-bb61-e69b1aff7539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.5490034222602844}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f76f9a-3b5e-4260-a8eb-9d8dfdfcbdf9",
   "metadata": {},
   "source": [
    "## Creating a Performance Benchmark\n",
    "\n",
    "*Model performance*\n",
    "How well does our model perform on a well-crafted test set that reflects production data?\n",
    "\n",
    "*Latency*\n",
    "How fast can our model deliver predictions?\n",
    "\n",
    "*Memory*\n",
    "Billion-parameter models. Especially important role in mobile or edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff36494f-0c27-40d9-a998-5584f776f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    def __init__(self, pipeline, dataset, optim_type=\"BERT-baseline\"):\n",
    "        self.pipeline = pipeline\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "\n",
    "    def compute_accuracy(self):\n",
    "        pass\n",
    "\n",
    "    def compute_size(self):\n",
    "        pass\n",
    "\n",
    "    def time_pipeline(self):\n",
    "        pass\n",
    "\n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type].update(self.time_pipeline())\n",
    "        metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2733c49b-a4b2-4f09-94ff-49009cc29ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b7b5db-0f9d-435b-96bd-237cbcfb1a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = clinc[\"test\"][42]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcdf5e0-3726-45b3-9bca-5f15dad451fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transfer'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc[\"test\"].features[\"intent\"]\n",
    "intents.int2str(sample[\"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ba3a38-b2b0-4d76-897e-e29547090d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy_score = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b3d505-3931-44ce-b5b0-e4902a68ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(self):\n",
    "    \"\"\"This overrides the PerformanceBenchmark.compute_accuracy() method\"\"\"\n",
    "    preds, labels = [], []\n",
    "    for example in self.dataset:\n",
    "        pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
    "        label = example[\"intent\"]\n",
    "        preds.append(intents.str2int(pred))\n",
    "        labels.append(label)\n",
    "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
    "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "    return accuracy\n",
    "\n",
    "PerformanceBenchmark.compute_accuracy = compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3ec836-1854-43b1-b37a-2a9beeac399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_size(self):\n",
    "    state_dict = self.pipeline.model.state_dict()\n",
    "    tmp_path = Path(\"model.pt\")\n",
    "    torch.save(state_dict, tmp_path)\n",
    "    # Calculate the size in megabytes\n",
    "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "    # Delete temporary file\n",
    "    tmp_path.unlink()\n",
    "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "    return {\"size_mb\": size_mb}\n",
    "\n",
    "PerformanceBenchmark.compute_size = compute_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3932649b-ebd3-4ef2-adc3-d6dd9c36fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency (ms) - 9.202\n",
      "Latency (ms) - 5.387\n",
      "Latency (ms) - 5.005\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "for _ in range(3):\n",
    "    start_time = perf_counter()\n",
    "    _ = pipe(query)\n",
    "    latency = perf_counter() - start_time\n",
    "    print(f\"Latency (ms) - {1000 * latency:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6a4fd8-3165-40c8-a26e-d503f56faef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
    "    latencies = []\n",
    "    for _ in range(10):\n",
    "        _ = self.pipeline(query)\n",
    "    # Timed run\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ = self.pipeline(query)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "PerformanceBenchmark.time_pipeline = time_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25b39389-2dc6-4dd0-98d9-57ba3402cba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 418.15\n",
      "Average latency (ms) - 5.18 +\\- 0.63\n",
      "Accuracy on test set - 0.867\n"
     ]
    }
   ],
   "source": [
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"])\n",
    "perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403bb62-e748-461a-89c9-da5329b91f15",
   "metadata": {},
   "source": [
    "## Making Models Smaller via Knowledge Distillation\n",
    "\n",
    "training a smaller *student* model to mimic the behavior of a slower, larger, but better-performing *teacher*.\n",
    "\n",
    "### Knowledge Distillation for Fine-tuning\n",
    "\n",
    "For supervised tasks like fine-tuning, the main idea is to augment the ground truth labels with a distribution of \"soft probabilities\" from the teacher which provide complementary information for the sudient to learn from.\n",
    "\n",
    "### Knowledge Distillation for Pretraining\n",
    "\n",
    "general-purpose student that can be subsequently fine-tuned on downstream tasks. The teacher is a pretrained language model ehich transfers its knowledge about masked language modleing to the student."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef88d42-8355-4212-8157-402ad27ad28b",
   "metadata": {},
   "source": [
    "Let's see how we can use knowledge distillation to fine-tune a smaller and faster model. To do that we'll need a way to augment the corss-entropy loss with a Lkd term. Fortunately we can do this by **creating our own trainer**!\n",
    "\n",
    "### Creating a Knowledge Distillation Trainer\n",
    "\n",
    "We need to add a few things to the Trainer base class:\n",
    "- The new hyperparameters alpha and T, which control the relative weight of the distillation loss and how much the probability distribution of the labels should be smoothed\n",
    "- The fine-tuned teacher model, which in our casi is BERT-base\n",
    "- A new loss function that combines the cross-entropy loss with the knowledge distillation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe55233-e035-45ad-a7f3-c1b27f378818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Adding the new hyperparameters. include them as attrbutes\n",
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c74f0696-e810-4fef-a7d1-5ebc4c11a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "# new loss function for the trainer itself. overriding compute_loss()\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs): # teacher model that has already been fine-tuned on our task\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs): # had to add **kwargs\n",
    "        outputs_stu = model(**inputs)\n",
    "        # Extract corss-entropy loss and logits from student\n",
    "        loss_ce = outputs_stu.loss\n",
    "        logits_stu = outputs_stu.logits\n",
    "        # Extract logits from teacher\n",
    "        with torch.no_grad():\n",
    "            outputs_tea = self.teacher_model(**inputs)\n",
    "            logits_tea = outputs_tea.logits\n",
    "        # Soften probabilities and compute distillation loss\n",
    "        loss_fct = nn.KLDivLoss(reduction=\"batchmean\") # we average the losses over the batch dimension\n",
    "        loss_kd = self.args.temperature ** 2 * loss_fct(\n",
    "            F.log_softmax(logits_stu / self.args.temperature, dim=-1), # expects the inputs in the form of log probabilities\n",
    "            F.softmax(logits_tea / self.args.temperature, dim=-1) # and the labels as normal probabilities\n",
    "        )\n",
    "        # Return weighted student loss\n",
    "        loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
    "        return (loss, outputs_stu) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda81ba7-a1cc-4f89-a5d7-0f8726b5cf0f",
   "metadata": {},
   "source": [
    "### Choosing a Good Student Initialization\n",
    "\n",
    "Which pretrained languange model should we pick for the student? In general we should pick a smaller model for the student to reduce the latency and memory footprint.\n",
    "\n",
    "A good rule of thumb from the literature is that knowledge distillation works best when the teacher and student are of the same *model type*. Different model types can have different output embedding spaces, which hinders the ability of the sudent to mimic the teacher.\n",
    "\n",
    "In our case the teacher is BERT, so DistilBERT is a natural candidate to initialize the student with since it has 40% fewer parameters and has been shown to acheve strong results on downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d2434e3-ef73-4478-a7f2-2f1e8243a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34944e2050b44788fe69d5b1119d328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenize and encode our queries. Instantiate DistilBERT and create a simple tokenize_text() function ot take care of the preprocessing\n",
    "student_ckpt = \"distilbert-base-uncased\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)\n",
    "\n",
    "def tokenize_text(batch):\n",
    "    return student_tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"]) # we no longer need text column\n",
    "clinc_enc = clinc_enc.rename_column(\"intent\", \"labels\") # so it can be automatically detected by the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e6dacd-f4f1-4544-83c1-b96f819971b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f6dfc199a74ad6a508b4a876ae0646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02db83dd-49da-457e-be60-9cc14dbefe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compute_metrics() for our DistillationTrainer\n",
    "def compute_metrics(pred):\n",
    "    preds, labels = pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return accuracy_score.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f79cccd6-f609-41a5-a52b-be2d4c7ed2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Define training argumemnts\n",
    "batch_size = 48\n",
    "\n",
    "finetuned_ckpt = \"distilbert-base-uncased-finetuned-clinc\"\n",
    "student_training_args = DistillationTrainingArguments(\n",
    "    output_dir=finetuned_ckpt, evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5, learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, alpha=1,\n",
    "    weight_decay=0.01, push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d4c5ea6-9ca1-4642-beb1-0bd4d1643f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "# initialize a student model\n",
    "\n",
    "id2label = pipe.model.config.id2label\n",
    "label2id = pipe.model.config.label2id\n",
    "\n",
    "num_labels = intents.num_classes\n",
    "student_config = (AutoConfig.\n",
    "                 from_pretrained(student_ckpt,\n",
    "                                num_labels=num_labels,\n",
    "                                id2label=id2label,\n",
    "                                label2id=label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e829652d-be8c-44b0-86cc-a3821b6b7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def student_init():\n",
    "    return (AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b9e506-49c9-4b61-9f96-bef1da98c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1334490/1465072472.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.320341</td>\n",
       "      <td>0.717097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.912013</td>\n",
       "      <td>0.853871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.193916</td>\n",
       "      <td>0.889677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.739800</td>\n",
       "      <td>0.889615</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.804199</td>\n",
       "      <td>0.917097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1590, training_loss=2.0883489740719585, metrics={'train_runtime': 83.0785, 'train_samples_per_second': 917.807, 'train_steps_per_second': 19.139, 'total_flos': 414689637990180.0, 'train_loss': 2.0883489740719585, 'epoch': 5.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the teacher and fine-tune\n",
    "teacher_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "teacher_model = (AutoModelForSequenceClassification\n",
    "                .from_pretrained(teacher_ckpt,\n",
    "                                num_labels=num_labels)\n",
    "                .to(device))\n",
    "\n",
    "distilbert_trainer = DistillationTrainer(model_init=student_init,\n",
    "                                        teacher_model=teacher_model, args=student_training_args,\n",
    "                                        train_dataset=clinc_enc[\"train\"],\n",
    "                                        eval_dataset=clinc_enc[\"validation\"],\n",
    "                                        compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f521eb58-7e57-4c81-a800-0b7df32d458c",
   "metadata": {},
   "source": [
    "The 92% accuracy on the validation set looks quite good compared to the 94% that the BERT-base teacher achieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a06ef94-704b-4b73-8953-aeccc4110315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658f630f856243f0a590bc960d42b22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sergi24sanchez/distilbert-base-uncased-finetuned-clinc/commit/100995603f7df01c6cd38673b47de06d386a8e04', commit_message='Training completed!', commit_description='', oid='100995603f7df01c6cd38673b47de06d386a8e04', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sergi24sanchez/distilbert-base-uncased-finetuned-clinc', endpoint='https://huggingface.co', repo_type='model', repo_id='sergi24sanchez/distilbert-base-uncased-finetuned-clinc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer.push_to_hub(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d07c9a84-ee42-48e4-8b51-b9f07b693060",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_ckpt = \"sergi24sanchez/distilbert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=finetuned_ckpt, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "723dd67f-6e41-4d65-91e7-cd9225718ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 255.88\n",
      "Average latency (ms) - 3.24 +\\- 0.18\n",
      "Accuracy on test set - 0.855\n"
     ]
    }
   ],
   "source": [
    "optim_type = \"DistilBERT\"\n",
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf26c0-8392-437b-8a14-39cec0f193c6",
   "metadata": {},
   "source": [
    "To compare these results against our baseline, let's create a scatter plot of the accyracy against the latency, with the radius of each point corresponding to the size of the model on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba81a9b5-f792-457d-9611-be96c6292d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1334490/2626924658.py:18: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  for handle in legend.legendHandles:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(perf_metrics, current_optim_type):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        # Add a dashed circle around the current optimization type\n",
    "        if idx == current_optim_type:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
    "            alpha=0.5, s=df_opt[\"size_mb\"], label=idx, marker='$\\u25CC$')\n",
    "        else:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
    "            alpha=0.5, s=df_opt[\"size_mb\"], label=idx)\n",
    "\n",
    "    legend = plt.legend(bbox_to_anchor=(1,1))\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_sizes([20])\n",
    "\n",
    "    plt.ylim(80,90)\n",
    "    # Use the slowest model to define the x-axis range\n",
    "    xlim = int(perf_metrics[\"BERT-baseline\"][\"time_avg_ms\"] + 3)\n",
    "    plt.xlim(1, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency (ms)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65682a36-bd0f-4413-b8a0-6735991f865a",
   "metadata": {},
   "source": [
    "From the plot we can see that by using a smaller model we've managed to significantly decrease the average latency. And all this at the price of just 1% reduction in accuracy!\n",
    "\n",
    "Let's see if we can close that last gap by including the distillation loss of the teacher and finding good values for alpha and T.\n",
    "\n",
    "### Finding Good Hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe8edc-2cd8-4793-85c2-9f2987ff410a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
