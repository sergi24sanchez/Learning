{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afffb5b1-366a-4a69-853e-0d52501863bd",
   "metadata": {},
   "source": [
    "# Chapter 8. Making Transformers Efficient in Production\n",
    "\n",
    "## Intent Detection as a Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d860dd-724f-4856-a08f-66d0079133ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbdf5c6f-e622-445d-bb61-e69b1aff7539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.5490034222602844}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f76f9a-3b5e-4260-a8eb-9d8dfdfcbdf9",
   "metadata": {},
   "source": [
    "## Creating a Performance Benchmark\n",
    "\n",
    "*Model performance*\n",
    "How well does our model perform on a well-crafted test set that reflects production data?\n",
    "\n",
    "*Latency*\n",
    "How fast can our model deliver predictions?\n",
    "\n",
    "*Memory*\n",
    "Billion-parameter models. Especially important role in mobile or edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff36494f-0c27-40d9-a998-5584f776f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    def __init__(self, pipeline, dataset, optim_type=\"BERT-baseline\"):\n",
    "        self.pipeline = pipeline\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "\n",
    "    def compute_accuracy(self):\n",
    "        pass\n",
    "\n",
    "    def compute_size(self):\n",
    "        pass\n",
    "\n",
    "    def time_pipeline(self):\n",
    "        pass\n",
    "\n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type].update(self.time_pipeline())\n",
    "        metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2733c49b-a4b2-4f09-94ff-49009cc29ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b7b5db-0f9d-435b-96bd-237cbcfb1a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = clinc[\"test\"][42]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcdf5e0-3726-45b3-9bca-5f15dad451fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transfer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc[\"test\"].features[\"intent\"]\n",
    "intents.int2str(sample[\"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ba3a38-b2b0-4d76-897e-e29547090d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy_score = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b3d505-3931-44ce-b5b0-e4902a68ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(self):\n",
    "    \"\"\"This overrides the PerformanceBenchmark.compute_accuracy() method\"\"\"\n",
    "    preds, labels = [], []\n",
    "    for example in self.dataset:\n",
    "        pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
    "        label = example[\"intent\"]\n",
    "        preds.append(intents.str2int(pred))\n",
    "        labels.append(label)\n",
    "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
    "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "    return accuracy\n",
    "\n",
    "PerformanceBenchmark.compute_accuracy = compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3ec836-1854-43b1-b37a-2a9beeac399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_size(self):\n",
    "    state_dict = self.pipeline.model.state_dict()\n",
    "    tmp_path = Path(\"model.pt\")\n",
    "    torch.save(state_dict, tmp_path)\n",
    "    # Calculate the size in megabytes\n",
    "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "    # Delete temporary file\n",
    "    tmp_path.unlink()\n",
    "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "    return {\"size_mb\": size_mb}\n",
    "\n",
    "PerformanceBenchmark.compute_size = compute_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3932649b-ebd3-4ef2-adc3-d6dd9c36fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency (ms) - 112.476\n",
      "Latency (ms) - 6.120\n",
      "Latency (ms) - 5.747\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "for _ in range(3):\n",
    "    start_time = perf_counter()\n",
    "    _ = pipe(query)\n",
    "    latency = perf_counter() - start_time\n",
    "    print(f\"Latency (ms) - {1000 * latency:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6a4fd8-3165-40c8-a26e-d503f56faef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
    "    latencies = []\n",
    "    for _ in range(10):\n",
    "        _ = self.pipeline(query)\n",
    "    # Timed run\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ = self.pipeline(query)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "PerformanceBenchmark.time_pipeline = time_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b39389-2dc6-4dd0-98d9-57ba3402cba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 418.15\n",
      "Average latency (ms) - 5.29 +\\- 0.05\n",
      "Accuracy on test set - 0.867\n"
     ]
    }
   ],
   "source": [
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"])\n",
    "perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403bb62-e748-461a-89c9-da5329b91f15",
   "metadata": {},
   "source": [
    "## Making Models Smaller via Knowledge Distillation\n",
    "\n",
    "training a smaller *student* model to mimic the behavior of a slower, larger, but better-performing *teacher*.\n",
    "\n",
    "### Knowledge Distillation for Fine-tuning\n",
    "\n",
    "For supervised tasks like fine-tuning, the main idea is to augment the ground truth labels with a distribution of \"soft probabilities\" from the teacher which provide complementary information for the sudient to learn from.\n",
    "\n",
    "### Knowledge Distillation for Pretraining\n",
    "\n",
    "general-purpose student that can be subsequently fine-tuned on downstream tasks. The teacher is a pretrained language model ehich transfers its knowledge about masked language modleing to the student."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef88d42-8355-4212-8157-402ad27ad28b",
   "metadata": {},
   "source": [
    "Let's see how we can use knowledge distillation to fine-tune a smaller and faster model. To do that we'll need a way to augment the corss-entropy loss with a Lkd term. Fortunately we can do this by **creating our own trainer**!\n",
    "\n",
    "### Creating a Knowledge Distillation Trainer\n",
    "\n",
    "We need to add a few things to the Trainer base class:\n",
    "- The new hyperparameters alpha and T, which control the relative weight of the distillation loss and how much the probability distribution of the labels should be smoothed\n",
    "- The fine-tuned teacher model, which in our casi is BERT-base\n",
    "- A new loss function that combines the cross-entropy loss with the knowledge distillation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe55233-e035-45ad-a7f3-c1b27f378818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Adding the new hyperparameters. include them as attrbutes\n",
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74f0696-e810-4fef-a7d1-5ebc4c11a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "# new loss function for the trainer itself. overriding compute_loss()\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs): # teacher model that has already been fine-tuned on our task\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs): # had to add **kwargs\n",
    "        outputs_stu = model(**inputs)\n",
    "        # Extract corss-entropy loss and logits from student\n",
    "        loss_ce = outputs_stu.loss\n",
    "        logits_stu = outputs_stu.logits\n",
    "        # Extract logits from teacher\n",
    "        with torch.no_grad():\n",
    "            outputs_tea = self.teacher_model(**inputs)\n",
    "            logits_tea = outputs_tea.logits\n",
    "        # Soften probabilities and compute distillation loss\n",
    "        loss_fct = nn.KLDivLoss(reduction=\"batchmean\") # we average the losses over the batch dimension\n",
    "        loss_kd = self.args.temperature ** 2 * loss_fct(\n",
    "            F.log_softmax(logits_stu / self.args.temperature, dim=-1), # expects the inputs in the form of log probabilities\n",
    "            F.softmax(logits_tea / self.args.temperature, dim=-1) # and the labels as normal probabilities\n",
    "        )\n",
    "        # Return weighted student loss\n",
    "        loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
    "        return (loss, outputs_stu) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda81ba7-a1cc-4f89-a5d7-0f8726b5cf0f",
   "metadata": {},
   "source": [
    "### Choosing a Good Student Initialization\n",
    "\n",
    "Which pretrained languange model should we pick for the student? In general we should pick a smaller model for the student to reduce the latency and memory footprint.\n",
    "\n",
    "A good rule of thumb from the literature is that knowledge distillation works best when the teacher and student are of the same *model type*. Different model types can have different output embedding spaces, which hinders the ability of the sudent to mimic the teacher.\n",
    "\n",
    "In our case the teacher is BERT, so DistilBERT is a natural candidate to initialize the student with since it has 40% fewer parameters and has been shown to acheve strong results on downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d2434e3-ef73-4478-a7f2-2f1e8243a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenize and encode our queries. Instantiate DistilBERT and create a simple tokenize_text() function ot take care of the preprocessing\n",
    "student_ckpt = \"distilbert-base-uncased\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)\n",
    "\n",
    "def tokenize_text(batch):\n",
    "    return student_tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"]) # we no longer need text column\n",
    "clinc_enc = clinc_enc.rename_column(\"intent\", \"labels\") # so it can be automatically detected by the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e6dacd-f4f1-4544-83c1-b96f819971b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8338f2caad479dadd48582d0aac955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02db83dd-49da-457e-be60-9cc14dbefe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compute_metrics() for our DistillationTrainer\n",
    "def compute_metrics(pred):\n",
    "    preds, labels = pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return accuracy_score.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f79cccd6-f609-41a5-a52b-be2d4c7ed2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Define training argumemnts\n",
    "batch_size = 48\n",
    "\n",
    "finetuned_ckpt = \"distilbert-base-uncased-finetuned-clinc\"\n",
    "student_training_args = DistillationTrainingArguments(\n",
    "    output_dir=finetuned_ckpt, evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5, learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, alpha=1,\n",
    "    weight_decay=0.01, push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d4c5ea6-9ca1-4642-beb1-0bd4d1643f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "# initialize a student model\n",
    "\n",
    "id2label = pipe.model.config.id2label\n",
    "label2id = pipe.model.config.label2id\n",
    "\n",
    "num_labels = intents.num_classes\n",
    "student_config = (AutoConfig.\n",
    "                 from_pretrained(student_ckpt,\n",
    "                                num_labels=num_labels,\n",
    "                                id2label=id2label,\n",
    "                                label2id=label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e829652d-be8c-44b0-86cc-a3821b6b7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def student_init():\n",
    "    return (AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7b9e506-49c9-4b61-9f96-bef1da98c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1349230/3053386859.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError(\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read)))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_102433-m7rubdz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/m7rubdz7' target=\"_blank\">distilbert-base-uncased-finetuned-clinc</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/m7rubdz7' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/m7rubdz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 01:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.320341</td>\n",
       "      <td>0.717097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.912013</td>\n",
       "      <td>0.853871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.193916</td>\n",
       "      <td>0.889677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.739800</td>\n",
       "      <td>0.889615</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.804199</td>\n",
       "      <td>0.917097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1590, training_loss=2.0883489740719585, metrics={'train_runtime': 113.0215, 'train_samples_per_second': 674.65, 'train_steps_per_second': 14.068, 'total_flos': 414689637990180.0, 'train_loss': 2.0883489740719585, 'epoch': 5.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n"
     ]
    }
   ],
   "source": [
    "# Load the teacher and fine-tune\n",
    "teacher_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "teacher_model = (AutoModelForSequenceClassification\n",
    "                .from_pretrained(teacher_ckpt,\n",
    "                                num_labels=num_labels)\n",
    "                .to(device))\n",
    "\n",
    "distilbert_trainer = DistillationTrainer(model_init=student_init,\n",
    "                                        teacher_model=teacher_model, args=student_training_args,\n",
    "                                        train_dataset=clinc_enc[\"train\"],\n",
    "                                        eval_dataset=clinc_enc[\"validation\"],\n",
    "                                        compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f521eb58-7e57-4c81-a800-0b7df32d458c",
   "metadata": {},
   "source": [
    "The 92% accuracy on the validation set looks quite good compared to the 94% that the BERT-base teacher achieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a06ef94-704b-4b73-8953-aeccc4110315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sergi24sanchez/distilbert-base-uncased-finetuned-clinc/commit/ce294051719361819bcacad60974dc2bf8f6c0a2', commit_message='Training completed!', commit_description='', oid='ce294051719361819bcacad60974dc2bf8f6c0a2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sergi24sanchez/distilbert-base-uncased-finetuned-clinc', endpoint='https://huggingface.co', repo_type='model', repo_id='sergi24sanchez/distilbert-base-uncased-finetuned-clinc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer.push_to_hub(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d07c9a84-ee42-48e4-8b51-b9f07b693060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10f87dddc5244a9afe6de3f64ffb0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/8.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c711ad3a1583414ab5de9d12b28afaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3884b44169c241e18db0a6e2c330e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141aa6013351459abb2ac49e3dbac45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255b5ca632b84d09b335c144d5567cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1785e8c1ac65484b8b270c2dad92aafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056c675d97f84a0a87a07918e65404eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned_ckpt = \"transformersbook/distilbert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=finetuned_ckpt, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723dd67f-6e41-4d65-91e7-cd9225718ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 255.88\n",
      "Average latency (ms) - 3.11 +\\- 0.46\n",
      "Accuracy on test set - 0.858\n"
     ]
    }
   ],
   "source": [
    "optim_type = \"DistilBERT\"\n",
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf26c0-8392-437b-8a14-39cec0f193c6",
   "metadata": {},
   "source": [
    "To compare these results against our baseline, let's create a scatter plot of the accyracy against the latency, with the radius of each point corresponding to the size of the model on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba81a9b5-f792-457d-9611-be96c6292d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1399227/2626924658.py:18: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  for handle in legend.legendHandles:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHbklEQVR4nO3de1yUZf7/8fcwnAbkoCgCKkgewPCQpzUPa1aYmpKa5WH9laeyvllmpaW1Wq4a6ZYd7Lua5qplHts0a/Ncpm7lGbQ0UVNEw6hUEJQBhvv3B19nIzUZBAZvX8/HYx6Pve+57uv6zEQ77677uu/bYhiGIQAAAJPwcHcBAAAAZYlwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMXt4ebcuXMaNWqUoqKiZLPZ1K5dO+3YscP5vmEYmjBhgsLDw2Wz2RQfH69Dhw65sWIAAFCZuT3cPPTQQ1q/fr3ef/997du3T3fddZfi4+N18uRJSdK0adP01ltvadasWdq2bZv8/f3VpUsX5ebmurlyAABQGVnc+eDMCxcuKCAgQB9//LG6d+/u3N+yZUt169ZNkyZNUkREhJ555hmNHj1akpSZmamaNWtq/vz56t+/v7tKBwAAlZSnOwcvKCiQw+GQr69vsf02m01bt27V0aNHderUKcXHxzvfCwoKUps2bfT1119fNtzY7XbZ7XbndmFhoU6fPq2QkBBZLJby+zAAAKDMGIahc+fOKSIiQh4erp1ocmu4CQgIUNu2bTVp0iQ1atRINWvW1OLFi/X111+rfv36OnXqlCSpZs2axY6rWbOm873fS0xM1MSJE8u9dgAAUP7S0tJUu3Ztl45xa7iRpPfff19Dhw5VrVq1ZLVa1aJFCw0YMEC7du0qVX/jxo3T008/7dzOzMxUZGSk0tLSFBgYWFZlAwCAcpSVlaU6deooICDA5WPdHm7q1aunL7/8Ujk5OcrKylJ4eLj69eunm266SWFhYZKkn376SeHh4c5jfvrpJ91yyy2X7c/Hx0c+Pj6X7A8MDCTcAABwnSnNkhK3Xy11kb+/v8LDw3XmzBmtXbtWPXv2VHR0tMLCwrRx40Znu6ysLG3btk1t27Z1Y7UAAKCycvvMzdq1a2UYhmJiYnT48GGNGTNGsbGxGjJkiCwWi0aNGqXJkyerQYMGio6O1vjx4xUREaFevXq5u3QAAFAJuT3cZGZmaty4cTpx4oSqVaumPn36aMqUKfLy8pIkPfvss8rJydHw4cN19uxZdejQQWvWrLnkCisAAADJzfe5qQhZWVkKCgpSZmYma24AoIw5HA7l5+e7uwxch7y8vGS1Wq/4/rX8frt95gYAcP0xDEOnTp3S2bNn3V0KrmPBwcEKCwsr8/vQEW4AAC67GGxCQ0Pl5+fHTVLhEsMwdP78eWVkZEhSsSuiywLhBgDgEofD4Qw2ISEh7i4H1ymbzSZJysjIUGho6B+eonJVpbkUHABwfbi4xsbPz8/NleB6d/FvqKzXbRFuAAClwqkoXKvy+hsi3AAAAFMh3AAA4GaDBw92+81pX3rppWKPNqoMNZUW4QYAcMMYPHiwLBaL8xUSEqKuXbtq7969zja/ff+3ryVLlkiSNm3aVGx/jRo1dPfdd2vfvn1/ePzF10svveSOj+6yN998U/Pnz3d3GaVCuAEA3FC6du2q9PR0paena+PGjfL09FSPHj2KtZk3b56zzcXX72cxDh48qPT0dK1du1Z2u13du3dXXl5esWPeeOMNBQYGFts3evToCvy0pRcUFKTg4GB3l1EqhBsAgNucycnT0V9ydCYnr8LG9PHxUVhYmMLCwnTLLbdo7NixSktL088//+xsc/Hmcr99/f6xP6GhoQoLC1OLFi00atQopaWl6fvvvy92TFBQkCwWS7F9VapUuWJtEydOVI0aNRQYGKhHH31UeXn//V7WrFmjDh06KDg4WCEhIerRo4eOHDnifD8vL0+PP/64wsPD5evrq6ioKCUmJjrfP3v2rB566CFn/3fccYeSk5OvWMvvT0t16tRJI0eO1LPPPqtq1aopLCzsklkoV8coL9znBgBQ4XLzHfp074/aeeyMzucVyM/bU63qVlWPphHy9Sq7+51cTXZ2thYuXKj69euX+p49mZmZzlNW3t7epa5l48aN8vX11aZNm3Ts2DENGTJEISEhmjJliiQpJydHTz/9tJo2bars7GxNmDBBvXv3VlJSkjw8PPTWW29p1apVWrZsmSIjI5WWlqa0tDRn//fff79sNptWr16toKAgvfPOO7rzzjuVkpKiatWqlajGBQsW6Omnn9a2bdv09ddfa/DgwWrfvr06d+5cZmOUBcINAKDCfbr3R63f/5NC/H0UEWxT1oUCrd//kyTpvpZ1ynfsTz91zp7k5OQoPDxcn376qTw8/nsyY8CAAZfcVG7//v2KjIx0bteuXdvZhyTdc889io2NLXVd3t7e+uc//yk/Pz/FxcXpb3/7m8aMGaNJkybJw8NDffr0Kdb+n//8p2rUqKH9+/ercePGOn78uBo0aKAOHTrIYrEoKirK2Xbr1q3avn27MjIy5OPjI0l69dVXtXLlSn344YcaPnx4iWps2rSpXnzxRUlSgwYN9Pbbb2vjxo3q3LlzmY1RFjgtBQCoUGdy8rTz2BmF+PuoRoCPfDytqhHgoxB/H+06dqbcT1HdfvvtSkpKUlJSkrZv364uXbqoW7duSk1NdbZ5/fXXnW0uviIiIor1s2XLFu3atUvz589Xw4YNNWvWrKuOffz4cVWpUsX5evnll53vNWvWrNiNEdu2bavs7Gzn7MuhQ4c0YMAA3XTTTQoMDFTdunWdfUpFp5GSkpIUExOjkSNHat26dc6+kpOTlZ2drZCQkGLjHz16tNipratp2rRpse3w8HDnIxTKaoyywMwNAKBCnb2Qr/N5BYoIthXbH2jz1I9nL+jshXxV9S/96Z2r8ff3V/369Z3b7777roKCgjRnzhxNnjxZkhQWFlaszeVER0crODhYMTExysjIUL9+/bR58+Y/PCYiIkJJSUnObVdO1SQkJCgqKkpz5sxRRESECgsL1bhxY+e6nBYtWujo0aNavXq1NmzYoL59+yo+Pl4ffvihsrOzFR4erk2bNl3SryuLhr28vIptWywWFRYWSlKZjVEWCDcAgAoVbPOSn7ensi4UqEbAf0/9ZF0okL+3p4JtXn9wdNmzWCzy8PDQhQsXSt3HiBEjlJiYqBUrVqh3795XbOfp6XnF0JScnKwLFy44n7n0zTffqEqVKqpTp45+/fVXHTx4UHPmzNGf//xnSUWnmn4vMDBQ/fr1U79+/XTfffepa9euOn36tFq0aKFTp07J09PTOeNT1ipijJLitBQAoEJV9fdWq7pV9WuOXT+fs8te4NDP5+z6NceulnWrluusjSTZ7XadOnVKp06d0oEDB/TEE08oOztbCQkJzjZnz551trn4uri25nL8/Pz08MMP68UXX5RhGKWqKy8vT8OGDdP+/fv12Wef6cUXX9Tjjz8uDw8PVa1aVSEhIZo9e7YOHz6szz//XE8//XSx46dPn67Fixfr+++/V0pKipYvX66wsDAFBwcrPj5ebdu2Va9evbRu3TodO3ZMX331lV544QXt3LmzVPX+XkWMUVKEGwBAhevRNEKdb64pwzD049kLMgxDnW+uqR5NI65+8DVas2aNwsPDFR4erjZt2mjHjh1avny5OnXq5GwzZMgQZ5uLrxkzZvxhv48//rgOHDig5cuXl6quO++8Uw0aNFDHjh3Vr18/3XPPPc5LrT08PLRkyRLt2rVLjRs31lNPPaW///3vxY4PCAjQtGnT1KpVK7Vu3VrHjh3TZ599Jg8PD1ksFn322Wfq2LGjhgwZooYNG6p///5KTU1VzZo1S1Xv71XEGCWuxShtxLxOZGVlKSgoSJmZmQoMDHR3OQBw3cvNzdXRo0cVHR19yb1fXHUmJ09nL+Qr2OZV7jM2qHz+6G/pWn6/WXMDAHCbqv7ehBqUOU5LAQAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAADwOxaLRStXriz18S+99JJuueUW5/bgwYPVq1eva64LJUO4AQDcMAYPHiyLxSKLxSIvLy/VrFlTnTt31j//+U8VFhY626Wnp6tbt24l6vNyQWj06NHauHFjieqwWCwKCQlR165dtXfv3kv6vtxryZIlkqRNmzYV21+jRg3dfffd2rdv3x8ef/F18dlVZkO4AQDcULp27ar09HQdO3ZMq1ev1u23364nn3xSPXr0UEFBgSQpLCxMPj4+pR6jSpUqCgkJKVEd6enp2rhxozw9PdWjR49L2s2bN8/Z7uLr97NABw8eVHp6utauXSu73a7u3bsrLy+v2DFvvPGGAgMDi+0bPXp0qT9jZUa4AQC4j2FI9mzJkV9hQ/r4+CgsLEy1atVSixYt9Pzzz+vjjz/W6tWrNX/+fEnFZ2Py8vL0+OOPKzw8XL6+voqKilJiYqIkqW7dupKk3r17y2KxOLd/f1rqj+oICwvTLbfcorFjxyotLU0///xzsXbBwcHOdhdfv3/IZGhoqMLCwtSiRQuNGjVKaWlp+v7774sdExQUJIvFUmxflSpVrum7rKx4cCYAwD0yDkjfrZCyf5J8gqTIW6X68ZJnxT9I84477lCzZs300Ucf6aGHHir23ltvvaVVq1Zp2bJlioyMVFpamtLS0iRJO3bsUGhoqObNm6euXbvKarWWavzs7GwtXLhQ9evXv+qMzx/JzMx0nrLy9r5xH0hKuAEAVLzMk9KOuZKnj+QfWrTv+0+lglyp8b1uKSk2NvaSNS+SdPz4cTVo0EAdOnSQxWJRVFSU870aNWpI+u/siis+/fRT58xJTk6OwsPD9emnn8rDo/hJlQEDBlwSmvbv36/IyEjndu3atZ39SNI999yj2NhYl+oxE8INAKDipX4l+QZLLR6QqkZJBXnSf96UfvpOqn+n5BtU4SUZhiGLxXLJ/sGDB6tz586KiYlR165d1aNHD911113XPN7tt9+umTNnSpLOnDmjf/zjH+rWrZu2b99eLEC9/vrrio+PL3ZsREREse0tW7bIz89P33zzjV5++WXNmjXrmuu7nhFuAAAVLz1ZcuQVBRup6FRUjYbSoQ1Szi9uCTcHDhxQdHT0JftbtGiho0ePavXq1dqwYYP69u2r+Ph4ffjhh9c0nr+/v+rXr+/cfvfddxUUFKQ5c+Zo8uTJzv1hYWHF2l1OdHS0goODFRMTo4yMDPXr10+bN2++pvquZywoBgBUvPBmkk+gdCa1aLsgT/o5RaoSKvlXr/ByPv/8c+3bt099+vS57PuBgYHq16+f5syZo6VLl+pf//qXTp8+LUny8vKSw+G45hosFos8PDx04cKFa+pnxIgR+vbbb7VixYprrul6xcwNAKDiRbWT0rZJ22dLXn5F+7JOFi0oLudZG7vdrlOnTsnhcOinn37SmjVrlJiYqB49eujBBx+8pP306dMVHh6u5s2by8PDQ8uXL1dYWJiCg4MlFV0xtXHjRrVv314+Pj6qWrWqS3VIRael3n77bWVnZyshIaFYu7NnzzrbXRQQECB/f//L9uvn56eHH35YL774onr16nXZU21mx8wNAKDiBdWSWg+TvP2lnAypwC7F9ih6lbM1a9YoPDxcdevWVdeuXfXFF1/orbfe0scff3zZq50CAgI0bdo0tWrVSq1bt9axY8f02WefORf+vvbaa1q/fr3q1Kmj5s2bu1xHeHi42rRpox07dmj58uXq1KlTsXZDhgxxtrv4mjFjxh/2/fjjj+vAgQNavnx5iesxE4thGIa7iyhPWVlZCgoKUmZmpgIDA91dDgBc93Jzc3X06FFFR0dfcr8VlxmGlJdTdNWU1atsCsR144/+lq7l95vTUgAA97FYJB9z3kgO7sNpKQAAYCqEGwAAYCqEGwAAYCqEGwBAqZj8ehRUgPL6GyLcAABc4uVVdFXT+fPn3VwJrncX/4Yu/k2VFa6WAgC4xGq1Kjg4WBkZGZKKbhp3I94oDqVnGIbOnz+vjIwMBQcHl/pp6ldCuAEAuOziE7AvBhygNErzNPWSINwAAFxmsVgUHh6u0NBQ5efnu7scXIe8vLzKfMbmIsINAKDUrFZruf1AAaXFgmIAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqbg03DodD48ePV3R0tGw2m+rVq6dJkybJMAxnm+zsbD3++OOqXbu2bDabbr75Zs2aNcuNVQMAgMrM052DT506VTNnztSCBQsUFxennTt3asiQIQoKCtLIkSMlSU8//bQ+//xzLVy4UHXr1tW6dev02GOPKSIiQvfcc487ywcAAJWQW2duvvrqK/Xs2VPdu3dX3bp1dd999+muu+7S9u3bi7UZNGiQOnXqpLp162r48OFq1qxZsTYAAAAXuTXctGvXThs3blRKSookKTk5WVu3blW3bt2KtVm1apVOnjwpwzD0xRdfKCUlRXfddddl+7Tb7crKyir2AgAANw63npYaO3assrKyFBsbK6vVKofDoSlTpmjgwIHONjNmzNDw4cNVu3ZteXp6ysPDQ3PmzFHHjh0v22diYqImTpxYUR8BAABUMm6duVm2bJk++OADLVq0SLt379aCBQv06quvasGCBc42M2bM0DfffKNVq1Zp165deu211zRixAht2LDhsn2OGzdOmZmZzldaWlpFfRwAAFAJWIzfXppUwerUqaOxY8dqxIgRzn2TJ0/WwoUL9f333+vChQsKCgrSihUr1L17d2ebhx56SCdOnNCaNWuuOkZWVpaCgoKUmZmpwMDAcvkcAACgbF3L77dbZ27Onz8vD4/iJVitVhUWFkqS8vPzlZ+f/4dtAAAAfsuta24SEhI0ZcoURUZGKi4uTnv27NH06dM1dOhQSVJgYKBuu+02jRkzRjabTVFRUfryyy/13nvvafr06e4sHQAAVFJuPS117tw5jR8/XitWrFBGRoYiIiI0YMAATZgwQd7e3pKkU6dOady4cVq3bp1Onz6tqKgoDR8+XE899ZQsFstVx+C0FAAA159r+f12a7ipCIQbAACuP9ftmhsAAICyRrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACm4unuAgAAxdkLHMrIsutcboEKDUMeFosCfD0VGugjH0+ru8sDKj3CDQBUAudy87XvZKb2nsjUiTPnlWMvkD2/0BlufLw85O/jqdpV/dS0dpCa1ApSgK+Xu8sGKiXCDQC4UY69QJsOZmjb0dPKyLLLy2pRgK+Xqlfxka+nVRaLZBhSboFDOXaHvjuZqaTjZxUa6KM20dXUKSZU/j78XznwW/wbAQBuYBiGDv50Tp8k/6jDGdkKtnmrXqi/PD0uXQppsUh+3p7y8/ZUjQAfFRQW6pdzeVqV/KP2p2cpoVmEYsMC3fApgMqJcAMAFcwwDG09/Is+3nNSF/ILVa9GFXlZS359h6eHh8KCfBVSxVvHfjmvdzf/oF7Na6t9/RBZLJZyrBy4PnC1FABUoIvB5sNdJ+ThYVH9UNeCzW95WT1UP7SKPDwsWr4rTf85/GsZVwtcnwg3AFCBDv50Th/vOSkfTw+FB9nKpM/wIJt8PD20Mumkvj+VVSZ9Atczwg0AVJAce4E+Sf5RF/ILyyzYXBQeZNOFPIc+Sf5ROfaCMu0buN4QbgCggmw6mKHDGdmKCvErl/6jQvx0OCNbmw5mlEv/wPWCcAMAFeBcbr62HT2tYJt3qdfYXI2X1UPBNm9tO3pa53Lzy2UM4HpAuAGACrDvZKYysuyqHuBdruNUD/BWRpZd355k7Q1uXIQbAKgAe09kystquex9bMqSp4eHvKwWJZ84W67jAJUZ4QYAypm9wKETZ85X2OMSAny9dPLMBdkLHBUyHlDZEG4AoJxlZNmVYy+Qv0/FPPTSz9uqbHuBMrLsFTIeUNkQbgCgnJ3LLXoIpm8FPdHb18sqe75D53K5JBw3JsINAJSzQsNQoWGoop6M4GGRCv9vXOBGRLgBgHLmYbHIw2JRRWWNQqPo/9w9eM4UblCEGwAoZwG+nvLx8lBuBS3wzc13yMfLqgBfno2MGxPhBgDKWWigj/x9PJVjr5hwcz7PoSo+ngoN9KmQ8YDKhnADAOXMx9Oq2lX9Kuyuwedy81Wrqk0+FbSAGahsCDcAUAGa1g5SvsNQQWFhuY5TUFiofIehZrWDy3UcoDIj3ABABWhSK0ihgT765VxeuY7zy7k8hQb6qHGtwHIdB6jMCDcAUAECfL3UJrqazl7IU76jfGZv8h2FOnshT22iq1XY3ZCByohwAwAVpFNMqOqHVlHqr+fLpf/UX8+rfmgVdYoJLZf+gesF4QYAKoi/j6cSmkXI5uWh9MwLZdp3euYF2bytSmgWIX8fLgHHjY1wAwAVKKZmgHo2ryV7QWGZBZz0zAuyFxSq1y21FBvGWhuAcAMAFchisahD/eq6v2UdFRrS4YzsUq/ByXcU6nBGtgoN6f6WddS+fkgZVwtcn5i7BIAKZrFY1KFBdVUP8NYnyT/qcEa2gm3eqh7gLU+Pq/83Z0FhoX45l6ezF/JUP7SKEppFMGMD/AbhBgDcJDYsUHWq+mnTwQxtO3paRzJy5GW1KMDXS37eVvl6WYsegmkUPVLhfJ5D53Lzle8wFBroo3saRqhTTChrbIDf4d8IAHAjfx9PdW8aoY4Na+jbk1lKPnFWJ89c0K85ebLnO1SoovUDPl5WVfHxVFytIDWrHazGtQK53Bu4AsINAFQCAb5ealsvRG3rhche4FBGll3ncgtUaBjysFgU4Fv0rCgeqQBcHeEGACoZH0+r6lTzc3cZwHWLq6UAAICpEG4AAICpEG4AAICpuLTmprCwUF9++aW2bNmi1NRUnT9/XjVq1FDz5s0VHx+vOnXqlFedAAAAJVKimZsLFy5o8uTJqlOnju6++26tXr1aZ8+eldVq1eHDh/Xiiy8qOjpad999t7755pvyrhkAAOCKSjRz07BhQ7Vt21Zz5sxR586d5eV16b0VUlNTtWjRIvXv318vvPCCHn744TIvFgAA4GoshmEYV2t04MABNWrUqEQd5ufn6/jx46pXr95V2zocDr300ktauHChTp06pYiICA0ePFh//etfZbFYio3/3HPP6csvv1RBQYFuvvlm/etf/1JkZORVx8jKylJQUJAyMzMVGMjtyXGNzp2STv8g5WZKhQWSl02qUlOqEStZuaEaAJSVa/n9LtHMTUmDjSR5eXmVKNhI0tSpUzVz5kwtWLBAcXFx2rlzp4YMGaKgoCCNHDlSknTkyBF16NBBw4YN08SJExUYGKjvvvtOvr6+Ja4JuCaFDskoLAovu+ZLp/YVbRc6ivb5BkmtH5JqtZDycyUv/jYBwJ1KfRO/goICvfPOO9q0aZMcDofat2+vESNGuBQ6vvrqK/Xs2VPdu3eXJNWtW1eLFy/W9u3bnW1eeOEF3X333Zo2bZpzX0nDE3DNzhyTkhZLfiHSnx4umqE5tU/y9JEsHpIjX7J6S1XrSj+nSLsXSHU7SPXjmckBADcpdbgZOXKkUlJSdO+99yo/P1/vvfeedu7cqcWLF5e4j3bt2mn27NlKSUlRw4YNlZycrK1bt2r69OmSiq7O+ve//61nn31WXbp00Z49exQdHa1x48apV69el+3TbrfLbrc7t7Oyskr7EXGjO7lL2rNQ+uWQFFhLOnuXFN1R8q9eFHY8vCR7ZlFbv2rSdyuk9L3S2dSiUNT8Acmnils/AgDciEocblasWKHevXs7t9etW6eDBw/Kai16zkmXLl106623ujT42LFjlZWVpdjYWFmtVjkcDk2ZMkUDBw6UJGVkZCg7O1uvvPKKJk+erKlTp2rNmjW699579cUXX+i22267pM/ExERNnDjRpTqAS6QnSzvnFa2x8Q2SQupJ3gFFIaZuh8sfUzW6aAbnXLr0w5dFp63+9HDRLA8AoMKUaEGxJCUkJMhqteof//iHIiIi1LdvXwUFBalPnz7Kz8/XnDlzdOHCBa1fv77Egy9ZskRjxozR3//+d8XFxSkpKUmjRo3S9OnTNWjQIP3444+qVauWBgwYoEWLFjmPu+eee+Tv73/ZWaLLzdzUqVOHBcVwzeZXpdT/FAWamLulxr1LFlJ+OSzt+qf00wGpSqh066NSRPPyrxcATKbcFxRL0ieffKKlS5eqU6dOeuKJJzR79mxNmjRJL7zwgnPNzUsvveTS4GPGjNHYsWPVv39/SVKTJk2UmpqqxMREDRo0SNWrV5enp6duvvnmYsc1atRIW7duvWyfPj4+8vHhv5RxjZoNkLz9i15N75c8Svgk5ur1pVbDpOQlUlQ7qWbj8q0TAHAJl9bc9OvXT126dHGugZk1a5Zee+21Ug9+/vx5eXgUv4+g1WpVYWGhJMnb21utW7fWwYMHi7VJSUlRVFRUqccFriqolnTr/0iGIf3mtgQlElJPuv15148DAJQJlxcUBwcHa/bs2dq8ebMefPBBde3aVZMmTSrVpdkJCQmaMmWKIiMjFRcXpz179mj69OkaOnSos82YMWPUr18/dezYUbfffrvWrFmjTz75RJs2bXJ5POCqzhwrWm9TI1aq3rD0AcVikXKzpFN7i+6JE3M3YQcAKkiJH5x5/Phx9e3bV02aNNHAgQPVoEED7dq1S35+fmrWrJlWr17t8uAzZszQfffdp8cee0yNGjXS6NGj9cgjj2jSpEnONr1799asWbM0bdo0NWnSRO+++67+9a9/qUOHKyzqBK7FqW+l3e9LX/9DOnP02vr6boX09f9KB9dIF86UTX0AgKsq8YLiTp06KSwsTIMHD9batWt15MgRrVq1SlLRHYQfeeQRhYWFadmyZeVasKu4QzFcsus9af/KorsOx78kBdQsfV/ffiQlLZJsVaU7/ipV5VQqAJRUhSwo3rlzp5KTk1WvXj116dJF0dHRzvcaNWqkzZs3a/bs2S4NDlQ6jlxJRtECYk/va+vr4o3+DEfRoxoAABWixOGmZcuWmjBhggYNGqQNGzaoSZMml7QZPnx4mRYHVDirryRL0T1qCvKura8Ce9FjGixWyaPU98sEALioxGtu3nvvPdntdj311FM6efKk3nnnnfKsC3APv2pFszZWbyk/59r6sp8r6sfTV/LllCgAVJQSr7m5XrHmBi45c6zoEQo1YqXqDa7tCqfcrKLnUOVmSjHduFoKAFxQ7mtucnJy5O/vX+JOXW0PVBpV6xa9LirNfW4uHucbKNVtX1aVAQBKqESnperXr69XXnlF6enpV2xjGIbWr1+vbt266a233iqzAgG3yDxZdDn4nveL1t+44pfD0hcvS0e+KHpqOACgQpVo5mbTpk16/vnn9dJLL6lZs2Zq1aqVIiIi5OvrqzNnzmj//v36+uuv5enpqXHjxumRRx4p77qB8pW8+L/PlvLwLsWzpfZLZ48XPXSzVovyrxcA4OTSmpvjx49r+fLl2rJli1JTU3XhwgVVr15dzZs3V5cuXdStWzfnU8IrC9bcoFTSk6Xtc4qeCu7pI4U3K3pmlH/IlY85/HnRjfvOpRddHRXdUWr90LVfUg4AN6Br+f1mQTFwJSd3SXsWSr8ckgJrSbePK5rJydgv+VeXPLwke2ZR21otpR1zpe9WSrbgoodmtniw6MGbAACXVchN/IAbTq2Wkl9I0RO+bdWk4Chp/8fSvuVFwcbDQ3LkSX7VparRUt0/S6d/kOp2kOrHS1Yvd38CALghEW6AP1K1rtRxzP/djM8i/fx90X6HXcp3FAUYR17RJeS1Wkh3jJe8XH+ILACg7BBugKvxsEr6v7VkLQcXzc7kZkmF+ZKXreg5VDVii94n2ACA2xFuAFcEhBW9AACVVokfvwAAAHA9cDnc1K1bV3/72990/Pjx8qgHAADgmrgcbkaNGqWPPvpIN910kzp37qwlS5bIbreXR20AAAAuK1W4SUpK0vbt29WoUSM98cQTCg8P1+OPP67du3eXR40AAAAlds038cvPz9c//vEPPffcc8rPz1eTJk00cuRIDRkyRJZK8BRkbuIHAMD1xy038cvPz9eKFSs0b948rV+/XrfeequGDRumEydO6Pnnn9eGDRu0aNGi0nYPAABQKi6Hm927d2vevHlavHixPDw89OCDD+r1119XbGyss03v3r3VunXrMi0UAACgJFwON61bt1bnzp01c+ZM9erVS15el95iPjo6Wv379y+TAgEAAFzhcrj54YcfFBUV9Ydt/P39NW/evFIXBQAAUFouXy2VkZGhbdu2XbJ/27Zt2rlzZ5kUBQAAUFouh5sRI0YoLS3tkv0nT57UiBEjyqQoAACA0nI53Ozfv18tWrS4ZH/z5s21f//+MikKAACgtFwONz4+Pvrpp58u2Z+eni5PT57DCQAA3MvlcHPXXXdp3LhxyszMdO47e/asnn/+eXXu3LlMiwMAAHCVy1Mtr776qjp27KioqCg1b95ckpSUlKSaNWvq/fffL/MCAQAAXOFyuKlVq5b27t2rDz74QMnJybLZbBoyZIgGDBhw2XveAAAAVKRSLZLx9/fX8OHDy7oWAACAa1bqFcD79+/X8ePHlZeXV2z/Pffcc81FAQAAlFap7lDcu3dv7du3TxaLRRcfKn7xCeAOh6NsKwQAAHCBy1dLPfnkk4qOjlZGRob8/Pz03XffafPmzWrVqpU2bdpUDiUCAACUnMszN19//bU+//xzVa9eXR4eHvLw8FCHDh2UmJiokSNHas+ePeVRJwAAQIm4PHPjcDgUEBAgSapevbp+/PFHSVJUVJQOHjxYttUBAAC4yOWZm8aNGys5OVnR0dFq06aNpk2bJm9vb82ePVs33XRTedQIAABQYi6Hm7/+9a/KycmRJP3tb39Tjx499Oc//1khISFaunRpmRcIAADgCotx8XKna3D69GlVrVrVecVUZZKVlaWgoCBlZmYqMDDQ3eUAAIASuJbfb5fW3OTn58vT01Pffvttsf3VqlWrlMEGAADceFwKN15eXoqMjOReNgAAoNJy+WqpF154Qc8//7xOnz5dHvUAAABcE5cXFL/99ts6fPiwIiIiFBUVJX9//2Lv7969u8yKAwAAcJXL4aZXr17lUAYAAEDZKJOrpSozrpYCAOD6U2FXSwEAAFR2Lp+W8vDw+MPLvrmSCgAAuJPL4WbFihXFtvPz87Vnzx4tWLBAEydOLLPCAAAASqPM1twsWrRIS5cu1ccff1wW3ZUZ1twAAHD9qRRrbm699VZt3LixrLoDAAAolTIJNxcuXNBbb72lWrVqlUV3AAAApebympvfPyDTMAydO3dOfn5+WrhwYZkWBwAA4CqXw83rr79eLNx4eHioRo0aatOmjapWrVqmxQEAALjK5XAzePDgcigDAACgbLi85mbevHlavnz5JfuXL1+uBQsWlElRAAAApeVyuElMTFT16tUv2R8aGqqXX365TIoCAAAoLZfDzfHjxxUdHX3J/qioKB0/frxMigIAACgtl8NNaGio9u7de8n+5ORkhYSElElRAAAApeVyuBkwYIBGjhypL774Qg6HQw6HQ59//rmefPJJ9e/fvzxqBAAAKDGXr5aaNGmSjh07pjvvvFOenkWHFxYW6sEHH2TNDQAAcLtSP1vq0KFDSkpKks1mU5MmTRQVFVXWtZUJni0FAMD151p+v12eubmoQYMGatCgQWkPBwAAKBcur7np06ePpk6desn+adOm6f777y+TogAAAErL5XCzefNm3X333Zfs79atmzZv3lwmRQEAAJSWy+EmOztb3t7el+z38vJSVlaWS305HA6NHz9e0dHRstlsqlevniZNmqQrLQN69NFHZbFY9MYbb7haNgAAuEG4HG6aNGmipUuXXrJ/yZIluvnmm13qa+rUqZo5c6befvttHThwQFOnTtW0adM0Y8aMS9quWLFC33zzjSIiIlwtGQAA3EBcXlA8fvx43XvvvTpy5IjuuOMOSdLGjRu1ePHiyz5z6o989dVX6tmzp7p37y5Jqlu3rhYvXqzt27cXa3fy5Ek98cQTWrt2rbMtAADA5bg8c5OQkKCVK1fq8OHDeuyxx/TMM8/oxIkT2rBhg3r16uVSX+3atdPGjRuVkpIiqegux1u3blW3bt2cbQoLC/XAAw9ozJgxiouLu2qfdrtdWVlZxV4AAODGUapLwbt3737ZGZRvv/1WjRs3LnE/Y8eOVVZWlmJjY2W1WuVwODRlyhQNHDjQ2Wbq1Kny9PTUyJEjS9RnYmKiJk6cWOIaAACAubg8c/N7586d0+zZs/WnP/1JzZo1c+nYZcuW6YMPPtCiRYu0e/duLViwQK+++qoWLFggSdq1a5fefPNNzZ8/XxaLpUR9jhs3TpmZmc5XWlqay58JAABcv0p9h+LNmzfr3Xff1UcffaSIiAjde++96tOnj1q3bl3iPurUqaOxY8dqxIgRzn2TJ0/WwoUL9f333+uNN97Q008/LQ+P/2Ywh8MhDw8P1alTR8eOHbvqGNyhGACA60+F3aH41KlTmj9/vubOnausrCz17dtXdrtdK1eudPlKKUk6f/58seAiSVarVYWFhZKkBx54QPHx8cXe79Klix544AENGTLE5fEAAID5lTjcJCQkaPPmzerevbveeOMNde3aVVarVbNmzSr14AkJCZoyZYoiIyMVFxenPXv2aPr06Ro6dKgkKSQkRCEhIcWO8fLyUlhYmGJiYko9LgAAMK8Sh5vVq1dr5MiR+p//+Z8ye6bUjBkzNH78eD322GPKyMhQRESEHnnkEU2YMKFM+gcAADeeEq+5+eabbzR37lwtXbpUjRo10gMPPKD+/fsrPDxcycnJpTotVRFYcwMAwPXnWn6/S3y11K233qo5c+YoPT1djzzyiJYsWaKIiAgVFhZq/fr1OnfunMuFAwAAlLVSXy0lSQcPHtTcuXP1/vvv6+zZs+rcubNWrVpVlvVdM2ZuAAC4/lTIzM3lxMTEaNq0aTpx4oQWL158LV0BAACUiWuaubkeMHMDAMD1x20zNwAAAJUN4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJiKW8ONw+HQ+PHjFR0dLZvNpnr16mnSpEkyDEOSlJ+fr+eee05NmjSRv7+/IiIi9OCDD+rHH390Z9kAAKAS83Tn4FOnTtXMmTO1YMECxcXFaefOnRoyZIiCgoI0cuRInT9/Xrt379b48ePVrFkznTlzRk8++aTuuece7dy5052lAwCASspiXJwmcYMePXqoZs2amjt3rnNfnz59ZLPZtHDhwsses2PHDv3pT39SamqqIiMjrzpGVlaWgoKClJmZqcDAwDKrHQAAlJ9r+f1262mpdu3aaePGjUpJSZEkJScna+vWrerWrdsVj8nMzJTFYlFwcPBl37fb7crKyir2AgAANw63npYaO3assrKyFBsbK6vVKofDoSlTpmjgwIGXbZ+bm6vnnntOAwYMuGKKS0xM1MSJE8uzbAAAUIm5deZm2bJl+uCDD7Ro0SLt3r1bCxYs0KuvvqoFCxZc0jY/P199+/aVYRiaOXPmFfscN26cMjMzna+0tLTy/AgAAKCScevMzZgxYzR27Fj1799fktSkSROlpqYqMTFRgwYNcra7GGxSU1P1+eef/+G5Nx8fH/n4+JR77QAAoHJya7g5f/68PDyKTx5ZrVYVFhY6ty8Gm0OHDumLL75QSEhIRZcJAACuI24NNwkJCZoyZYoiIyMVFxenPXv2aPr06Ro6dKikomBz3333affu3fr000/lcDh06tQpSVK1atXk7e3tzvIBAEAl5NZLwc+dO6fx48drxYoVysjIUEREhAYMGKAJEybI29tbx44dU3R09GWP/eKLL9SpU6erjsGl4AAAXH+u5ffbreGmIhBuAAC4/ly397kBAAAoa4QbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKm4NNw6HQ+PHj1d0dLRsNpvq1aunSZMmyTAMZxvDMDRhwgSFh4fLZrMpPj5ehw4dcmPVAACgMnNruJk6dapmzpypt99+WwcOHNDUqVM1bdo0zZgxw9lm2rRpeuuttzRr1ixt27ZN/v7+6tKli3Jzc91YOQAAqKwsxm+nSSpYjx49VLNmTc2dO9e5r0+fPrLZbFq4cKEMw1BERISeeeYZjR49WpKUmZmpmjVrav78+erfv/9Vx8jKylJQUJAyMzMVGBhYbp8FAACUnWv5/fYsp5pKpF27dpo9e7ZSUlLUsGFDJScna+vWrZo+fbok6ejRozp16pTi4+OdxwQFBalNmzb6+uuvLxtu7Ha77Ha7czszM1NS0ZcEAACuDxd/t0szB+PWcDN27FhlZWUpNjZWVqtVDodDU6ZM0cCBAyVJp06dkiTVrFmz2HE1a9Z0vvd7iYmJmjhx4iX769SpU8bVAwCA8vbrr78qKCjIpWPcGm6WLVumDz74QIsWLVJcXJySkpI0atQoRUREaNCgQaXqc9y4cXr66aed22fPnlVUVJSOHz/u8pdjdllZWapTp47S0tI4Zfc7fDdXxndzeXwvV8Z3c2V8N1eWmZmpyMhIVatWzeVj3RpuxowZo7FjxzpPLzVp0kSpqalKTEzUoEGDFBYWJkn66aefFB4e7jzup59+0i233HLZPn18fOTj43PJ/qCgIP5wriAwMJDv5gr4bq6M7+by+F6ujO/myvhurszDw/Vrn9x6tdT58+cvKdpqtaqwsFCSFB0drbCwMG3cuNH5flZWlrZt26a2bdtWaK0AAOD64NaZm4SEBE2ZMkWRkZGKi4vTnj17NH36dA0dOlSSZLFYNGrUKE2ePFkNGjRQdHS0xo8fr4iICPXq1cudpQMAgErKreFmxowZGj9+vB577DFlZGQoIiJCjzzyiCZMmOBs8+yzzyonJ0fDhw/X2bNn1aFDB61Zs0a+vr4lGsPHx0cvvvjiZU9V3ej4bq6M7+bK+G4uj+/lyvhurozv5squ5btx631uAAAAyhrPlgIAAKZCuAEAAKZCuAEAAKZCuAEAAKZi2nCzefNmJSQkKCIiQhaLRStXrnR3SZVGYmKiWrdurYCAAIWGhqpXr146ePCgu8tyu5kzZ6pp06bOm2m1bdtWq1evdndZldIrr7zivFXDje6ll16SxWIp9oqNjXV3WZXGyZMn9f/+3/9TSEiIbDabmjRpop07d7q7LLerW7fuJX83FotFI0aMcHdpbudwODR+/HhFR0fLZrOpXr16mjRpkkvPmHLrpeDlKScnR82aNdPQoUN17733urucSuXLL7/UiBEj1Lp1axUUFOj555/XXXfdpf3798vf39/d5blN7dq19corr6hBgwYyDEMLFixQz549tWfPHsXFxbm7vEpjx44deuedd9S0aVN3l1JpxMXFacOGDc5tT0/T/l+rS86cOaP27dvr9ttv1+rVq1WjRg0dOnRIVatWdXdpbrdjxw45HA7n9rfffqvOnTvr/vvvd2NVlcPUqVM1c+ZMLViwQHFxcdq5c6eGDBmioKAgjRw5skR9mPbfwG7duqlbt27uLqNSWrNmTbHt+fPnKzQ0VLt27VLHjh3dVJX7JSQkFNueMmWKZs6cqW+++YZw83+ys7M1cOBAzZkzR5MnT3Z3OZWGp6en83Ex+K+pU6eqTp06mjdvnnNfdHS0GyuqPGrUqFFs+5VXXlG9evV02223uamiyuOrr75Sz5491b17d0lFs1yLFy/W9u3bS9yHaU9LoeQyMzMlqVQPJzMrh8OhJUuWKCcnh0d9/MaIESPUvXt3xcfHu7uUSuXQoUOKiIjQTTfdpIEDB+r48ePuLqlSWLVqlVq1aqX7779foaGhat68uebMmePusiqdvLw8LVy4UEOHDpXFYnF3OW7Xrl07bdy4USkpKZKk5ORkbd261aUJC9PO3KBkCgsLNWrUKLVv316NGzd2dzlut2/fPrVt21a5ubmqUqWKVqxYoZtvvtndZVUKS5Ys0e7du7Vjxw53l1KptGnTRvPnz1dMTIzS09M1ceJE/fnPf9a3336rgIAAd5fnVj/88INmzpypp59+Ws8//7x27NihkSNHytvbW4MGDXJ3eZXGypUrdfbsWQ0ePNjdpVQKY8eOVVZWlmJjY2W1WuVwODRlyhQNHDiwxH0Qbm5wI0aM0LfffqutW7e6u5RKISYmRklJScrMzNSHH36oQYMG6csvv7zhA05aWpqefPJJrV+/vsSPPrlR/Pa/Jps2bao2bdooKipKy5Yt07Bhw9xYmfsVFhaqVatWevnllyVJzZs317fffqtZs2YRbn5j7ty56tatmyIiItxdSqWwbNkyffDBB1q0aJHi4uKUlJSkUaNGKSIiosR/N4SbG9jjjz+uTz/9VJs3b1bt2rXdXU6l4O3trfr160uSWrZsqR07dujNN9/UO++84+bK3GvXrl3KyMhQixYtnPscDoc2b96st99+W3a7XVar1Y0VVh7BwcFq2LChDh8+7O5S3C48PPyS/zBo1KiR/vWvf7mposonNTVVGzZs0EcffeTuUiqNMWPGaOzYserfv78kqUmTJkpNTVViYiLhBldmGIaeeOIJrVixQps2bWKB3x8oLCyU3W53dxlud+edd2rfvn3F9g0ZMkSxsbF67rnnCDa/kZ2drSNHjuiBBx5wdylu1759+0tuM5GSkqKoqCg3VVT5zJs3T6Ghoc7Fs5DOnz8vD4/iS4KtVqsKCwtL3Idpw012dnax/3I6evSokpKSVK1aNUVGRrqxMvcbMWKEFi1apI8//lgBAQE6deqUJCkoKEg2m83N1bnPuHHj1K1bN0VGRurcuXNatGiRNm3apLVr17q7NLcLCAi4ZE2Wv7+/QkJCbvi1WqNHj1ZCQoKioqL0448/6sUXX5TVatWAAQPcXZrbPfXUU2rXrp1efvll9e3bV9u3b9fs2bM1e/Zsd5dWKRQWFmrevHkaNGgQtw/4jYSEBE2ZMkWRkZGKi4vTnj17NH36dA0dOrTknRgm9cUXXxiSLnkNGjTI3aW53eW+F0nGvHnz3F2aWw0dOtSIiooyvL29jRo1ahh33nmnsW7dOneXVWnddtttxpNPPunuMtyuX79+Rnh4uOHt7W3UqlXL6Nevn3H48GF3l1VpfPLJJ0bjxo0NHx8fIzY21pg9e7a7S6o01q5da0gyDh486O5SKpWsrCzjySefNCIjIw1fX1/jpptuMl544QXDbreXuA+LYbhwyz8AAIBKjvvcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAKhUjh07JovFoqSkJHeXUm7y8vJUv359ffXVV+U2xqxZs5SQkFBu/QOVGeEGuA58/fXXslqtPH/mCgYPHqxevXq5u4wSmzVrlqKjo9WuXbtyG2Po0KHavXu3tmzZUm5jAJUV4Qa4DsydO1dPPPGENm/erB9//LFcxzIMQwUFBeU6xo3MMAy9/fbbGjZsWLmO4+3trb/85S966623ynUcoDIi3ACVXHZ2tpYuXar/+Z//Uffu3TV//nzne3/5y1/Ur1+/Yu3z8/NVvXp1vffee5KKHs6XmJio6Oho2Ww2NWvWTB9++KGz/aZNm2SxWLR69Wq1bNlSPj4+2rp1q44cOaKePXuqZs2aqlKlilq3bq0NGzYUGys9PV3du3eXzWZTdHS0Fi1apLp16+qNN95wtjl79qweeugh1ahRQ4GBgbrjjjuUnJxc4s/vcDg0bNgwZ/0xMTF68803ne+/9NJLWrBggT7++GNZLBZZLBZt2rRJkpSWlqa+ffsqODhY1apVU8+ePXXs2DHnsRdnfF599VWFh4crJCREI0aMUH5+vrON3W7Xc889pzp16sjHx0f169fX3LlzZRiG6tevr1dffbVYvUlJSbJYLMUe3Ptbu3bt0pEjR4rNwl08Fbds2TL9+c9/ls1mU+vWrZWSkqIdO3aoVatWqlKlirp166aff/652D+7P/3pT/L391dwcLDat2+v1NRU5/sJCQlatWqVLly4UOLvGzCF8nnsFYCyMnfuXKNVq1aGYRQ9hLBevXpGYWGhYRiG8emnnxo2m804d+6cs/0nn3xi2Gw2IysryzAMw5g8ebIRGxtrrFmzxjhy5Igxb948w8fHx9i0aZNhGP99yGzTpk2NdevWGYcPHzZ+/fVXIykpyZg1a5axb98+IyUlxfjrX/9q+Pr6Gqmpqc6x4uPjjVtuucX45ptvjF27dhm33XabYbPZjNdff71Ym4SEBGPHjh1GSkqK8cwzzxghISHGr7/+etnPe/ToUUOSsWfPHsMwDCMvL8+YMGGCsWPHDuOHH34wFi5caPj5+RlLly41DMMwzp07Z/Tt29fo2rWrkZ6ebqSnpxt2u93Iy8szGjVqZAwdOtTYu3evsX//fuMvf/mLERMT43wA36BBg4zAwEDj0UcfNQ4cOGB88sknhp+fX7GHO/bt29eoU6eO8dFHHxlHjhwxNmzYYCxZssQwDMOYMmWKcfPNNxerf+TIkUbHjh2v+M9z+vTpRmxs7GU/88V/Tvv37zduvfVWo2XLlkanTp2MrVu3Grt37zbq169vPProo4ZhGEZ+fr4RFBRkjB492jh8+LCxf/9+Y/78+cX++eTk5BgeHh7GF198ccV6ADMi3ACVXLt27Yw33njDMIyiH7Tq1as7f6wubr/33nvO9gMGDDD69etnGIZh5ObmGn5+fsZXX31VrM9hw4YZAwYMMAzjv+Fm5cqVV60lLi7OmDFjhmEYhnHgwAFDkrFjxw7n+4cOHTIkOcPNli1bjMDAQCM3N7dYP/Xq1TPeeeedy47x+3BzOSNGjDD69Onj3B40aJDRs2fPYm3ef/99IyYmxhkEDcMw7Ha7YbPZjLVr1zqPi4qKMgoKCpxt7r//fuf3d/DgQUOSsX79+svWcfLkScNqtRrbtm0zDKMoiFWvXt2YP3/+FWt/8sknjTvuuOOyn/ndd9917lu8eLEhydi4caNzX2JiohETE2MYhmH8+uuvhiRnSL2SqlWr/mE9gBlxWgqoxA4ePKjt27drwIABkiRPT0/169dPc+fOdW737dtXH3zwgSQpJydHH3/8sQYOHChJOnz4sM6fP6/OnTurSpUqztd7772nI0eOFBurVatWxbazs7M1evRoNWrUSMHBwapSpYoOHDig48ePO2vz9PRUixYtnMfUr19fVatWdW4nJycrOztbISEhxcY/evToJeP/kf/93/9Vy5YtVaNGDVWpUkWzZ8921nElycnJOnz4sAICApzjVqtWTbm5ucXGjouLk9VqdW6Hh4crIyNDUtEpJqvVqttuu+2yY0RERKh79+765z//KUn65JNPZLfbdf/991+xrgsXLsjX1/ey7zVt2tT5v2vWrClJatKkSbF9F2urVq2aBg8erC5duighIUFvvvmm0tPTL+nTZrPp/PnzV6wHMCNPdxcA4Mrmzp2rgoICRUREOPcZhiEfHx+9/fbbCgoK0sCBA3XbbbcpIyND69evl81mU9euXSUVBRRJ+ve//61atWoV69vHx6fYtr+/f7Ht0aNHa/369Xr11VdVv3592Ww23XfffcrLyytx/dnZ2QoPD3eugfmt4ODgEvWxZMkSjR49Wq+99pratm2rgIAA/f3vf9e2bduuOnbLli2dwe+3atSo4fzfXl5exd6zWCwqLCyUVBQMruahhx7SAw88oNdff13z5s1Tv3795Ofnd8X21atX1759+y773m9rsVgsl913sTZJmjdvnkaOHKk1a9Zo6dKl+utf/6r169fr1ltvdbY5ffp0sc8L3AgIN0AlVVBQoPfee0+vvfaa7rrrrmLv9erVS4sXL9ajjz6qdu3aqU6dOlq6dKlWr16t+++/3/mDePPNN8vHx0fHjx+/4uzDlfznP//R4MGD1bt3b0lFYeG3i3FjYmJUUFCgPXv2qGXLlpKKZorOnDnjbNOiRQudOnVKnp6eqlu3bim+haI62rVrp8cee8y57/ezPt7e3nI4HMX2tWjRQkuXLlVoaKgCAwNLNXaTJk1UWFioL7/8UvHx8Zdtc/fdd8vf318zZ87UmjVrtHnz5j/ss3nz5po5c6YMw3AGmGvRvHlzNW/eXOPGjVPbtm21aNEiZ7g5cuSIcnNz1bx582seB7iecFoKqKQ+/fRTnTlzRsOGDVPjxo2Lvfr06eM8NSUVXTU1a9YsrV+/3nlKSpICAgI0evRoPfXUU1qwYIGOHDmi3bt3a8aMGVqwYMEfjt+gQQN99NFHSkpKUnJysv7yl78UmzWIjY1VfHy8hg8fru3bt2vPnj0aPny4bDab80c7Pj5ebdu2Va9evbRu3TodO3ZMX331lV544QXt3LmzRN9DgwYNtHPnTq1du1YpKSkaP368duzYUaxN3bp1tXfvXh08eFC//PKL8vPzNXDgQFWvXl09e/bUli1bdPToUW3atEkjR47UiRMnSjR23bp1NWjQIA0dOlQrV6509rFs2TJnG6vVqsGDB2vcuHFq0KCB2rZt+4d93n777crOztZ3331Xohqu5OjRoxo3bpy+/vprpaamat26dTp06JAaNWrkbLNlyxbddNNNqlev3jWNBVxvCDdAJTV37lzFx8crKCjokvf69OmjnTt3au/evZKkgQMHav/+/apVq5bat29frO2kSZM0fvx4JSYmqlGjRuratav+/e9/Kzo6+g/Hnz59uqpWrap27dopISFBXbp0Kba+RpLee+891axZUx07dlTv3r318MMPKyAgwLmmxGKx6LPPPlPHjh01ZMgQNWzYUP3791dqaqpzTcnVPPLII7r33nvVr18/tWnTRr/++muxWRxJevjhhxUTE6NWrVqpRo0a+s9//iM/Pz9t3rxZkZGRuvfee9WoUSMNGzZMubm5Ls3kzJw5U/fdd58ee+wxxcbG6uGHH1ZOTk6xNsOGDVNeXp6GDBly1f5CQkLUu3fvy54uc4Wfn5++//579enTRw0bNtTw4cM1YsQIPfLII842ixcv1sMPP3xN4wDXI4thGIa7iwBgDidOnFCdOnW0YcMG3Xnnne4up8Js2bJFd955p9LS0koU2vbu3avOnTvryJEjqlKlSrnU9N133+mOO+5QSkrKZQMyYGaEGwCl9vnnnys7O1tNmjRRenq6nn32WZ08eVIpKSmXLNQ1I7vdrp9//lmDBg1SWFiYS7Mx8+fPV8uWLYtdDVWWNmzYIIfDoS5dupRL/0BlRrgBUGpr167VM888ox9++EEBAQFq166d3njjDUVFRbm7tAoxf/58DRs2TLfccotWrVp1yRVpANyDcAMAAEyFBcUAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBU/j+njsPsEAp3sgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(perf_metrics, current_optim_type):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        # Add a dashed circle around the current optimization type\n",
    "        if idx == current_optim_type:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
    "            alpha=0.5, s=df_opt[\"size_mb\"], label=idx, marker='$\\u25CC$')\n",
    "        else:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
    "            alpha=0.5, s=df_opt[\"size_mb\"], label=idx)\n",
    "\n",
    "    legend = plt.legend(bbox_to_anchor=(1,1))\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_sizes([20])\n",
    "\n",
    "    plt.ylim(80,90)\n",
    "    # Use the slowest model to define the x-axis range\n",
    "    xlim = int(perf_metrics[\"BERT-baseline\"][\"time_avg_ms\"] + 3)\n",
    "    plt.xlim(1, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency (ms)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65682a36-bd0f-4413-b8a0-6735991f865a",
   "metadata": {},
   "source": [
    "From the plot we can see that by using a smaller model we've managed to significantly decrease the average latency. And all this at the price of just 1% reduction in accuracy!\n",
    "\n",
    "Let's see if we can close that last gap by including the distillation loss of the teacher and finding good values for alpha and T.\n",
    "\n",
    "### Finding Good Hyperparameters with Optuna\n",
    "\n",
    "To find good values of alpha and T we could do a grid search over the 2D parameter space. But a much better alternative is to *Optuna*, which is an optimization framework designed for just this type of task.\n",
    "\n",
    "Optuna formulates the search problem in therms of an objesctive function that is oprimized though mutliple *trials*. We can dinf the minimum of $f(x,y)$ by defining an *objective()* function that returns the value of $f(x,y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94fe8edc-2cd8-4793-85c2-9f2987ff410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -2, 2) # suggest_float specifies the parameter ranges to sample uniformly from\n",
    "    y = trial.suggest_float(\"y\", -2, 2)\n",
    "    return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "142af8c3-e50b-4a27-9360-d7d5017d9759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 13:59:45,603] A new study created in memory with name: no-name-b95f7f30-6e1c-4761-b127-3876be165693\n",
      "[I 2025-06-17 13:59:45,604] Trial 0 finished with value: 88.0855368235617 and parameters: {'x': -0.7494109551075359, 'y': -0.3604737697888436}. Best is trial 0 with value: 88.0855368235617.\n",
      "[I 2025-06-17 13:59:45,605] Trial 1 finished with value: 21.44088564258775 and parameters: {'x': -1.4811197953412933, 'y': 1.8027563847319894}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,606] Trial 2 finished with value: 108.95132171920034 and parameters: {'x': 1.2962200083306938, 'y': 0.6368092188841961}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,607] Trial 3 finished with value: 119.76123880263073 and parameters: {'x': -0.696539327512947, 'y': -0.5959573480479969}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,608] Trial 4 finished with value: 1781.3049791835833 and parameters: {'x': -1.6959067386317157, 'y': -1.3358322730574552}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,608] Trial 5 finished with value: 55.04394885476037 and parameters: {'x': 0.4816564969103596, 'y': -0.5081101798174825}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,609] Trial 6 finished with value: 51.04953992366369 and parameters: {'x': -0.29876190298609284, 'y': 0.7918450212768828}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,610] Trial 7 finished with value: 1540.6650599947993 and parameters: {'x': 1.78500178441428, 'y': -0.738114221189714}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,610] Trial 8 finished with value: 75.53233789771167 and parameters: {'x': 0.20947076509536355, 'y': 0.9093686219823542}. Best is trial 1 with value: 21.44088564258775.\n",
      "[I 2025-06-17 13:59:45,611] Trial 9 finished with value: 2.42898722788051 and parameters: {'x': 0.36322051018435175, 'y': 0.27417888802470847}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,619] Trial 10 finished with value: 667.2119098134661 and parameters: {'x': 0.7706146832681189, 'y': -1.9890956964616784}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,624] Trial 11 finished with value: 348.95053213330607 and parameters: {'x': -1.954144987394896, 'y': 1.974167629038322}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,629] Trial 12 finished with value: 83.54680248944649 and parameters: {'x': -1.044057769476464, 'y': 1.9809473618662579}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,634] Trial 13 finished with value: 27.314143284294204 and parameters: {'x': -1.3286667859753933, 'y': 1.297472384176424}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,639] Trial 14 finished with value: 6.424074804103393 and parameters: {'x': -0.14483251289312854, 'y': 0.24710547574972197}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,644] Trial 15 finished with value: 5.323355584982559 and parameters: {'x': -0.17524837449742403, 'y': 0.22926039601175469}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,649] Trial 16 finished with value: 47.443861807493626 and parameters: {'x': 0.9278243759702771, 'y': 0.17210084047360602}. Best is trial 9 with value: 2.42898722788051.\n",
      "[I 2025-06-17 13:59:45,654] Trial 17 finished with value: 1.54556242584871 and parameters: {'x': 0.11004383092920089, 'y': -0.07469706256029923}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,659] Trial 18 finished with value: 214.18245517301898 and parameters: {'x': 0.4642969061790875, 'y': -1.2469449721117396}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,665] Trial 19 finished with value: 10.91048320468706 and parameters: {'x': 1.2769003670725776, 'y': 1.3013270213661294}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,670] Trial 20 finished with value: 1574.6275295839932 and parameters: {'x': 1.9504722946556012, 'y': -0.16267702612251622}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,675] Trial 21 finished with value: 13.995550282712943 and parameters: {'x': 0.14218703744256572, 'y': 0.38435596236936387}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,680] Trial 22 finished with value: 10.54263225778185 and parameters: {'x': -0.4327169116123041, 'y': -0.104131339466141}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,686] Trial 23 finished with value: 26.927023848056205 and parameters: {'x': 0.0369912595463924, 'y': 0.5112667550636751}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,691] Trial 24 finished with value: 163.487486729887 and parameters: {'x': 0.4857870002746508, 'y': -1.041598841436639}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,697] Trial 25 finished with value: 7.167272633039833 and parameters: {'x': -0.49425750527457657, 'y': 0.022153876230385283}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,706] Trial 26 finished with value: 17.22738825942553 and parameters: {'x': 0.8116691938579115, 'y': 1.0734382800202396}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,713] Trial 27 finished with value: 83.19105993376816 and parameters: {'x': -0.13456568200956284, 'y': -0.886899373588012}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,718] Trial 28 finished with value: 77.45507371846001 and parameters: {'x': -0.8610588516138249, 'y': -0.11876096980645476}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,724] Trial 29 finished with value: 19.494074973595385 and parameters: {'x': 0.30006133449172584, 'y': -0.34590081537094935}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,729] Trial 30 finished with value: 366.8705660764124 and parameters: {'x': 1.247760596785084, 'y': -0.35831980026875576}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,734] Trial 31 finished with value: 8.832400053616887 and parameters: {'x': -0.16114043413523868, 'y': 0.2995380389706407}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,740] Trial 32 finished with value: 6.175433136689231 and parameters: {'x': -0.5939354624081852, 'y': 0.1621077434689407}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,745] Trial 33 finished with value: 6.583259438200493 and parameters: {'x': -0.6049966858691761, 'y': 0.5662020348832195}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,750] Trial 34 finished with value: 69.75883590236258 and parameters: {'x': -0.9835813898401926, 'y': 0.15611095436907238}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,756] Trial 35 finished with value: 123.33603699143613 and parameters: {'x': -1.3649220149117798, 'y': 0.7779168074976243}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,761] Trial 36 finished with value: 19.676313243578406 and parameters: {'x': -0.3466094286728335, 'y': -0.30250781118936093}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,767] Trial 37 finished with value: 84.39670667390733 and parameters: {'x': 0.5975080275165751, 'y': -0.5607788339063796}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,772] Trial 38 finished with value: 23.439854689772027 and parameters: {'x': -0.7176612517757867, 'y': 0.06238444394649706}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,777] Trial 39 finished with value: 13.248414849909542 and parameters: {'x': 0.27438807772594315, 'y': 0.4319665735576187}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,783] Trial 40 finished with value: 120.06059217492903 and parameters: {'x': 0.040189670177032844, 'y': 1.0931249727413082}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,788] Trial 41 finished with value: 5.111190505570287 and parameters: {'x': -0.21396939760820372, 'y': 0.23650439658539557}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,794] Trial 42 finished with value: 41.12034871400432 and parameters: {'x': -0.2378919824192281, 'y': 0.6857823294325966}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,799] Trial 43 finished with value: 9.945340124105758 and parameters: {'x': -0.5177516121268907, 'y': -0.00837078672227029}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,805] Trial 44 finished with value: 12.243352520808678 and parameters: {'x': -0.028604334543121362, 'y': 0.33526290657862434}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,810] Trial 45 finished with value: 220.4594415307611 and parameters: {'x': -0.8464582235654434, 'y': -0.7567702772023887}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,816] Trial 46 finished with value: 18.27854709021114 and parameters: {'x': -1.136840061108096, 'y': 0.9221019132211805}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,821] Trial 47 finished with value: 12.066373139913773 and parameters: {'x': 0.34403780774845955, 'y': -0.22275507439536352}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,827] Trial 48 finished with value: 804.6968415361026 and parameters: {'x': 0.969027609562196, 'y': -1.897701695982878}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,833] Trial 49 finished with value: 154.92295196914114 and parameters: {'x': 0.6219864962949833, 'y': 1.6309735385082105}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,843] Trial 50 finished with value: 36.6109598839331 and parameters: {'x': -0.345269731814947, 'y': -0.4707143095596372}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,850] Trial 51 finished with value: 5.978659913263931 and parameters: {'x': -0.09547393099899948, 'y': 0.22771528933584312}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,856] Trial 52 finished with value: 2.184739239474088 and parameters: {'x': 0.12309159427408123, 'y': 0.1341377115186249}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,861] Trial 53 finished with value: 27.538477221176592 and parameters: {'x': 0.14766110025781082, 'y': 0.5396068096086966}. Best is trial 17 with value: 1.54556242584871.\n",
      "[I 2025-06-17 13:59:45,871] Trial 54 finished with value: 0.9991546653546867 and parameters: {'x': 0.0068129458844108925, 'y': -0.011238148842797169}. Best is trial 54 with value: 0.9991546653546867.\n",
      "[I 2025-06-17 13:59:45,878] Trial 55 finished with value: 0.801560339909226 and parameters: {'x': 0.12747981743140596, 'y': 0.03631820900473104}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,884] Trial 56 finished with value: 2.949908339272092 and parameters: {'x': 0.41220086464056094, 'y': 0.008528001332483326}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,889] Trial 57 finished with value: 6.213846481068994 and parameters: {'x': 0.407091939616455, 'y': -0.07639815733749522}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,895] Trial 58 finished with value: 6.167294951375964 and parameters: {'x': 0.1358753941762126, 'y': -0.214359345704547}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,901] Trial 59 finished with value: 14.859300014808008 and parameters: {'x': 0.6600428677157726, 'y': 0.051680947851717784}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,907] Trial 60 finished with value: 206.387181685265 and parameters: {'x': 0.8747045820267159, 'y': -0.6714554421789103}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,912] Trial 61 finished with value: 1.5117523098095953 and parameters: {'x': 0.09420448929371228, 'y': 0.09201814476719361}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,918] Trial 62 finished with value: 46.924830395459026 and parameters: {'x': 0.5043027596777881, 'y': -0.42889988141628566}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,924] Trial 63 finished with value: 52.05733601531655 and parameters: {'x': 1.0588432886302508, 'y': 0.3996654060925493}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,929] Trial 64 finished with value: 0.8195903349884126 and parameters: {'x': 0.18688568851091522, 'y': 0.07473021156002448}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,935] Trial 65 finished with value: 5.125538073849654 and parameters: {'x': 0.03863306401757563, 'y': -0.20347850110204985}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,940] Trial 66 finished with value: 41.0553761311743 and parameters: {'x': 0.10349731434673781, 'y': 0.6451536462348724}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,946] Trial 67 finished with value: 16.605753813536502 and parameters: {'x': 0.7265074562266037, 'y': 0.12123030465647085}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,952] Trial 68 finished with value: 15.120342954095062 and parameters: {'x': 0.18905376870070753, 'y': 0.4160400148628363}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,957] Trial 69 finished with value: 1.5666570207810584 and parameters: {'x': -0.011012343047828055, 'y': -0.07366972117818327}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,963] Trial 70 finished with value: 7.714688641542853 and parameters: {'x': -0.011994425405353636, 'y': -0.25851722330478866}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,968] Trial 71 finished with value: 2.3114538285247965 and parameters: {'x': 0.23122404415535883, 'y': -0.07770088495722843}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,974] Trial 72 finished with value: 2.8653527385228497 and parameters: {'x': 0.25915997147214964, 'y': -0.08503692359481273}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,979] Trial 73 finished with value: 1.5846529727154404 and parameters: {'x': -0.03876797128799933, 'y': -0.06960358942738297}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,985] Trial 74 finished with value: 24.96407982931401 and parameters: {'x': -0.055117956433735654, 'y': -0.485334879978861}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,990] Trial 75 finished with value: 1.6996255993683782 and parameters: {'x': -0.30233317051955566, 'y': 0.09736681589305125}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:45,996] Trial 76 finished with value: 37.43672786240898 and parameters: {'x': -0.4771965374251623, 'y': -0.36603946044739905}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,001] Trial 77 finished with value: 2.1509341623574367 and parameters: {'x': -0.28776583864186567, 'y': 0.012624186104370404}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,007] Trial 78 finished with value: 3.4717518957842177 and parameters: {'x': -0.39867223318519146, 'y': 0.2820438906183286}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,012] Trial 79 finished with value: 40.95639259963225 and parameters: {'x': -0.13941891621786875, 'y': -0.6103092763369007}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,018] Trial 80 finished with value: 724.4406571645542 and parameters: {'x': 1.5488483146769392, 'y': -0.2920527752425014}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,023] Trial 81 finished with value: 1.8062737237635433 and parameters: {'x': -0.26379032552280113, 'y': 0.023857036409147464}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,032] Trial 82 finished with value: 5.701692143511838 and parameters: {'x': -0.2456017732720565, 'y': -0.14339938917765066}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,040] Trial 83 finished with value: 2.4187743188844117 and parameters: {'x': -0.07365057541657669, 'y': 0.11794323949593737}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,045] Trial 84 finished with value: 20.42926786427956 and parameters: {'x': -0.6174031612253814, 'y': -0.0408710917786993}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,051] Trial 85 finished with value: 25.56921222050447 and parameters: {'x': 0.03424694234418431, 'y': 0.49752487785818245}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,056] Trial 86 finished with value: 6.431453395822713 and parameters: {'x': -0.17565578306611765, 'y': 0.25556113729641666}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,062] Trial 87 finished with value: 9.10082543336227 and parameters: {'x': -0.33787099859770264, 'y': -0.15623044067758324}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,067] Trial 88 finished with value: 5.009345325050045 and parameters: {'x': 0.5345514170998783, 'y': 0.06682278967000584}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,073] Trial 89 finished with value: 7.2306879273883595 and parameters: {'x': 0.310502101818233, 'y': 0.35632078122968086}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,078] Trial 90 finished with value: 2.062080590813591 and parameters: {'x': -0.43365408852261667, 'y': 0.17986041531639635}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,084] Trial 91 finished with value: 3.6201344517106504 and parameters: {'x': 0.07755660074128631, 'y': 0.17242514100135575}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,089] Trial 92 finished with value: 22.58605003035141 and parameters: {'x': -0.27985459553335795, 'y': -0.37937149968736533}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,095] Trial 93 finished with value: 6.444560346468888 and parameters: {'x': -0.4323106474514925, 'y': -0.022703461972974362}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,100] Trial 94 finished with value: 5.743293054428973 and parameters: {'x': -0.09713053092817697, 'y': 0.22249765580471828}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,106] Trial 95 finished with value: 866.9121893933294 and parameters: {'x': -1.729492765572874, 'y': 0.059486892331189686}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,111] Trial 96 finished with value: 23.935273623252503 and parameters: {'x': -0.5663371650804194, 'y': -0.14274750656955}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,117] Trial 97 finished with value: 18.61924586197467 and parameters: {'x': 0.35920333971551927, 'y': -0.2976886213608101}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,122] Trial 98 finished with value: 4.477460731009184 and parameters: {'x': -0.667615244099881, 'y': 0.3154595813857724}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,128] Trial 99 finished with value: 25.671008122460176 and parameters: {'x': -0.769107971033208, 'y': 0.11675064889013986}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,133] Trial 100 finished with value: 6.7561905894965 and parameters: {'x': 0.18813007622140815, 'y': -0.21152928517484543}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,139] Trial 101 finished with value: 2.1557032848349893 and parameters: {'x': -0.28366681102680297, 'y': 0.009199559806206452}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,144] Trial 102 finished with value: 1.5009702296598284 and parameters: {'x': -0.2117713495082561, 'y': 0.026797055671847106}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,150] Trial 103 finished with value: 4.302778180108045 and parameters: {'x': -0.011463385042901038, 'y': 0.181231381610378}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,156] Trial 104 finished with value: 21.98823810799307 and parameters: {'x': -0.19007846973684386, 'y': 0.4896929552563385}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,164] Trial 105 finished with value: 2.2453855290677627 and parameters: {'x': 0.23335883314742725, 'y': -0.07429328995678436}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,172] Trial 106 finished with value: 2.081521698739267 and parameters: {'x': -0.37031275092328875, 'y': 0.0919912340516075}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,178] Trial 107 finished with value: 10.139590622446821 and parameters: {'x': 0.08811221916243604, 'y': 0.31285475447169947}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,184] Trial 108 finished with value: 16.18777920647654 and parameters: {'x': -0.4862550763726523, 'y': -0.1374386701909729}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,189] Trial 109 finished with value: 1.3348202964862483 and parameters: {'x': -0.1056405633793486, 'y': -0.022363084523508214}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,195] Trial 110 finished with value: 18.82915882709398 and parameters: {'x': -0.05035891656374403, 'y': -0.4184854157165636}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,200] Trial 111 finished with value: 1.4944366165046825 and parameters: {'x': -0.15384615197091092, 'y': -0.0167139907207885}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,206] Trial 112 finished with value: 1.5786919363279124 and parameters: {'x': -0.1376004169600647, 'y': -0.03441003096433432}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,212] Trial 113 finished with value: 7.994866225071649 and parameters: {'x': -0.12701872946222026, 'y': -0.2431864114331748}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,217] Trial 114 finished with value: 1.3689109369021597 and parameters: {'x': 0.0009362522661293671, 'y': -0.06089104119309438}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,223] Trial 115 finished with value: 1.404319338481826 and parameters: {'x': 0.1609906942501267, 'y': -0.057770867987494444}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,228] Trial 116 finished with value: 10.849258903760262 and parameters: {'x': 0.4095249611013174, 'y': -0.15633557040410836}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,234] Trial 117 finished with value: 13.896203480329493 and parameters: {'x': 0.177091039597182, 'y': -0.3322185255516501}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,240] Trial 118 finished with value: 1.3336358201298546 and parameters: {'x': 0.04563098129039929, 'y': -0.06294208564983125}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,245] Trial 119 finished with value: 8.77347437839714 and parameters: {'x': 0.28870568867347446, 'y': -0.2041822369931434}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,251] Trial 120 finished with value: 28.874924641739124 and parameters: {'x': 0.04317199008473668, 'y': -0.526902713776537}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,259] Trial 121 finished with value: 1.1218149622808138 and parameters: {'x': 0.13645246501664332, 'y': -0.04270776752938186}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,268] Trial 122 finished with value: 1.9113216658147767 and parameters: {'x': 0.14962700499776152, 'y': -0.08661577008994648}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,274] Trial 123 finished with value: 0.8717293878055372 and parameters: {'x': 0.07322982630965791, 'y': 0.016687991765422787}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,279] Trial 124 finished with value: 0.8416218536013141 and parameters: {'x': 0.08444942502452471, 'y': 0.012953215726558814}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,289] Trial 125 finished with value: 0.9322041558255656 and parameters: {'x': 0.08652205557268326, 'y': 0.03875301364428018}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,297] Trial 126 finished with value: 3.6108198083740484 and parameters: {'x': 0.22689490687798242, 'y': 0.22506494786358652}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,302] Trial 127 finished with value: 0.964654616560666 and parameters: {'x': 0.04395995052784451, 'y': 0.024436263679797135}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,308] Trial 128 finished with value: 25.771551095167812 and parameters: {'x': 0.47911436360506465, 'y': -0.2754269434033129}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,317] Trial 129 finished with value: 2.000482127323684 and parameters: {'x': 0.33766667253224514, 'y': -0.010953082720534003}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,325] Trial 130 finished with value: 2.9131952135594448 and parameters: {'x': 0.04171289246402815, 'y': 0.14298022287021472}. Best is trial 55 with value: 0.801560339909226.\n",
      "[I 2025-06-17 13:59:46,331] Trial 131 finished with value: 0.762864716697181 and parameters: {'x': 0.12680349563768714, 'y': 0.01806049337408211}. Best is trial 131 with value: 0.762864716697181.\n",
      "[I 2025-06-17 13:59:46,336] Trial 132 finished with value: 4.01868010679112 and parameters: {'x': 0.12624628287705134, 'y': -0.16448456167894088}. Best is trial 131 with value: 0.762864716697181.\n",
      "[I 2025-06-17 13:59:46,342] Trial 133 finished with value: 0.678812387498537 and parameters: {'x': 0.19608972861972898, 'y': 0.056490212427889826}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,348] Trial 134 finished with value: 3.7331377694532883 and parameters: {'x': 0.2594132820168613, 'y': 0.24575166244432323}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,354] Trial 135 finished with value: 0.8907508415276867 and parameters: {'x': 0.4042492832491383, 'y': 0.09021694168304188}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,359] Trial 136 finished with value: 8.175709885688038 and parameters: {'x': 0.32742761848248203, 'y': 0.385118116102814}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,365] Trial 137 finished with value: 354.78489868804263 and parameters: {'x': 0.5507664998927405, 'y': -1.5796939360119788}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,371] Trial 138 finished with value: 2.1130720177046656 and parameters: {'x': 0.45515990976373805, 'y': 0.07240328876212448}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,377] Trial 139 finished with value: 2.1222136209228757 and parameters: {'x': 0.002404170487673017, 'y': 0.10616679839287316}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,382] Trial 140 finished with value: 3.0950509081697173 and parameters: {'x': 0.07340097926749237, 'y': 0.1549358619857138}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,388] Trial 141 finished with value: 2.448520247081924 and parameters: {'x': 0.16766806518114638, 'y': -0.10439190276192176}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,394] Trial 142 finished with value: 1.5215028475356003 and parameters: {'x': 0.3932401286168976, 'y': 0.04724388337695734}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,400] Trial 143 finished with value: 1.2797638389373123 and parameters: {'x': -0.05076064784482154, 'y': -0.03933587264624252}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,405] Trial 144 finished with value: 5.6615394522759805 and parameters: {'x': -0.05807672427675466, 'y': 0.21649289787484063}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,411] Trial 145 finished with value: 7.369274045424818 and parameters: {'x': 0.24707349739006182, 'y': -0.19976833160513008}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,417] Trial 146 finished with value: 0.8969074767091613 and parameters: {'x': 0.07506750101716259, 'y': 0.025983925504911104}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,423] Trial 147 finished with value: 9.194562322167759 and parameters: {'x': -0.0927414430274435, 'y': 0.2914521456759027}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,429] Trial 148 finished with value: 0.9831485183839672 and parameters: {'x': 0.08025212302829726, 'y': 0.04348259017168159}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,435] Trial 149 finished with value: 1.2022470459168368 and parameters: {'x': 0.08750012406440555, 'y': 0.06845026996229478}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,440] Trial 150 finished with value: 3.4546312988398524 and parameters: {'x': 0.10292149673467978, 'y': 0.17337739941624167}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,446] Trial 151 finished with value: 0.7656833576134084 and parameters: {'x': 0.2916557310109776, 'y': 0.03368877670617304}. Best is trial 133 with value: 0.678812387498537.\n",
      "[I 2025-06-17 13:59:46,451] Trial 152 finished with value: 0.6349075257422749 and parameters: {'x': 0.2991345642065038, 'y': 0.051574342180230805}. Best is trial 152 with value: 0.6349075257422749.\n",
      "[I 2025-06-17 13:59:46,460] Trial 153 finished with value: 0.5497961574425538 and parameters: {'x': 0.31245779890715675, 'y': 0.06986625256657159}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,468] Trial 154 finished with value: 0.7848289349213297 and parameters: {'x': 0.3385505186705021, 'y': 0.05568314235032416}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,474] Trial 155 finished with value: 3.358542841901497 and parameters: {'x': 0.40660603441631205, 'y': 0.3387189641810711}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,479] Trial 156 finished with value: 7.968763001503516 and parameters: {'x': 0.6350150817404767, 'y': 0.1233236472694855}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,485] Trial 157 finished with value: 0.6606142017950323 and parameters: {'x': 0.3193229800019936, 'y': 0.057549489318983606}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,490] Trial 158 finished with value: 2.4753067874115664 and parameters: {'x': 0.31997534193316995, 'y': 0.24425998382495756}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,496] Trial 159 finished with value: 2.412160358615116 and parameters: {'x': 0.551971225840479, 'y': 0.45338102932748625}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,501] Trial 160 finished with value: 2.7739692378869223 and parameters: {'x': 0.4578283042677392, 'y': 0.052125992594076825}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,507] Trial 161 finished with value: 1.4145103329984814 and parameters: {'x': 0.2559409600005226, 'y': 0.1582897433406932}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,512] Trial 162 finished with value: 0.6773109147727333 and parameters: {'x': 0.21142772441144325, 'y': 0.021150741915762848}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,518] Trial 163 finished with value: 0.9412945436427156 and parameters: {'x': 0.33841927346359124, 'y': 0.04356243813182645}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,523] Trial 164 finished with value: 6.780666966762012 and parameters: {'x': 0.36339738231375457, 'y': -0.12043796771569175}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,529] Trial 165 finished with value: 0.8555197469392732 and parameters: {'x': 0.22202213478239125, 'y': 0.09932083985418025}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,534] Trial 166 finished with value: 2.365874109864562 and parameters: {'x': 0.22404264086012382, 'y': 0.18300189265151165}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,540] Trial 167 finished with value: 4.574317449664903 and parameters: {'x': 0.7114014270594731, 'y': 0.2941715262532276}. Best is trial 153 with value: 0.5497961574425538.\n",
      "[I 2025-06-17 13:59:46,546] Trial 168 finished with value: 0.48486436496642277 and parameters: {'x': 0.32375045913898015, 'y': 0.08821588894394977}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,551] Trial 169 finished with value: 1.2489473680134693 and parameters: {'x': 0.4619144183243011, 'y': 0.11541538800875113}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,557] Trial 170 finished with value: 1.2327180019726813 and parameters: {'x': 0.28686793796969207, 'y': 0.16739084388876793}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,562] Trial 171 finished with value: 0.6153239259375521 and parameters: {'x': 0.31618732132929184, 'y': 0.06153952312871071}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,568] Trial 172 finished with value: 1.003037635256518 and parameters: {'x': 0.2021019563490393, 'y': 0.10137588283081488}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,573] Trial 173 finished with value: 0.8746972051880886 and parameters: {'x': 0.38425424293803084, 'y': 0.21804694579628342}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,579] Trial 174 finished with value: 0.6188858533450539 and parameters: {'x': 0.5453885909960092, 'y': 0.2332447962935432}. Best is trial 168 with value: 0.48486436496642277.\n",
      "[I 2025-06-17 13:59:46,585] Trial 175 finished with value: 0.3294032976248222 and parameters: {'x': 0.5939322258860973, 'y': 0.39331559994820475}. Best is trial 175 with value: 0.3294032976248222.\n",
      "[I 2025-06-17 13:59:46,590] Trial 176 finished with value: 0.4362725878713797 and parameters: {'x': 0.5903973360290167, 'y': 0.40038583072802947}. Best is trial 175 with value: 0.3294032976248222.\n",
      "[I 2025-06-17 13:59:46,596] Trial 177 finished with value: 0.21925169903409608 and parameters: {'x': 0.5524411460426184, 'y': 0.3189544938984783}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,602] Trial 178 finished with value: 1.679722929349163 and parameters: {'x': 0.7617034815545085, 'y': 0.7075867658569868}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,607] Trial 179 finished with value: 0.2343688126885766 and parameters: {'x': 0.5770071842546476, 'y': 0.3564842417614776}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,613] Trial 180 finished with value: 2.4823375532016034 and parameters: {'x': 0.6665479346816179, 'y': 0.5982714496091299}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,619] Trial 181 finished with value: 0.7089679121721595 and parameters: {'x': 0.5977678703404069, 'y': 0.4312978554876308}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,625] Trial 182 finished with value: 2.7282655354279552 and parameters: {'x': 0.8434356048332563, 'y': 0.5469526879335965}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,630] Trial 183 finished with value: 0.6883407029030535 and parameters: {'x': 0.6007236139920324, 'y': 0.43359568286535444}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,636] Trial 184 finished with value: 3.7466585227406575 and parameters: {'x': 0.5671261340433318, 'y': 0.5102925602072745}. Best is trial 177 with value: 0.21925169903409608.\n",
      "[I 2025-06-17 13:59:46,642] Trial 185 finished with value: 0.21129104871968385 and parameters: {'x': 0.6260684060535706, 'y': 0.41869481418501375}. Best is trial 185 with value: 0.21129104871968385.\n",
      "[I 2025-06-17 13:59:46,648] Trial 186 finished with value: 0.1446578297416649 and parameters: {'x': 0.6202504995617905, 'y': 0.3868276296755199}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,654] Trial 187 finished with value: 0.2858509691216995 and parameters: {'x': 0.6182791868720015, 'y': 0.3448338500691731}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,659] Trial 188 finished with value: 0.18577394402005284 and parameters: {'x': 0.6213155906295712, 'y': 0.40661753840646686}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,665] Trial 189 finished with value: 0.18313561205484663 and parameters: {'x': 0.625867523902869, 'y': 0.41248526334469715}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,671] Trial 190 finished with value: 21.89187619108612 and parameters: {'x': 0.9441906768696107, 'y': 0.4236417673352957}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,676] Trial 191 finished with value: 1.4071155862384157 and parameters: {'x': 0.7047200054756998, 'y': 0.381742283651262}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,682] Trial 192 finished with value: 0.9994277835723941 and parameters: {'x': 0.5958713734387014, 'y': 0.4465016261340802}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,687] Trial 193 finished with value: 6.273783232650119 and parameters: {'x': 0.6433092611349255, 'y': 0.6617692721618981}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,693] Trial 194 finished with value: 0.1489366239783757 and parameters: {'x': 0.7722327980757441, 'y': 0.565189245001708}. Best is trial 186 with value: 0.1446578297416649.\n",
      "[I 2025-06-17 13:59:46,699] Trial 195 finished with value: 0.059929121588932426 and parameters: {'x': 0.7560473228372219, 'y': 0.5695674247311805}. Best is trial 195 with value: 0.059929121588932426.\n",
      "[I 2025-06-17 13:59:46,705] Trial 196 finished with value: 0.7037298419012937 and parameters: {'x': 0.8333118207588041, 'y': 0.7766244584766725}. Best is trial 195 with value: 0.059929121588932426.\n",
      "[I 2025-06-17 13:59:46,710] Trial 197 finished with value: 0.6188662926585355 and parameters: {'x': 0.7978008157714556, 'y': 0.5604610285213273}. Best is trial 195 with value: 0.059929121588932426.\n",
      "[I 2025-06-17 13:59:46,716] Trial 198 finished with value: 35.699902362275665 and parameters: {'x': 1.059896435131525, 'y': 0.5259165230854306}. Best is trial 195 with value: 0.059929121588932426.\n",
      "[I 2025-06-17 13:59:46,722] Trial 199 finished with value: 0.05483067559229583 and parameters: {'x': 0.7757519061028789, 'y': 0.6085315450063908}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,728] Trial 200 finished with value: 0.7901235535591739 and parameters: {'x': 0.8876207921339763, 'y': 0.876046317334346}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,734] Trial 201 finished with value: 0.07957933999138819 and parameters: {'x': 0.7761071126841566, 'y': 0.6195036357927436}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,739] Trial 202 finished with value: 0.10257431694868319 and parameters: {'x': 0.7861577849740904, 'y': 0.5942017005717927}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,745] Trial 203 finished with value: 0.05957483092362638 and parameters: {'x': 0.7837269116803074, 'y': 0.625541926269076}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,751] Trial 204 finished with value: 0.468883654589716 and parameters: {'x': 0.7710883520139589, 'y': 0.6591127493992958}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,757] Trial 205 finished with value: 0.31057715180902257 and parameters: {'x': 0.7520201173764025, 'y': 0.6154424856814824}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,763] Trial 206 finished with value: 24.811756435243844 and parameters: {'x': 1.054157146063452, 'y': 0.6131627230982308}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,769] Trial 207 finished with value: 1.6763867270648927 and parameters: {'x': 0.7876695687857119, 'y': 0.7481458031787314}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,775] Trial 208 finished with value: 0.9341825910878402 and parameters: {'x': 0.7565631905946288, 'y': 0.6659250791380238}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,781] Trial 209 finished with value: 0.23763044082182433 and parameters: {'x': 0.7113914085700853, 'y': 0.5453632961012049}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,787] Trial 210 finished with value: 11.350315200406826 and parameters: {'x': 0.6969396195886645, 'y': 0.8212612636581307}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,793] Trial 211 finished with value: 16.400315929264544 and parameters: {'x': 0.9859623039766081, 'y': 0.5671510625673997}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,799] Trial 212 finished with value: 0.13212246279775913 and parameters: {'x': 0.8112245502086958, 'y': 0.6270230281293521}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,805] Trial 213 finished with value: 2.0093745457052163 and parameters: {'x': 0.8774355530813441, 'y': 0.6286716039317646}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,811] Trial 214 finished with value: 0.414897898310523 and parameters: {'x': 0.7341433210566604, 'y': 0.4802963106389926}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,816] Trial 215 finished with value: 19.6038688195461 and parameters: {'x': 0.7332669822568642, 'y': 0.9796388625587734}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,822] Trial 216 finished with value: 5.837050232044642 and parameters: {'x': 0.6800979380831977, 'y': 0.7020058113930117}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,828] Trial 217 finished with value: 2.8883789909685342 and parameters: {'x': 0.8178131867692723, 'y': 0.49984542374747726}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,838] Trial 218 finished with value: 11.924642638339341 and parameters: {'x': 0.9748924371224919, 'y': 0.6051036329841496}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,846] Trial 219 finished with value: 1.1263774361616428 and parameters: {'x': 0.7567039301491134, 'y': 0.46929621755355033}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,852] Trial 220 finished with value: 0.3375567265301504 and parameters: {'x': 0.6553463954694827, 'y': 0.38270597646400517}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,858] Trial 221 finished with value: 0.8565450117040913 and parameters: {'x': 0.6549859848231387, 'y': 0.34312821805188726}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,863] Trial 222 finished with value: 3.440595038153159 and parameters: {'x': 0.8529673749129136, 'y': 0.5426485983969694}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,869] Trial 223 finished with value: 1.3567921436699812 and parameters: {'x': 0.5133799331375702, 'y': 0.3693886800320545}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,875] Trial 224 finished with value: 6.592034630712225 and parameters: {'x': 0.6878648965110501, 'y': 0.7280032905736377}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,881] Trial 225 finished with value: 0.139086365956787 and parameters: {'x': 0.7687895036921244, 'y': 0.6202995757370812}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,887] Trial 226 finished with value: 0.05654230368779919 and parameters: {'x': 0.7791668705405593, 'y': 0.6159186266898667}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,893] Trial 227 finished with value: 3.9992096902555505 and parameters: {'x': 0.9092374506630718, 'y': 0.6269385729403327}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,899] Trial 228 finished with value: 3.8704745885909833 and parameters: {'x': 0.779673423165617, 'y': 0.8033882372652376}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,906] Trial 229 finished with value: 1.402499938576214 and parameters: {'x': 0.6209539340736971, 'y': 0.4977811152365886}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,912] Trial 230 finished with value: 3.049375206773906 and parameters: {'x': 0.7190958795910192, 'y': 0.6894493433395326}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,918] Trial 231 finished with value: 0.5199310211290463 and parameters: {'x': 0.8024491416049908, 'y': 0.5745773336771018}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,924] Trial 232 finished with value: 0.15142706068846085 and parameters: {'x': 0.6227361095798963, 'y': 0.3973391392960166}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,930] Trial 233 finished with value: 0.142963233522217 and parameters: {'x': 0.6251129046831021, 'y': 0.395688439089302}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,936] Trial 234 finished with value: 0.1413949333426515 and parameters: {'x': 0.6244075381426137, 'y': 0.39168820358415707}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,942] Trial 235 finished with value: 0.29615542649575577 and parameters: {'x': 0.6536234673947963, 'y': 0.4691972865006951}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,948] Trial 236 finished with value: 1.2443977267117108 and parameters: {'x': 0.5341645920773611, 'y': 0.3866923115974965}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,954] Trial 237 finished with value: 0.690966915083578 and parameters: {'x': 0.6452528865319225, 'y': 0.3411767306738863}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,960] Trial 238 finished with value: 1.0159177209153576 and parameters: {'x': 0.668663777388248, 'y': 0.542302319697986}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,966] Trial 239 finished with value: 11.364399635941902 and parameters: {'x': 0.8996445850208342, 'y': 0.4723985354249987}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,973] Trial 240 finished with value: 6.569283109036496 and parameters: {'x': 0.5896777805143628, 'y': 0.6007202560817343}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,979] Trial 241 finished with value: 0.27443785311038754 and parameters: {'x': 0.7178898132841267, 'y': 0.4712237750391025}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,985] Trial 242 finished with value: 0.44284173094292634 and parameters: {'x': 0.7033659811214984, 'y': 0.43515441686753153}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,991] Trial 243 finished with value: 0.5972250450335549 and parameters: {'x': 0.5026121644016525, 'y': 0.31176544890172103}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:46,997] Trial 244 finished with value: 2.4674448873933117 and parameters: {'x': 0.8162619760151265, 'y': 0.510280881911539}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,003] Trial 245 finished with value: 0.14123160403665624 and parameters: {'x': 0.624269129687969, 'y': 0.3889509132254564}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,009] Trial 246 finished with value: 5.202619270385453 and parameters: {'x': 0.5851629562363818, 'y': 0.5667041045241809}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,016] Trial 247 finished with value: 1.5169038155582133 and parameters: {'x': 0.7608661526038554, 'y': 0.45809847837214357}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,022] Trial 248 finished with value: 1.1050416338103897 and parameters: {'x': 0.8500221864439289, 'y': 0.6184921366060508}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,028] Trial 249 finished with value: 22.09401296894806 and parameters: {'x': 0.5145413996802822, 'y': 0.7322819197050556}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,034] Trial 250 finished with value: 1.0024499549323653 and parameters: {'x': 0.644269938722284, 'y': 0.3214938998738158}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,040] Trial 251 finished with value: 0.7232580025667346 and parameters: {'x': 0.7082448927724821, 'y': 0.4217273530027428}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,046] Trial 252 finished with value: 13.389136989039455 and parameters: {'x': 0.9426609536293314, 'y': 0.5227429050856782}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,052] Trial 253 finished with value: 0.684244705742972 and parameters: {'x': 0.7566230095613784, 'y': 0.6515361009446213}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,059] Trial 254 finished with value: 0.5483942920175222 and parameters: {'x': 0.5829889344640664, 'y': 0.40107218118011195}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,065] Trial 255 finished with value: 2.651938877343557 and parameters: {'x': 0.8441131187713924, 'y': 0.5504270449561307}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,071] Trial 256 finished with value: 0.23659885456880464 and parameters: {'x': 0.6561147077261067, 'y': 0.46488734694108497}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,077] Trial 257 finished with value: 71.7862246353895 and parameters: {'x': 1.1536927665244598, 'y': 0.4838788913387917}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,084] Trial 258 finished with value: 11.567035914433754 and parameters: {'x': 0.705880315874338, 'y': 0.837096321401257}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,090] Trial 259 finished with value: 0.2612306087917395 and parameters: {'x': 0.8019684141950609, 'y': 0.6902717095599136}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,096] Trial 260 finished with value: 6.630025500251334 and parameters: {'x': 0.9976693289638238, 'y': 0.7378558364711304}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,102] Trial 261 finished with value: 22.11110689490964 and parameters: {'x': 0.8844321890257745, 'y': 0.31213784702559677}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,113] Trial 262 finished with value: 19.448316589212556 and parameters: {'x': 0.4880260938074132, 'y': 0.6761900078077333}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,119] Trial 263 finished with value: 0.6029940276685929 and parameters: {'x': 0.6559707257307023, 'y': 0.4999135312851678}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,126] Trial 264 finished with value: 0.9684184137700195 and parameters: {'x': 0.8189175129484071, 'y': 0.5738980507626151}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,132] Trial 265 finished with value: 0.3146885566611878 and parameters: {'x': 0.6291414234316495, 'y': 0.43790841545074755}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,138] Trial 266 finished with value: 9.53016349360485 and parameters: {'x': 0.7713737745873428, 'y': 0.28715562293172003}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,144] Trial 267 finished with value: 0.8626099974920605 and parameters: {'x': 0.5304275189551045, 'y': 0.36148522433542574}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,151] Trial 268 finished with value: 7.5663847860088 and parameters: {'x': 0.69280985989513, 'y': 0.7533354425903863}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,157] Trial 269 finished with value: 4.146410873275281 and parameters: {'x': 0.9119674190430116, 'y': 0.6282475773022099}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,163] Trial 270 finished with value: 2.761618186850187 and parameters: {'x': 0.8095358895972187, 'y': 0.4902622696246614}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,169] Trial 271 finished with value: 35.582802878436866 and parameters: {'x': 0.5990201427735264, 'y': 0.953989125928387}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,176] Trial 272 finished with value: 0.5902709341358259 and parameters: {'x': 0.7163136122624779, 'y': 0.5845049787556394}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,182] Trial 273 finished with value: 4.6442536933814385 and parameters: {'x': 0.4663575178124838, 'y': 0.4262829979875379}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,188] Trial 274 finished with value: 6.501330881278461 and parameters: {'x': 0.6516728766507618, 'y': 0.6772641390819973}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,194] Trial 275 finished with value: 5.0597007451253155 and parameters: {'x': 0.5474279775583595, 'y': 0.5200152972395361}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,201] Trial 276 finished with value: 387.20483081927756 and parameters: {'x': 1.5187471345707984, 'y': 0.3395246539768152}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,207] Trial 277 finished with value: 6.4717669965541775 and parameters: {'x': 0.8413274304293896, 'y': 0.4539304861532318}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,213] Trial 278 finished with value: 0.10626898092308334 and parameters: {'x': 0.7485767304094001, 'y': 0.5811168973167984}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,220] Trial 279 finished with value: 83.74899908274146 and parameters: {'x': 0.7542421805492003, 'y': 1.4836960141603872}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,226] Trial 280 finished with value: 4.819561615975373 and parameters: {'x': 1.0067220859549604, 'y': 0.7939553876402838}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,232] Trial 281 finished with value: 4.628863060870698 and parameters: {'x': 0.8991254267441215, 'y': 0.593515216858292}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,238] Trial 282 finished with value: 0.8733772722972161 and parameters: {'x': 0.7781885264407312, 'y': 0.6963615741764961}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,245] Trial 283 finished with value: 0.096949188353578 and parameters: {'x': 0.7337928058307497, 'y': 0.5546020887378295}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,251] Trial 284 finished with value: 0.4477083128002992 and parameters: {'x': 0.7288320351273904, 'y': 0.5923660829207299}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,257] Trial 285 finished with value: 0.09731338013639919 and parameters: {'x': 0.8356287074616562, 'y': 0.6717620460432029}. Best is trial 199 with value: 0.05483067559229583.\n",
      "[I 2025-06-17 13:59:47,264] Trial 286 finished with value: 0.0458645049264241 and parameters: {'x': 0.9241772516801443, 'y': 0.874132425680203}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,270] Trial 287 finished with value: 17.609072082497768 and parameters: {'x': 1.1293695893671214, 'y': 0.8560434866467755}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,276] Trial 288 finished with value: 5.669050527624049 and parameters: {'x': 0.8997599205488296, 'y': 1.0474544937787003}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,283] Trial 289 finished with value: 3.084853504842164 and parameters: {'x': 0.9742866249145085, 'y': 0.7736157403499759}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,289] Trial 290 finished with value: 2.7648064606477907 and parameters: {'x': 0.8521393533421684, 'y': 0.891759824620571}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,296] Trial 291 finished with value: 9.418512953546477 and parameters: {'x': 0.9363118074460892, 'y': 0.5698499331216963}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,302] Trial 292 finished with value: 4.741535318128727 and parameters: {'x': 0.5616321760025623, 'y': 0.5287231990910035}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,308] Trial 293 finished with value: 0.05022750624727614 and parameters: {'x': 0.8088148450127526, 'y': 0.6424871203726403}. Best is trial 286 with value: 0.0458645049264241.\n",
      "[I 2025-06-17 13:59:47,315] Trial 294 finished with value: 0.032789843778711435 and parameters: {'x': 0.8337828018239294, 'y': 0.6880092725985757}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,321] Trial 295 finished with value: 16.328335276189236 and parameters: {'x': 1.068154191347413, 'y': 0.7369275074896984}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,328] Trial 296 finished with value: 0.09384202901327612 and parameters: {'x': 0.8057635689639917, 'y': 0.6729433730606307}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,334] Trial 297 finished with value: 0.6143715636755768 and parameters: {'x': 0.8635783047325798, 'y': 0.66858195318375}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,341] Trial 298 finished with value: 1.7273387065571781 and parameters: {'x': 0.9431216101148978, 'y': 0.7581732476006808}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,347] Trial 299 finished with value: 2.147747760901692 and parameters: {'x': 0.814128894157024, 'y': 0.8081743430140512}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,353] Trial 300 finished with value: 0.042110093455094276 and parameters: {'x': 0.8138246941329641, 'y': 0.6536799613464714}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,360] Trial 301 finished with value: 14.564609460544851 and parameters: {'x': 1.0163586288217206, 'y': 0.6513522922843668}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,366] Trial 302 finished with value: 12.350161782079523 and parameters: {'x': 0.8969966122973659, 'y': 1.1558799084000297}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,373] Trial 303 finished with value: 0.21390081630673607 and parameters: {'x': 0.8034737674126633, 'y': 0.6874363410156633}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,379] Trial 304 finished with value: 1.1870420941290554 and parameters: {'x': 0.8603396461949346, 'y': 0.6321316770595019}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,386] Trial 305 finished with value: 5.710116528684806 and parameters: {'x': 0.7611108988978555, 'y': 0.817051204481126}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,392] Trial 306 finished with value: 4.011070821628365 and parameters: {'x': 0.9083734094039772, 'y': 0.6250753773542845}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,398] Trial 307 finished with value: 942.9834578583011 and parameters: {'x': 1.9454165949426185, 'y': 0.7152978405895174}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,405] Trial 308 finished with value: 19.908796946868588 and parameters: {'x': 1.1539270275851026, 'y': 0.8856204225865035}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,411] Trial 309 finished with value: 0.7089169458217484 and parameters: {'x': 0.8081678970576498, 'y': 0.5711525839564762}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,418] Trial 310 finished with value: 4.506062002330364 and parameters: {'x': 0.7357157365617522, 'y': 0.7519009065706441}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,424] Trial 311 finished with value: 0.8254863561184816 and parameters: {'x': 0.8421158524088205, 'y': 0.619685148864279}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,431] Trial 312 finished with value: 17.361274461956263 and parameters: {'x': 0.9794168921426236, 'y': 0.5425939057211655}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,437] Trial 313 finished with value: 360.68344366562553 and parameters: {'x': -1.9511174514679968, 'y': 1.930761365675719}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,444] Trial 314 finished with value: 25.17324209542265 and parameters: {'x': 0.6860614648371314, 'y': 0.9714266235013802}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,450] Trial 315 finished with value: 1.5761658677099253 and parameters: {'x': 0.7497660279615241, 'y': 0.6851754689371605}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,457] Trial 316 finished with value: 11.765530852424586 and parameters: {'x': 0.9402857936560105, 'y': 0.541180159714558}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,463] Trial 317 finished with value: 3.1988880863831746 and parameters: {'x': 0.6730235091516221, 'y': 0.628800754790191}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,470] Trial 318 finished with value: 1.1198515725923528 and parameters: {'x': 0.8128885256123033, 'y': 0.7649434495273595}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,476] Trial 319 finished with value: 10.269064525793079 and parameters: {'x': 0.7180462373891832, 'y': 0.8348014045023007}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,483] Trial 320 finished with value: 21.752986759618793 and parameters: {'x': 1.0820993830168275, 'y': 0.7046103660774424}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,489] Trial 321 finished with value: 6.717838736909001 and parameters: {'x': 0.878519138122798, 'y': 0.5128927834224901}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,496] Trial 322 finished with value: 335.06301071937486 and parameters: {'x': 0.7764607057383098, 'y': -1.227444918902977}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,503] Trial 323 finished with value: 0.15033617475791403 and parameters: {'x': 0.6355312246762376, 'y': 0.41712819765533077}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,509] Trial 324 finished with value: 2.265491119705971 and parameters: {'x': 0.6763884385137217, 'y': 0.604496784888428}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,516] Trial 325 finished with value: 7.768559825503174 and parameters: {'x': 0.8337343704216186, 'y': 0.4168879913752652}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,522] Trial 326 finished with value: 11.532565303550355 and parameters: {'x': 0.9260402188381334, 'y': 0.5180347250578066}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,529] Trial 327 finished with value: 9.148343087581209 and parameters: {'x': 0.6051625071588836, 'y': 0.6660957410086114}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,536] Trial 328 finished with value: 0.0742525384873981 and parameters: {'x': 0.7570246335405137, 'y': 0.5854214122362453}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,542] Trial 329 finished with value: 0.0902833094591475 and parameters: {'x': 0.7640131493928632, 'y': 0.6023154246374263}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,549] Trial 330 finished with value: 5.706301351284036 and parameters: {'x': 0.9873016130745043, 'y': 0.735889191773019}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,555] Trial 331 finished with value: 9.165880479696765 and parameters: {'x': 0.7871814190472993, 'y': 0.9216577111675199}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,562] Trial 332 finished with value: 2.2764666715099495 and parameters: {'x': 0.8623351399394767, 'y': 0.5933716004694162}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,568] Trial 333 finished with value: 0.9165428426996838 and parameters: {'x': 0.7510410782921425, 'y': 0.656505240083457}. Best is trial 294 with value: 0.032789843778711435.\n",
      "[I 2025-06-17 13:59:47,575] Trial 334 finished with value: 0.01362121496815475 and parameters: {'x': 0.8907830374484058, 'y': 0.7976088700232227}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,581] Trial 335 finished with value: 0.08120886520268358 and parameters: {'x': 0.9209880461844078, 'y': 0.8208390658829057}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,588] Trial 336 finished with value: 81.38078552165878 and parameters: {'x': 1.3333271548868422, 'y': 0.8762643328596107}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,594] Trial 337 finished with value: 6.24835055220898 and parameters: {'x': 1.0316851687572548, 'y': 0.8144273610215006}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,601] Trial 338 finished with value: 1.07260383737136 and parameters: {'x': 0.9459331961625791, 'y': 0.7913642463337605}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,608] Trial 339 finished with value: 1.876922195657333 and parameters: {'x': 0.8918206061452641, 'y': 0.9319170294785591}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,614] Trial 340 finished with value: 0.4988037034194162 and parameters: {'x': 0.9937133593856654, 'y': 1.0580894791177509}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,621] Trial 341 finished with value: 0.05072940976126719 and parameters: {'x': 0.833020621098218, 'y': 0.7090386774614819}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,628] Trial 342 finished with value: 0.028812752277689292 and parameters: {'x': 0.9078340104731826, 'y': 0.8384167768524322}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,634] Trial 343 finished with value: 11.31798334866586 and parameters: {'x': 1.0821876134782036, 'y': 0.8348083314232402}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,641] Trial 344 finished with value: 1.5476861849528212 and parameters: {'x': 0.9264469802667379, 'y': 0.9824924180670174}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,648] Trial 345 finished with value: 62.47568555351074 and parameters: {'x': 1.2416372218470015, 'y': 0.7516168084401874}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,654] Trial 346 finished with value: 2.5745966215492015 and parameters: {'x': 0.8490966370912212, 'y': 0.8807094197263963}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,661] Trial 347 finished with value: 3.721044393800431 and parameters: {'x': 0.9897907072727525, 'y': 0.7867882579033584}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,667] Trial 348 finished with value: 0.3187895394958849 and parameters: {'x': 0.9011388233476201, 'y': 0.8676403871817953}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,674] Trial 349 finished with value: 0.20742061493017505 and parameters: {'x': 0.8198187899416177, 'y': 0.7139305122101312}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,680] Trial 350 finished with value: 0.06705736508825774 and parameters: {'x': 0.8607324239096639, 'y': 0.7190286983591745}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,687] Trial 351 finished with value: 16.289647495158302 and parameters: {'x': 1.0516944041794245, 'y': 0.7024898722468289}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,694] Trial 352 finished with value: 7.347156791773205 and parameters: {'x': 0.9446587115075858, 'y': 1.1633799729902725}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,700] Trial 353 finished with value: 0.06355724390130704 and parameters: {'x': 0.8582007056801918, 'y': 0.7573531637565917}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,707] Trial 354 finished with value: 0.37376052287864586 and parameters: {'x': 0.8611234239252094, 'y': 0.8010712552106081}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,714] Trial 355 finished with value: 2.1472358453292077 and parameters: {'x': 0.9389305452712733, 'y': 0.7351833843534292}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,720] Trial 356 finished with value: 37.98795249133123 and parameters: {'x': 1.1346293922217, 'y': 0.6711872379519151}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,727] Trial 357 finished with value: 4.259049374124131 and parameters: {'x': 0.853591084268239, 'y': 0.9344723918348106}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,733] Trial 358 finished with value: 15.741742432832014 and parameters: {'x': 0.7927805595252057, 'y': 1.0247181597676724}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,740] Trial 359 finished with value: 4.322292925695047 and parameters: {'x': 1.0094242916331089, 'y': 0.8110382877842288}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,747] Trial 360 finished with value: 1.2035980092056204 and parameters: {'x': 0.8815816080244013, 'y': 0.668118487750082}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,753] Trial 361 finished with value: 6.473353340683504 and parameters: {'x': 0.7879682678331805, 'y': 0.8744368057457222}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,760] Trial 362 finished with value: 1.4380976067541076 and parameters: {'x': 0.9315591888729238, 'y': 0.7480772759914412}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,767] Trial 363 finished with value: 0.2469437682547417 and parameters: {'x': 0.8233607641046673, 'y': 0.6314748748610233}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,773] Trial 364 finished with value: 3.683811631600291 and parameters: {'x': 0.7533976531077642, 'y': 0.7579497930104434}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,780] Trial 365 finished with value: 14.870532050755411 and parameters: {'x': 1.023802639386127, 'y': 0.6625559022498609}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,787] Trial 366 finished with value: 1.004790895544098 and parameters: {'x': 0.8577405045539974, 'y': 0.8349434238951688}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,794] Trial 367 finished with value: 7.414663846215128 and parameters: {'x': 0.9417193914998039, 'y': 0.614598985357702}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,800] Trial 368 finished with value: 3.298900424493927 and parameters: {'x': 0.7432525044490577, 'y': 0.7322292115543214}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,807] Trial 369 finished with value: 0.8339635084741011 and parameters: {'x': 0.8289266325632204, 'y': 0.5974144341347303}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,814] Trial 370 finished with value: 1.3783116770138728 and parameters: {'x': 0.8916653910010537, 'y': 0.9119677806925335}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,820] Trial 371 finished with value: 1.728573601653417 and parameters: {'x': 0.7400729042812049, 'y': 0.6765881390081026}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,827] Trial 372 finished with value: 11.18059156765469 and parameters: {'x': 1.0704995325562965, 'y': 0.8116696622522028}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,834] Trial 373 finished with value: 918.6824350688064 and parameters: {'x': -1.1110126385148453, 'y': -1.7892680566942611}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,841] Trial 374 finished with value: 227.10330320013497 and parameters: {'x': -1.4963418993991673, 'y': 0.7528641900496168}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,847] Trial 375 finished with value: 0.2925428630188864 and parameters: {'x': 0.7979259572246776, 'y': 0.5865152298424857}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,854] Trial 376 finished with value: 6.852926701958694 and parameters: {'x': 0.9764111758347066, 'y': 0.6916084599773326}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,861] Trial 377 finished with value: 4.423271369878303 and parameters: {'x': 0.8841967725187392, 'y': 0.571807242501897}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,867] Trial 378 finished with value: 1.8644712047498129 and parameters: {'x': 0.7230169366196963, 'y': 0.6564603187125282}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,874] Trial 379 finished with value: 4.609085550721869 and parameters: {'x': 0.8047153628940039, 'y': 0.8613646043502062}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,881] Trial 380 finished with value: 1.8015517369730853 and parameters: {'x': 0.9515658800889797, 'y': 0.7713431441303363}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,888] Trial 381 finished with value: 22.394456302403277 and parameters: {'x': 0.709743424390094, 'y': 0.9760725513225486}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,894] Trial 382 finished with value: 0.5529981683514883 and parameters: {'x': 0.8728150252594606, 'y': 0.6885379203584756}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,901] Trial 383 finished with value: 79.65769661376991 and parameters: {'x': 1.198624044430572, 'y': 0.5444090356495104}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,908] Trial 384 finished with value: 19.951643917940988 and parameters: {'x': 1.0222041163793456, 'y': 0.598234143532639}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,915] Trial 385 finished with value: 2.2698221272208836 and parameters: {'x': 0.8023919957433677, 'y': 0.7931906466005697}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,922] Trial 386 finished with value: 4.904839149916304 and parameters: {'x': 0.7059534884384002, 'y': 0.7178783185574718}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,928] Trial 387 finished with value: 5.057927468606449 and parameters: {'x': 0.9162317219933301, 'y': 0.6147382638644112}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,935] Trial 388 finished with value: 6.933219394786684 and parameters: {'x': 0.7693472028172994, 'y': 0.8541930155757548}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,942] Trial 389 finished with value: 2.4852443200127463 and parameters: {'x': 0.8243002244911671, 'y': 0.5228064445801278}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,949] Trial 390 finished with value: 259.9599045773582 and parameters: {'x': 0.8939250618730169, 'y': -0.8131903042879847}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,955] Trial 391 finished with value: 4.0762244677342725 and parameters: {'x': 0.7147280449986325, 'y': 0.7107072462344678}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,962] Trial 392 finished with value: 9.184508912199446 and parameters: {'x': 0.9689894361970357, 'y': 0.6358968464989174}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,969] Trial 393 finished with value: 16.1669897360524 and parameters: {'x': 1.0890031649262673, 'y': 0.7839444585770835}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,976] Trial 394 finished with value: 3.8816268319011322 and parameters: {'x': 0.8394839018705906, 'y': 0.9010966960602499}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,987] Trial 395 finished with value: 0.10292355760075944 and parameters: {'x': 0.7606656332521233, 'y': 0.557248072468095}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:47,994] Trial 396 finished with value: 0.059532503164169394 and parameters: {'x': 0.7605791149439722, 'y': 0.5737793743279452}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,001] Trial 397 finished with value: 6.19355022881607 and parameters: {'x': 0.8890445442939031, 'y': 0.5417792228237571}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,012] Trial 398 finished with value: 7.596749734669477 and parameters: {'x': 0.9921044813472129, 'y': 0.7086504138137318}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,019] Trial 399 finished with value: 34.789532961435626 and parameters: {'x': 0.7504720926490537, 'y': 1.15250683278222}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,026] Trial 400 finished with value: 0.22026493846440665 and parameters: {'x': 0.6942412043211073, 'y': 0.5175765371500836}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,033] Trial 401 finished with value: 0.040846960131674125 and parameters: {'x': 0.798561597523102, 'y': 0.6360588877294869}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,040] Trial 402 finished with value: 8.617270389920908 and parameters: {'x': 0.8461370850245271, 'y': 1.0090963351179}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,047] Trial 403 finished with value: 3.6969864327362405 and parameters: {'x': 0.7837159794479105, 'y': 0.8052659026948384}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,054] Trial 404 finished with value: 119.2437106446573 and parameters: {'x': 1.3247514404187974, 'y': 0.6634616965993708}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,060] Trial 405 finished with value: 10.55262331917295 and parameters: {'x': 0.9396886528759427, 'y': 0.5582227407259043}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,067] Trial 406 finished with value: 17.952812382571018 and parameters: {'x': 0.7041601082656398, 'y': 0.9185149862363138}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,074] Trial 407 finished with value: 11.505332582929874 and parameters: {'x': 1.0388674048037925, 'y': 0.7400726393328024}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,081] Trial 408 finished with value: 2.272071957198762 and parameters: {'x': 0.8842204789382831, 'y': 0.631557231063772}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,088] Trial 409 finished with value: 55.968963634002414 and parameters: {'x': 0.7676891783580578, 'y': 1.3371099747918136}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,095] Trial 410 finished with value: 0.024244817284875392 and parameters: {'x': 0.844314847546623, 'y': 0.7131312015123804}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,102] Trial 411 finished with value: 0.6976719717958647 and parameters: {'x': 0.9569510049028629, 'y': 0.8323394745252002}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,108] Trial 412 finished with value: 0.05825277731922948 and parameters: {'x': 0.85182885010619, 'y': 0.7446644468903583}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,115] Trial 413 finished with value: 0.04405340160192262 and parameters: {'x': 0.8652971352496207, 'y': 0.7648352621880355}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,122] Trial 414 finished with value: 7.945275467049532 and parameters: {'x': 1.102173061860909, 'y': 0.9330970465231113}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,129] Trial 415 finished with value: 5.85451749430101 and parameters: {'x': 1.0312259561183001, 'y': 0.8214860203964629}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,136] Trial 416 finished with value: 0.3499164545385196 and parameters: {'x': 0.8900558795723, 'y': 0.7340764315967797}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,143] Trial 417 finished with value: 0.41745074372065794 and parameters: {'x': 0.9693320949275874, 'y': 0.8750671070071945}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,150] Trial 418 finished with value: 0.02738427544577878 and parameters: {'x': 0.8733976299747098, 'y': 0.7734799276111289}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,157] Trial 419 finished with value: 0.254422761198083 and parameters: {'x': 0.9139516256493165, 'y': 0.7856066244918648}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,164] Trial 420 finished with value: 0.41041032761552754 and parameters: {'x': 1.0178718647572749, 'y': 0.9720247911070259}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,171] Trial 421 finished with value: 2.320802807812568 and parameters: {'x': 0.8529225703099768, 'y': 0.8791070872775293}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,178] Trial 422 finished with value: 2.3291645266273906 and parameters: {'x': 0.9526615003861536, 'y': 0.7550213634375477}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,185] Trial 423 finished with value: 168.92196464768622 and parameters: {'x': 1.5496775757403083, 'y': 1.1029636458415517}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,192] Trial 424 finished with value: 29.834009763538795 and parameters: {'x': 1.1709760662535313, 'y': 0.8252474334724722}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,199] Trial 425 finished with value: 0.12058771771905094 and parameters: {'x': 0.8429205090741838, 'y': 0.7414849299277356}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,206] Trial 426 finished with value: 1.7148488821958037 and parameters: {'x': 0.9162341322584251, 'y': 0.7088009324693854}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,213] Trial 427 finished with value: 4.252180522765976 and parameters: {'x': 0.8209788742814199, 'y': 0.8794359096724319}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,220] Trial 428 finished with value: 8.154326642848897 and parameters: {'x': 0.691646843063513, 'y': 0.7622634492020091}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,227] Trial 429 finished with value: 1.522558683832592 and parameters: {'x': 1.0398151630017396, 'y': 0.9578878213992733}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,233] Trial 430 finished with value: 0.6784225636015573 and parameters: {'x': 0.8577176699315971, 'y': 0.6545514124910081}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,241] Trial 431 finished with value: 0.8762022561323373 and parameters: {'x': 0.9622759141561864, 'y': 0.8324453059976369}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,248] Trial 432 finished with value: 4.401723418671969 and parameters: {'x': 0.6975747740003604, 'y': 0.6942222798599004}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,255] Trial 433 finished with value: 16.560941785361845 and parameters: {'x': 0.7955051892874828, 'y': 1.0392657542026544}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,262] Trial 434 finished with value: 0.024600139399685007 and parameters: {'x': 0.876786413929984, 'y': 0.7784593379122978}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,269] Trial 435 finished with value: 0.6775462908937562 and parameters: {'x': 0.9049847064570928, 'y': 0.9007602925025963}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,276] Trial 436 finished with value: 17.915172217189532 and parameters: {'x': 1.1062618289479242, 'y': 0.8006854592847756}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,283] Trial 437 finished with value: 6.101281329151006 and parameters: {'x': 0.998540384446803, 'y': 0.7500752234039345}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,290] Trial 438 finished with value: 0.3197588227064569 and parameters: {'x': 0.8807822318922245, 'y': 0.8310535506753286}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,297] Trial 439 finished with value: 0.05582477945682496 and parameters: {'x': 0.8220105698669953, 'y': 0.6912398911291048}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,304] Trial 440 finished with value: 0.22754244673660431 and parameters: {'x': 0.9364223412125275, 'y': 0.9241626224304922}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,311] Trial 441 finished with value: 453.24919688832443 and parameters: {'x': 1.0605751973534807, 'y': -1.0041366324954377}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,319] Trial 442 finished with value: 4.302275879268131 and parameters: {'x': -0.8949055133069146, 'y': 0.7164989589492337}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,326] Trial 443 finished with value: 0.8734687659089845 and parameters: {'x': 0.8437771811145985, 'y': 0.8041045566480334}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,333] Trial 444 finished with value: 10.564642678059421 and parameters: {'x': 0.999506790940243, 'y': 0.6739808662714231}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,340] Trial 445 finished with value: 1.4960118620278668 and parameters: {'x': 0.7933870008523484, 'y': 0.750016777133655}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,347] Trial 446 finished with value: 2.6288288823440316 and parameters: {'x': 0.9002020894914782, 'y': 0.9721930100240463}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,354] Trial 447 finished with value: 1.9826599389486614 and parameters: {'x': 0.700714059961645, 'y': 0.6285897234093655}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,361] Trial 448 finished with value: 6.239298094689886 and parameters: {'x': 0.7890314980650688, 'y': 0.8714640633451975}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,369] Trial 449 finished with value: 0.6468119548585467 and parameters: {'x': 0.9192027894226878, 'y': 0.7649160346965643}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,375] Trial 450 finished with value: 0.652853794739758 and parameters: {'x': 0.8599579025604641, 'y': 0.6599510897490383}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,383] Trial 451 finished with value: 7.585807221328607 and parameters: {'x': 0.7561555155776837, 'y': 0.8461130506013761}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,390] Trial 452 finished with value: 56.10027578088706 and parameters: {'x': 0.9951464694145862, 'y': 1.739317511770056}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,397] Trial 453 finished with value: 0.8364417258792323 and parameters: {'x': 0.8443707367479598, 'y': 0.6228386223236599}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,404] Trial 454 finished with value: 11.478338564365727 and parameters: {'x': 0.6547224061375936, 'y': 0.7656943940670481}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,411] Trial 455 finished with value: 3.475264016749541 and parameters: {'x': 0.9433736565210646, 'y': 0.7036192784047729}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,418] Trial 456 finished with value: 0.5614700144146146 and parameters: {'x': 0.7571027168410039, 'y': 0.502319340329286}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,425] Trial 457 finished with value: 29.41208106956922 and parameters: {'x': 1.0727988390332976, 'y': 0.6086171502538008}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,432] Trial 458 finished with value: 5.4937921426305785 and parameters: {'x': 0.8382349913641963, 'y': 0.9364674160915618}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,440] Trial 459 finished with value: 6.53878748089567 and parameters: {'x': 0.6812467998495886, 'y': 0.7178132616765943}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,447] Trial 460 finished with value: 0.07103507355180447 and parameters: {'x': 0.9256062371254044, 'y': 0.8311538130752397}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,454] Trial 461 finished with value: 11.456195905059502 and parameters: {'x': 1.1521929259506642, 'y': 0.9894208523981317}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,461] Trial 462 finished with value: 0.2240497913777857 and parameters: {'x': 1.0014463041974981, 'y': 1.0502283773754661}. Best is trial 334 with value: 0.01362121496815475.\n",
      "[I 2025-06-17 13:59:48,469] Trial 463 finished with value: 0.013506784418543725 and parameters: {'x': 0.9326860407407569, 'y': 0.8604292781906673}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,476] Trial 464 finished with value: 10.321190494486105 and parameters: {'x': 1.1050837287046067, 'y': 0.9001158571475775}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,483] Trial 465 finished with value: 0.3067009902514008 and parameters: {'x': 0.9419975538679248, 'y': 0.8322833797916793}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,490] Trial 466 finished with value: 1.5180069405027987 and parameters: {'x': 0.8701502956808457, 'y': 0.8796828003215633}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,497] Trial 467 finished with value: 9.00997842578445 and parameters: {'x': 1.0362226920816942, 'y': 0.7736130632999826}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,505] Trial 468 finished with value: 4.736336832153266 and parameters: {'x': 0.9544729190401383, 'y': 0.6934349114003635}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,512] Trial 469 finished with value: 1.9351324249066173 and parameters: {'x': 0.8164314958907974, 'y': 0.8044529191586325}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,519] Trial 470 finished with value: 0.8389359138011481 and parameters: {'x': 0.887192378949576, 'y': 0.8780064312884309}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,526] Trial 471 finished with value: 20.354211112058092 and parameters: {'x': 0.804563436576939, 'y': 1.0980552339870921}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,533] Trial 472 finished with value: 6.080462403232222 and parameters: {'x': 0.9917102534896249, 'y': 1.230073769849754}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,540] Trial 473 finished with value: 33.69201537485376 and parameters: {'x': 1.25050874048958, 'y': 0.9838646972084762}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,554] Trial 474 finished with value: 4.471131990931822 and parameters: {'x': 0.7051015451661907, 'y': 0.7065522116017846}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,562] Trial 475 finished with value: 432.8939652630295 and parameters: {'x': 1.6914506445388757, 'y': 0.7815441477387042}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,569] Trial 476 finished with value: 2.6511316363097928 and parameters: {'x': 0.8871954455122596, 'y': 0.6246840261453894}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,576] Trial 477 finished with value: 9.764822603587028 and parameters: {'x': 0.7878846268112923, 'y': 0.932528598880133}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,583] Trial 478 finished with value: 21.419410085488938 and parameters: {'x': 1.070534931287465, 'y': 0.683287706274889}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,591] Trial 479 finished with value: 11.276130399360664 and parameters: {'x': 0.931381442799387, 'y': 0.5317420085143102}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,598] Trial 480 finished with value: 0.4131918671762523 and parameters: {'x': 0.8460618581744395, 'y': 0.7782301956291962}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,605] Trial 481 finished with value: 14.420327148097334 and parameters: {'x': 0.6781785930314085, 'y': 0.8383011256531103}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,618] Trial 482 finished with value: 1.0075050969202695 and parameters: {'x': 0.7467705146712376, 'y': 0.6547939486312908}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,626] Trial 483 finished with value: 5.622142214380004 and parameters: {'x': 0.9946253300861334, 'y': 0.7521695869498658}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,633] Trial 484 finished with value: 3.864517773409584 and parameters: {'x': 0.8825651808986043, 'y': 0.5826886091917498}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,640] Trial 485 finished with value: 6.63823422879584 and parameters: {'x': 0.7961732633372122, 'y': 0.8907320663551359}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,647] Trial 486 finished with value: 0.14381656943924315 and parameters: {'x': 0.7300289265674746, 'y': 0.5063091359930023}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,655] Trial 487 finished with value: 1.5324745020325963 and parameters: {'x': 0.8990289777385688, 'y': 0.6848724173440057}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,662] Trial 488 finished with value: 1.326304041234935 and parameters: {'x': 0.9635205232726431, 'y': 0.813264314692371}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,669] Trial 489 finished with value: 0.48703164995854253 and parameters: {'x': 0.8136008649431358, 'y': 0.5946940803071853}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,676] Trial 490 finished with value: 5.182191550202654 and parameters: {'x': 1.1149263020729012, 'y': 1.0157066730476714}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,684] Trial 491 finished with value: 7.274767204425343 and parameters: {'x': 0.6771414412388534, 'y': 0.7262989763459031}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,691] Trial 492 finished with value: 0.9056110289925424 and parameters: {'x': 0.8579067924436695, 'y': 0.6419072766183744}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,698] Trial 493 finished with value: 9.80004401061689 and parameters: {'x': 0.7645073176165674, 'y': 0.8966346525239772}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,706] Trial 494 finished with value: 6.2950002133796925 and parameters: {'x': 1.0009878194495088, 'y': 0.751078244073948}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,713] Trial 495 finished with value: 236.23795469120222 and parameters: {'x': 1.433275683867568, 'y': 0.5178865705419424}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,720] Trial 496 finished with value: 25.90622706546205 and parameters: {'x': 0.5699080296762681, 'y': 0.8319563591739194}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,727] Trial 497 finished with value: 4.98531781526472 and parameters: {'x': 0.9449702494245664, 'y': 0.6697583437370246}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,735] Trial 498 finished with value: 0.049921894538137834 and parameters: {'x': 0.85063976165723, 'y': 0.7402052884091477}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,743] Trial 499 finished with value: 2.0446395128630734 and parameters: {'x': 0.8830527049665421, 'y': 0.9222939333977279}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,750] Trial 500 finished with value: 9.952588780159246 and parameters: {'x': 1.0529583459324572, 'y': 0.7932884931345607}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,757] Trial 501 finished with value: 2.7593479418790667 and parameters: {'x': 0.9406616121307072, 'y': 0.7188374344118346}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,765] Trial 502 finished with value: 8.887302487243224 and parameters: {'x': 0.8263647771580835, 'y': 0.9804884439736432}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,772] Trial 503 finished with value: 9.47656535068051 and parameters: {'x': 0.7369552362158638, 'y': 0.8498174281117609}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,780] Trial 504 finished with value: 9.097735756637045 and parameters: {'x': 1.0298303809724756, 'y': 0.7589408341401551}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,787] Trial 505 finished with value: 54.16780636066433 and parameters: {'x': 1.1975413445391954, 'y': 0.6983826082508814}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,794] Trial 506 finished with value: 3.0883745940947156 and parameters: {'x': 0.8769820266081461, 'y': 0.5937908529762705}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,802] Trial 507 finished with value: 14.386047965317553 and parameters: {'x': 0.6713758840084435, 'y': 0.828608703054593}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,809] Trial 508 finished with value: 7.795548003970463 and parameters: {'x': 0.8036832062448047, 'y': 0.924420748077381}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,817] Trial 509 finished with value: 2.934316219616943 and parameters: {'x': 0.9493352648981778, 'y': 1.0724609629633293}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,824] Trial 510 finished with value: 0.04937169440438827 and parameters: {'x': 0.8559387205697854, 'y': 0.7495479613352846}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,831] Trial 511 finished with value: 0.1289752107683166 and parameters: {'x': 0.9003594336772328, 'y': 0.7761439261452654}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,839] Trial 512 finished with value: 5.790882637501826 and parameters: {'x': 1.050863359876951, 'y': 0.8637250325635171}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,846] Trial 513 finished with value: 85.66500244074814 and parameters: {'x': -1.2803071509938646, 'y': 0.7421624227345258}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,853] Trial 514 finished with value: 3.2922268965898236 and parameters: {'x': 1.125084590350279, 'y': 1.446828615118013}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,861] Trial 515 finished with value: 1.3443541513590311 and parameters: {'x': 0.8389741465592763, 'y': 0.8187003004082916}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,868] Trial 516 finished with value: 0.11566157058029151 and parameters: {'x': 0.9612757925117547, 'y': 0.9578390178515828}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,876] Trial 517 finished with value: 0.8181949679526632 and parameters: {'x': 0.8745770780867532, 'y': 0.6753047072540701}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,883] Trial 518 finished with value: 1.8400652315981287 and parameters: {'x': 0.9439696938091936, 'y': 0.7555455457115626}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,891] Trial 519 finished with value: 3.432059875853537 and parameters: {'x': 0.8439736328929772, 'y': 0.8968914835012598}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,898] Trial 520 finished with value: 11.031626804703516 and parameters: {'x': 1.0008604523523488, 'y': 0.6695827273945018}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,905] Trial 521 finished with value: 6.428661188188884 and parameters: {'x': 0.7546390074962833, 'y': 0.8218380941482718}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,913] Trial 522 finished with value: 0.4461481281207416 and parameters: {'x': 0.817952515710904, 'y': 0.7333119263019766}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,920] Trial 523 finished with value: 3.079746163138394 and parameters: {'x': 0.6783592364193236, 'y': 0.6326906259488275}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,927] Trial 524 finished with value: 3.9713158281440584 and parameters: {'x': 0.9047197114160068, 'y': 1.0175714548778505}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,935] Trial 525 finished with value: 2.941652863511983 and parameters: {'x': 1.0181153255314856, 'y': 0.8650559094451145}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,942] Trial 526 finished with value: 3.09546291838577 and parameters: {'x': 0.7734403465064503, 'y': 0.7726844273849394}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,950] Trial 527 finished with value: 2.942184386453328 and parameters: {'x': 0.6341388339486572, 'y': 0.569712787347138}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,957] Trial 528 finished with value: 211.21636686899114 and parameters: {'x': 0.9112271383869242, 'y': -0.622966468976891}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,965] Trial 529 finished with value: 0.031237768410320003 and parameters: {'x': 0.8252849841939289, 'y': 0.6837644466874921}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,972] Trial 530 finished with value: 1.4367013056886495 and parameters: {'x': 0.7156307152042036, 'y': 0.6285676664532219}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,980] Trial 531 finished with value: 0.08609468989414623 and parameters: {'x': 0.8108874749229955, 'y': 0.6799731003383205}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,987] Trial 532 finished with value: 0.24427688619148702 and parameters: {'x': 0.7330415836062991, 'y': 0.49575548167790573}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:48,995] Trial 533 finished with value: 3.5695115976720415 and parameters: {'x': 0.6193436178116477, 'y': 0.5686435977496758}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,002] Trial 534 finished with value: 0.033064267832134085 and parameters: {'x': 0.8311356067435601, 'y': 0.6975310869472214}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,010] Trial 535 finished with value: 1080.3497066136767 and parameters: {'x': 1.9840670731385557, 'y': 0.6511282342860709}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,017] Trial 536 finished with value: 2.751027772188696 and parameters: {'x': 0.8108169486891523, 'y': 0.49264434562882276}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,025] Trial 537 finished with value: 4.220099530559316 and parameters: {'x': 0.7219876838140737, 'y': 0.7248051229804312}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,032] Trial 538 finished with value: 0.808178236262928 and parameters: {'x': 0.8214952050353836, 'y': 0.5867456734357839}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,040] Trial 539 finished with value: 0.6622829264773732 and parameters: {'x': 0.7648118597712353, 'y': 0.6628454259285695}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,048] Trial 540 finished with value: 11.777939012937306 and parameters: {'x': 0.6450496162366817, 'y': 0.7574385238561924}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,055] Trial 541 finished with value: 8.600025273127686 and parameters: {'x': 0.8776858250892877, 'y': 0.477329600140216}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,063] Trial 542 finished with value: 12.022754787694677 and parameters: {'x': 0.9749212132314008, 'y': 0.6037419985463877}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,070] Trial 543 finished with value: 0.12376008122968983 and parameters: {'x': 0.8592430729263048, 'y': 0.7060577575298247}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,085] Trial 544 finished with value: 26.208391664943587 and parameters: {'x': 0.5675532077326525, 'y': 0.8322282141174606}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,098] Trial 545 finished with value: 19.232894369340077 and parameters: {'x': 0.7076412821126049, 'y': 0.9383338429651273}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,106] Trial 546 finished with value: 30.883408477821728 and parameters: {'x': 1.0507873117081294, 'y': 0.5484487546873357}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,119] Trial 547 finished with value: 1.6957911265363512 and parameters: {'x': 0.8111202816327977, 'y': 0.7867615837819308}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,127] Trial 548 finished with value: 4.44587750084988 and parameters: {'x': 0.9345931625502248, 'y': 0.662713354660965}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,135] Trial 549 finished with value: 477.5521630678789 and parameters: {'x': 0.7590601566565665, 'y': -1.6089915421340422}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,142] Trial 550 finished with value: 0.43999418299009097 and parameters: {'x': 0.8771792194528641, 'y': 0.7042583204215812}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,150] Trial 551 finished with value: 22.050349480354647 and parameters: {'x': 1.1200492504905477, 'y': 0.785085807144953}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,158] Trial 552 finished with value: 2.337352029862214 and parameters: {'x': 0.6739717199485433, 'y': 0.6036051310716668}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,165] Trial 553 finished with value: 0.3819016794381093 and parameters: {'x': 0.9754935753503096, 'y': 0.8898381313738833}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,173] Trial 554 finished with value: 0.4689241516217885 and parameters: {'x': 0.8126398542274637, 'y': 0.7262485710070605}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,180] Trial 555 finished with value: 2.581408439303532 and parameters: {'x': 0.899873839570936, 'y': 0.6494175969769982}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,188] Trial 556 finished with value: 0.7649898463992736 and parameters: {'x': 0.7574873104152352, 'y': 0.4897526609342907}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,196] Trial 557 finished with value: 4.158919552964066 and parameters: {'x': 1.0027933602354588, 'y': 0.8016604224540571}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,203] Trial 558 finished with value: 8.464523245147822 and parameters: {'x': 0.5374053144561969, 'y': 0.5760418198916969}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,211] Trial 559 finished with value: 18.393269797485033 and parameters: {'x': 0.6616375032144513, 'y': 0.8653010918826267}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,218] Trial 560 finished with value: 0.0315759841611936 and parameters: {'x': 0.8430720311133867, 'y': 0.7191068737845226}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,226] Trial 561 finished with value: 0.18490133471492398 and parameters: {'x': 0.7790930335039168, 'y': 0.6438778844417696}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,234] Trial 562 finished with value: 8.53334160190535 and parameters: {'x': 0.9235547614069527, 'y': 0.5609346012203219}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,241] Trial 563 finished with value: 3.6709719700246306 and parameters: {'x': 0.7142261704628328, 'y': 0.6995736421633999}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,249] Trial 564 finished with value: 5.317959067598421 and parameters: {'x': 0.8498624568907757, 'y': 0.49214844782171135}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,256] Trial 565 finished with value: 17.14398074766741 and parameters: {'x': 1.088013005105362, 'y': 0.7698129479092144}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,264] Trial 566 finished with value: 0.05252127590880726 and parameters: {'x': 0.9630659528219669, 'y': 0.9501139763563076}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,272] Trial 567 finished with value: 0.2832018221240388 and parameters: {'x': 1.0662067617274715, 'y': 1.0839935930564946}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,280] Trial 568 finished with value: 14.904794830963157 and parameters: {'x': 1.191934914820841, 'y': 1.035118957750898}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,287] Trial 569 finished with value: 5.116221409880609 and parameters: {'x': 0.9958973990590647, 'y': 1.2180019161261568}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,295] Trial 570 finished with value: 0.1442596026076767 and parameters: {'x': 0.9736167692951594, 'y': 0.9100398354453111}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,302] Trial 571 finished with value: 0.9839000139326683 and parameters: {'x': 0.9094965856736683, 'y': 0.9259620301155874}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,310] Trial 572 finished with value: 0.3124256150982255 and parameters: {'x': 1.0315468901428573, 'y': 1.0082830362694986}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,318] Trial 573 finished with value: 1.185424081800662 and parameters: {'x': 0.9200907343727837, 'y': 0.9551505029402421}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,326] Trial 574 finished with value: 1.7227741986173983 and parameters: {'x': 0.8499202464684231, 'y': 0.8527580703783686}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,333] Trial 575 finished with value: 21.893707855715142 and parameters: {'x': 1.137930521160733, 'y': 0.8271820862380677}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,341] Trial 576 finished with value: 0.2225510301642777 and parameters: {'x': 0.9666327308438089, 'y': 0.9814359989722474}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,349] Trial 577 finished with value: 0.944269703078947 and parameters: {'x': 0.8004633842810734, 'y': 0.735844460345743}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,356] Trial 578 finished with value: 13.134644170836342 and parameters: {'x': 0.8722044755584869, 'y': 1.1229327574623376}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,364] Trial 579 finished with value: 5.133417799310783 and parameters: {'x': 1.053748966323312, 'y': 0.8838801766669387}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,372] Trial 580 finished with value: 2903.5795427572166 and parameters: {'x': 1.8432417936477756, 'y': -1.990287161436366}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,380] Trial 581 finished with value: 3.834095122304438 and parameters: {'x': 0.7881609258752262, 'y': 0.8158568171947991}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,387] Trial 582 finished with value: 2.4732819172896465 and parameters: {'x': 0.9286403528876181, 'y': 0.7052681718535899}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,395] Trial 583 finished with value: 0.2551590651761533 and parameters: {'x': 0.8573159404541341, 'y': 0.783446820981176}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,403] Trial 584 finished with value: 2.5510757328220577 and parameters: {'x': 0.7105272089284104, 'y': 0.6619247318640921}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,410] Trial 585 finished with value: 916.2450647707211 and parameters: {'x': -1.991125026485606, 'y': 0.9524397045801724}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,418] Trial 586 finished with value: 4.3872053576739445 and parameters: {'x': 0.9804674442786607, 'y': 0.7518689496031571}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,426] Trial 587 finished with value: 23.9004252383324 and parameters: {'x': 0.6065333746308543, 'y': 0.8551774015861259}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,434] Trial 588 finished with value: 0.05693794294470709 and parameters: {'x': 0.8120099292005174, 'y': 0.6446639772489289}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,441] Trial 589 finished with value: 2.3020608744333053 and parameters: {'x': 0.9127737473234906, 'y': 0.6816814124742845}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,449] Trial 590 finished with value: 10.660139436913445 and parameters: {'x': 0.8368468679055352, 'y': 1.0264034727784304}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,457] Trial 591 finished with value: 7.3881783064172035 and parameters: {'x': 1.0225916299213984, 'y': 0.77389099397725}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,469] Trial 592 finished with value: 442.3343883982021 and parameters: {'x': -1.720831898910371, 'y': 0.8757613761752168}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,477] Trial 593 finished with value: 0.04979930803517273 and parameters: {'x': 0.7840487118451368, 'y': 0.6203576373664047}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,485] Trial 594 finished with value: 5.178531923211144 and parameters: {'x': 0.9217812144082946, 'y': 0.6222511952244856}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,493] Trial 595 finished with value: 0.31422251510134813 and parameters: {'x': 0.8251640317741546, 'y': 0.7341549413748428}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,500] Trial 596 finished with value: 9.010923994247094 and parameters: {'x': 0.730530677976721, 'y': 0.8326451415178907}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,508] Trial 597 finished with value: 21.991767695921865 and parameters: {'x': 1.0791022598373772, 'y': 0.695574594930328}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,516] Trial 598 finished with value: 0.0193804245518228 and parameters: {'x': 0.9692404564722692, 'y': 0.9530043504958247}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,524] Trial 599 finished with value: 37.058850216873104 and parameters: {'x': 1.2475851151428667, 'y': 0.9482124906820077}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,532] Trial 600 finished with value: 1.948268024102255 and parameters: {'x': 0.9730175074804202, 'y': 1.0863173592707827}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,540] Trial 601 finished with value: 14.642792346167028 and parameters: {'x': 1.1609845967985113, 'y': 0.9655649977385573}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,547] Trial 602 finished with value: 2.231530829789471 and parameters: {'x': 1.0950290192786305, 'y': 1.0500080273292642}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,559] Trial 603 finished with value: 2.7234538179767585 and parameters: {'x': 1.0287340138413232, 'y': 0.8932897872062993}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,567] Trial 604 finished with value: 0.5728092997568971 and parameters: {'x': 0.9394589674048237, 'y': 0.9580247900150625}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,575] Trial 605 finished with value: 20.972716827641193 and parameters: {'x': 0.8843527496133464, 'y': 1.239893531076622}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,583] Trial 606 finished with value: 43.43045939945101 and parameters: {'x': 0.9904506351708711, 'y': 1.6400096699627835}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,591] Trial 607 finished with value: 28.435733268362927 and parameters: {'x': 0.7892085582258488, 'y': 1.1556850218268286}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,599] Trial 608 finished with value: 14.58501612700962 and parameters: {'x': 0.6507724193051365, 'y': 0.8038079920942234}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,606] Trial 609 finished with value: 7.119650115627145 and parameters: {'x': 0.8661976376896157, 'y': 1.0167893800986543}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,614] Trial 610 finished with value: 0.02038748748342918 and parameters: {'x': 0.954447844657747, 'y': 0.8974383237712034}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,622] Trial 611 finished with value: 0.8118286292816556 and parameters: {'x': 1.0431234361083992, 'y': 0.9981082252784147}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,630] Trial 612 finished with value: 21.746950366301792 and parameters: {'x': 1.1844716248177727, 'y': 0.9370017799632309}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,638] Trial 613 finished with value: 11.387277997903956 and parameters: {'x': 1.101119071960053, 'y': 0.8751643382496036}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,646] Trial 614 finished with value: 994.9686668545487 and parameters: {'x': 1.3909714225050591, 'y': -1.2192685837498143}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,654] Trial 615 finished with value: 0.14976916532967952 and parameters: {'x': 0.983655245686125, 'y': 0.9289121520241711}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,662] Trial 616 finished with value: 2.992116522081126 and parameters: {'x': 0.9469705824775325, 'y': 1.069649333857997}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,670] Trial 617 finished with value: 3.985546898223807 and parameters: {'x': 1.029813786948154, 'y': 0.8609003533619656}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,677] Trial 618 finished with value: 0.07342094022526927 and parameters: {'x': 0.9077968496836719, 'y': 0.798615811180748}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,685] Trial 619 finished with value: 255.57317915286913 and parameters: {'x': 1.6487332282327656, 'y': 1.1209724407713901}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,693] Trial 620 finished with value: 11.395213576008928 and parameters: {'x': 1.11874223238901, 'y': 0.9142251177606373}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,701] Trial 621 finished with value: 18.825530988289163 and parameters: {'x': 0.949889135200401, 'y': 1.3361444128155868}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,708] Trial 622 finished with value: 0.23248221142180725 and parameters: {'x': 0.876826180199533, 'y': 0.815440716173293}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,716] Trial 623 finished with value: 37.50849689939887 and parameters: {'x': -0.6645156901244593, 'y': 1.0309696365544483}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,724] Trial 624 finished with value: 9.633292883450705 and parameters: {'x': 0.7559519405526951, 'y': 0.880877838802548}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,732] Trial 625 finished with value: 9.774323123943969 and parameters: {'x': 1.033303330267222, 'y': 0.7550943717281129}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,740] Trial 626 finished with value: 0.59014327838976 and parameters: {'x': 0.8577095025663476, 'y': 0.8111570931441903}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,748] Trial 627 finished with value: 4.706009227072822 and parameters: {'x': 0.9612593025318338, 'y': 0.7071206595835312}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,756] Trial 628 finished with value: 268.07355805038156 and parameters: {'x': -1.5787043926781625, 'y': 0.8754468922869281}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,764] Trial 629 finished with value: 21.1165786057842 and parameters: {'x': 0.7255488991271956, 'y': 0.9851286847872668}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,771] Trial 630 finished with value: 0.428350216365844 and parameters: {'x': 0.8304056986669006, 'y': 0.6263606518711384}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,779] Trial 631 finished with value: 2.072741197820801 and parameters: {'x': 0.9319812525138536, 'y': 0.7247796447815219}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,787] Trial 632 finished with value: 2.8819020944265095 and parameters: {'x': 0.790181313816898, 'y': 0.7928465399696402}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,795] Trial 633 finished with value: 12.350534139190454 and parameters: {'x': 1.0177201400814948, 'y': 0.6843254836856809}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,803] Trial 634 finished with value: 1.030236073924495 and parameters: {'x': 0.6735218961141396, 'y': 0.5497383583450481}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,811] Trial 635 finished with value: 1.7836441139592418 and parameters: {'x': 0.8933706997632043, 'y': 0.9312380003773204}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,819] Trial 636 finished with value: 15.896372646528777 and parameters: {'x': 1.105842487168319, 'y': 0.8243255659054574}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,827] Trial 637 finished with value: 0.14302722550127991 and parameters: {'x': 0.805195448660854, 'y': 0.6159239100328548}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,835] Trial 638 finished with value: 0.6323124164994915 and parameters: {'x': 0.9074160375011071, 'y': 0.744426613554822}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,843] Trial 639 finished with value: 39.058074099610714 and parameters: {'x': 1.2328250064242623, 'y': 0.8953267396883906}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,857] Trial 640 finished with value: 2.8277780455926704 and parameters: {'x': 0.707542365436288, 'y': 0.6662134989128142}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,865] Trial 641 finished with value: 19.554946392522634 and parameters: {'x': 0.9882437035083662, 'y': 0.5344174292006552}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,873] Trial 642 finished with value: 10.871967737082214 and parameters: {'x': 0.8246899375668503, 'y': 1.0093737871026836}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,881] Trial 643 finished with value: 3.4006891951293374 and parameters: {'x': 0.7632749415648503, 'y': 0.7654724914173292}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,889] Trial 644 finished with value: 0.21224457497073498 and parameters: {'x': 0.8964630686037015, 'y': 0.8485375335466536}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,897] Trial 645 finished with value: 25.417306898298502 and parameters: {'x': 1.062188352201437, 'y': 0.6241266538074375}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,905] Trial 646 finished with value: 9.71231105218934 and parameters: {'x': 0.634758016902631, 'y': 0.7124158716154297}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,913] Trial 647 finished with value: 23.190421202476955 and parameters: {'x': 0.9713138370801296, 'y': 0.4618947757603027}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,921] Trial 648 finished with value: 0.4678051777020898 and parameters: {'x': 0.8687204489324944, 'y': 0.8217997934143718}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,929] Trial 649 finished with value: 79.43535090655814 and parameters: {'x': 0.4772707759867786, 'y': 1.117518280255521}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,937] Trial 650 finished with value: 10.627909551144159 and parameters: {'x': 0.7765242619752343, 'y': 0.9282278138478609}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,945] Trial 651 finished with value: 224.34478895085843 and parameters: {'x': 0.7068220930534255, 'y': 1.9971248855542427}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,953] Trial 652 finished with value: 54.1172428709925 and parameters: {'x': 1.1525756693107294, 'y': 0.5929446876509971}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,961] Trial 653 finished with value: 16.751652715602315 and parameters: {'x': 0.5848550027049706, 'y': 0.7492323301531822}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,970] Trial 654 finished with value: 5.017487733363792 and parameters: {'x': 0.9489601882112538, 'y': 0.6765861016898967}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,978] Trial 655 finished with value: 0.7728656517833512 and parameters: {'x': 0.8488022416096572, 'y': 0.8070680680431225}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,986] Trial 656 finished with value: 1.4973344600713006 and parameters: {'x': 1.0516559018259362, 'y': 0.9837235970476846}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:49,994] Trial 657 finished with value: 4.779719033421201 and parameters: {'x': 0.8070904646463849, 'y': 0.869167949053269}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,002] Trial 658 finished with value: 8.129305857898238 and parameters: {'x': 0.8940135207100972, 'y': 0.5143378573062318}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,010] Trial 659 finished with value: 2.8941805165730994 and parameters: {'x': 0.7365529731959142, 'y': 0.7105809871072097}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,018] Trial 660 finished with value: 13.281843252914076 and parameters: {'x': 0.9937794071176768, 'y': 0.6231554082015833}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,026] Trial 661 finished with value: 0.3593232141150985 and parameters: {'x': 0.9191411842192914, 'y': 0.7854248040543585}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,034] Trial 662 finished with value: 14.621591439201902 and parameters: {'x': 0.8259841193149022, 'y': 1.0642354969325676}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,042] Trial 663 finished with value: 20.60124708587124 and parameters: {'x': 0.6674992400552711, 'y': 0.8982216726055859}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,050] Trial 664 finished with value: 0.08261419320485297 and parameters: {'x': 0.756626263551846, 'y': 0.557191665239269}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,058] Trial 665 finished with value: 3.886906205473601 and parameters: {'x': -0.7704953201770041, 'y': 0.6803955309826129}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,066] Trial 666 finished with value: 2.626768814236965 and parameters: {'x': 0.9706056187934506, 'y': 0.7800288299202061}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,074] Trial 667 finished with value: 1.3243148661998478 and parameters: {'x': 0.8678608555052818, 'y': 0.6388647444268509}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,083] Trial 668 finished with value: 635.0519781264951 and parameters: {'x': -1.8605357068142996, 'y': 0.9578572804318872}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,091] Trial 669 finished with value: 14.17471857354018 and parameters: {'x': 1.1055401449900009, 'y': 0.8458736940080313}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,099] Trial 670 finished with value: 0.9431627353547001 and parameters: {'x': 0.8025959895424284, 'y': 0.7392494591387833}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,107] Trial 671 finished with value: 8.537633933913883 and parameters: {'x': 0.9154463105959036, 'y': 0.5459720140485129}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,115] Trial 672 finished with value: 13.322586130126432 and parameters: {'x': 1.0335075663190039, 'y': 0.7031520902830141}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,123] Trial 673 finished with value: 0.1661583237094657 and parameters: {'x': 0.7036636615097013, 'y': 0.46715271140937953}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,131] Trial 674 finished with value: 27.516379140742146 and parameters: {'x': 0.5740498829648795, 'y': 0.8523615921403599}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,140] Trial 675 finished with value: 0.33033403151749197 and parameters: {'x': 0.8249004623394736, 'y': 0.6257182679449736}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,148] Trial 676 finished with value: 0.9127032747881945 and parameters: {'x': 0.9342149478683309, 'y': 0.7774488283135673}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,156] Trial 677 finished with value: 38.79505439863055 and parameters: {'x': 0.7509855693333873, 'y': 1.1863381142457294}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,164] Trial 678 finished with value: 4.019322451831701 and parameters: {'x': 0.863869460992284, 'y': 0.9462902178622761}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,172] Trial 679 finished with value: 7.427550763879732 and parameters: {'x': 0.9965651445489206, 'y': 0.7206069709567506}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,180] Trial 680 finished with value: 1.9526294408027272 and parameters: {'x': 0.6764955738367138, 'y': 0.5935864808943543}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,188] Trial 681 finished with value: 0.35012386864053585 and parameters: {'x': 0.8988785292193918, 'y': 0.8662834093245378}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,196] Trial 682 finished with value: 60.86832058862858 and parameters: {'x': -1.2404046353627152, 'y': 0.7912823921120085}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,205] Trial 683 finished with value: 0.16901603911495006 and parameters: {'x': 0.7981820020573018, 'y': 0.6729114785231287}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,213] Trial 684 finished with value: 61.031440450450354 and parameters: {'x': -0.5209896881323028, 'y': 1.0377071686580526}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,221] Trial 685 finished with value: 1.6975521540524203 and parameters: {'x': 1.028355286344442, 'y': 0.9272553099941065}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,229] Trial 686 finished with value: 3.7305329521195487 and parameters: {'x': 0.7442891108079652, 'y': 0.745411961882907}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,237] Trial 687 finished with value: 45.94426377484166 and parameters: {'x': 1.1549395361698815, 'y': 0.6562404582885383}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,245] Trial 688 finished with value: 12.130988188949692 and parameters: {'x': 0.9517567096145916, 'y': 0.5575785656843251}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,253] Trial 689 finished with value: 1.7102256836815255 and parameters: {'x': 0.838577568993855, 'y': 0.8329878562654098}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,262] Trial 690 finished with value: 0.6639707066316798 and parameters: {'x': 0.6280868298985262, 'y': 0.466994879699412}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,270] Trial 691 finished with value: 0.5629513194975175 and parameters: {'x': 0.8864432665742891, 'y': 0.7116158919005744}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,278] Trial 692 finished with value: 17.27112257743762 and parameters: {'x': 0.7669906884852744, 'y': 1.003206388166642}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,286] Trial 693 finished with value: 6.005709110511432 and parameters: {'x': 1.070681050188557, 'y': 0.9013943772190172}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,294] Trial 694 finished with value: 1.7969580012034296 and parameters: {'x': 0.9626645428622864, 'y': 0.7927243629550029}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,303] Trial 695 finished with value: 125.25579128987282 and parameters: {'x': 1.3126576691593064, 'y': 0.6043296303119579}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,311] Trial 696 finished with value: 0.19962834700225085 and parameters: {'x': 0.8485885746907528, 'y': 0.6780665217924373}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,319] Trial 697 finished with value: 6.6888473716354095 and parameters: {'x': 0.7277680101901565, 'y': 0.7868375890164055}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,327] Trial 698 finished with value: 185.45711608655193 and parameters: {'x': 0.9226831669379454, 'y': -0.5104602314897873}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,335] Trial 699 finished with value: 4.17993679659373 and parameters: {'x': 0.8138021768128335, 'y': 0.8658732749102561}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,343] Trial 700 finished with value: 0.8159222817575352 and parameters: {'x': 0.6674913253086205, 'y': 0.5295303980911634}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,352] Trial 701 finished with value: 805.7956519025026 and parameters: {'x': 0.984453769229296, 'y': -1.8695043483107812}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,360] Trial 702 finished with value: 0.25067677693354423 and parameters: {'x': 0.8818638993273423, 'y': 0.7290299917061035}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,368] Trial 703 finished with value: 13.599076957638754 and parameters: {'x': -0.9661922015117561, 'y': 0.6215471596020168}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,377] Trial 704 finished with value: 67.63014923503492 and parameters: {'x': 0.5298947750729952, 'y': 1.1018192291535274}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,385] Trial 705 finished with value: 12.740099863480644 and parameters: {'x': 0.7862788611268011, 'y': 0.9745267872304907}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,393] Trial 706 finished with value: 11.53259030598787 and parameters: {'x': 1.0755710549598057, 'y': 0.8173405124439338}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,401] Trial 707 finished with value: 0.6590136466505074 and parameters: {'x': 0.8806159553721487, 'y': 0.695187443692299}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,409] Trial 708 finished with value: 1.1310007258379113 and parameters: {'x': 0.9902398338287187, 'y': 0.8742308894112848}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,418] Trial 709 finished with value: 0.8714915301952211 and parameters: {'x': 0.6929993168220501, 'y': 0.568409388786489}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,426] Trial 710 finished with value: 1.7696718559115865 and parameters: {'x': 0.7979182992328108, 'y': 0.7681587765135744}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,434] Trial 711 finished with value: 2.5727165084926313 and parameters: {'x': 0.8995679134971256, 'y': 0.6491402675744918}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,443] Trial 712 finished with value: 31.76068249446921 and parameters: {'x': 1.0213449515480053, 'y': 0.4795833849278456}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,451] Trial 713 finished with value: 4.320210124963869 and parameters: {'x': 0.839154640798158, 'y': 0.9114083783962731}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,459] Trial 714 finished with value: 15.286225285331273 and parameters: {'x': 0.5937411586158251, 'y': 0.7413881658506617}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,467] Trial 715 finished with value: 799.6117453270282 and parameters: {'x': 1.2009925004622524, 'y': -1.38528627904424}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,476] Trial 716 finished with value: 7.959941854814756 and parameters: {'x': 0.7390412857490931, 'y': 0.8271062538955886}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,484] Trial 717 finished with value: 5.771030301532735 and parameters: {'x': 0.9416078575869316, 'y': 0.646466646212975}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,492] Trial 718 finished with value: 12.465185385046146 and parameters: {'x': 0.8220814853022882, 'y': 1.0284300837986513}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,500] Trial 719 finished with value: 367.22431839329414 and parameters: {'x': 1.0841289445813795, 'y': -0.7409557473545965}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,509] Trial 720 finished with value: 2.668929084135403 and parameters: {'x': 0.9359182836287698, 'y': 0.7127001894455764}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,517] Trial 721 finished with value: 0.22522587952787024 and parameters: {'x': 0.7290549344473137, 'y': 0.5704844970601469}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,525] Trial 722 finished with value: 3.898524029097707 and parameters: {'x': 0.8513809457546277, 'y': 0.9217361930080088}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,534] Trial 723 finished with value: 3.4850425390673685 and parameters: {'x': 0.9884869227939632, 'y': 0.7904272603646015}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,542] Trial 724 finished with value: 0.2965380093329443 and parameters: {'x': 0.6397258992836092, 'y': 0.45008310696121256}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,550] Trial 725 finished with value: 71.99350196508705 and parameters: {'x': 0.7637898041360317, 'y': 1.4315358561559228}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,559] Trial 726 finished with value: 3.4572081782544837 and parameters: {'x': 0.914496811097153, 'y': 0.6505654236756815}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,567] Trial 727 finished with value: 1.9187837329265676 and parameters: {'x': 0.8375607195297918, 'y': 0.8390723879166103}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,576] Trial 728 finished with value: 12.067828551814715 and parameters: {'x': 1.0394981503674696, 'y': 0.7331910573541343}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,584] Trial 729 finished with value: 24.06689288029543 and parameters: {'x': 0.6834550128541658, 'y': 0.9566686383172014}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,592] Trial 730 finished with value: 48.82893606309111 and parameters: {'x': 1.1192962123502674, 'y': 0.5541488040592254}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,601] Trial 731 finished with value: 2.7941702916268474 and parameters: {'x': 0.7811547372053153, 'y': 0.7759216735690023}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,609] Trial 732 finished with value: 6.221608586547756 and parameters: {'x': 0.9365523330255612, 'y': 0.6277794557714077}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,617] Trial 733 finished with value: 0.5751413947389508 and parameters: {'x': 0.878908013436951, 'y': 0.8473443831088936}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,626] Trial 734 finished with value: 1.0254768887424273 and parameters: {'x': 0.7718333319684813, 'y': 0.6943885826672094}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,634] Trial 735 finished with value: 1.3994694298735892 and parameters: {'x': 1.0114535208303574, 'y': 0.9047445966228582}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,642] Trial 736 finished with value: 44.00726138957321 and parameters: {'x': 0.6229652600813957, 'y': 1.050393092506884}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,650] Trial 737 finished with value: 0.018233168678764504 and parameters: {'x': 0.866340003907855, 'y': 0.7486262159748933}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,659] Trial 738 finished with value: 1.4743777297986815 and parameters: {'x': 0.9600967642206983, 'y': 0.8004274240027424}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,667] Trial 739 finished with value: 1.3092218863179244 and parameters: {'x': 0.8760188857950792, 'y': 0.8811566407549004}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,675] Trial 740 finished with value: 15.195476577991844 and parameters: {'x': 1.0716414692403884, 'y': 0.7586675190646646}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,684] Trial 741 finished with value: 0.2727596432682157 and parameters: {'x': 0.9408550305540876, 'y': 0.8333177736181581}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,692] Trial 742 finished with value: 13.080398181032105 and parameters: {'x': 1.1544590154987617, 'y': 0.9714372646542782}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,701] Trial 743 finished with value: 0.03358291246195506 and parameters: {'x': 0.8554692270848987, 'y': 0.7205609360985707}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,709] Trial 744 finished with value: 0.7306782785781157 and parameters: {'x': 1.0024610402940706, 'y': 0.9194487700976699}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,717] Trial 745 finished with value: 289.9617955654454 and parameters: {'x': 0.8850301796814725, 'y': -0.9195092293105704}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,726] Trial 746 finished with value: 2.9473697179313936 and parameters: {'x': 0.955389622843309, 'y': 0.7411482478781228}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,734] Trial 747 finished with value: 1.4557949247745567 and parameters: {'x': 0.8442749200396807, 'y': 0.8324473145924336}. Best is trial 463 with value: 0.013506784418543725.\n",
      "[I 2025-06-17 13:59:50,743] Trial 748 finished with value: 0.0059042407468668226 and parameters: {'x': 1.0768332892388228, 'y': 1.1594757833779483}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,751] Trial 749 finished with value: 1.8548992167074825 and parameters: {'x': 1.2925518909489724, 'y': 1.5376748801284115}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,760] Trial 750 finished with value: 41.209478812825004 and parameters: {'x': 1.2574418107254013, 'y': 0.9397302344661806}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,768] Trial 751 finished with value: 1.8359800788324663 and parameters: {'x': 1.1398138446731003, 'y': 1.433950678607884}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,776] Trial 752 finished with value: 2.4211259859127683 and parameters: {'x': 1.108496701313006, 'y': 1.3839858906816913}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,785] Trial 753 finished with value: 2.9454600201858057 and parameters: {'x': 1.1759080837606313, 'y': 1.2120402746449972}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,793] Trial 754 finished with value: 1.0256497818476338 and parameters: {'x': 1.05938424055527, 'y': 1.2233950825799929}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,802] Trial 755 finished with value: 0.22340999389931301 and parameters: {'x': 1.0667925500177202, 'y': 1.1848383044631374}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,810] Trial 756 finished with value: 0.02363019075533095 and parameters: {'x': 1.012818403328016, 'y': 1.0411196948460477}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,819] Trial 757 finished with value: 1.299445273264058 and parameters: {'x': 1.1347402098910546, 'y': 1.17444124740572}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,827] Trial 758 finished with value: 0.4389762232235165 and parameters: {'x': 1.0743723498281006, 'y': 1.0884394078304562}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,836] Trial 759 finished with value: 0.6731911630360403 and parameters: {'x': 1.0128589508363146, 'y': 1.1079214045864907}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,844] Trial 760 finished with value: 7.796306109182257 and parameters: {'x': 1.0195224110717238, 'y': 1.3186377835442105}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,852] Trial 761 finished with value: 26.09666093454751 and parameters: {'x': 1.2576753319848026, 'y': 1.0715486091890933}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,861] Trial 762 finished with value: 1.5331051929144814 and parameters: {'x': 0.9962191231630991, 'y': 1.116270589227916}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,869] Trial 763 finished with value: 24.9855654814528 and parameters: {'x': 0.9016760705783999, 'y': 1.312778656998055}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,878] Trial 764 finished with value: 1.1873149012849724 and parameters: {'x': 1.1488807629125122, 'y': 1.2119849201529012}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,886] Trial 765 finished with value: 72.75827590963458 and parameters: {'x': 1.4648058906905752, 'y': 1.2939390239265443}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,895] Trial 766 finished with value: 15.817515122384288 and parameters: {'x': 0.9288879446904786, 'y': 1.2604816311914537}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,903] Trial 767 finished with value: 0.8193157029533548 and parameters: {'x': 1.035739852592195, 'y': 1.1632025156496386}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,912] Trial 768 finished with value: 8.819934232343636 and parameters: {'x': 1.1755008634908488, 'y': 1.0853375489569699}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,920] Trial 769 finished with value: 5.869984489367441 and parameters: {'x': 0.8848607308989952, 'y': 1.0249852782420956}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,929] Trial 770 finished with value: 3.89941152351139 and parameters: {'x': 0.9753040163093567, 'y': 1.1486717576156258}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,937] Trial 771 finished with value: 75.02847096948122 and parameters: {'x': 1.3660786906503144, 'y': 1.000755150496491}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,946] Trial 772 finished with value: 2.010905052661561 and parameters: {'x': 0.8391002171739735, 'y': 0.8449797814069436}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,954] Trial 773 finished with value: 0.896832405728346 and parameters: {'x': 1.0642071497823755, 'y': 1.0380535338471015}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,963] Trial 774 finished with value: 2.019811644231244 and parameters: {'x': 0.9461504039972978, 'y': 0.7531825647039212}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,971] Trial 775 finished with value: 8.497738637369292 and parameters: {'x': 0.8342557508763093, 'y': 0.9870198974333082}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,980] Trial 776 finished with value: 0.4630390414693912 and parameters: {'x': 0.9034172102060863, 'y': 0.8835207143224478}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,988] Trial 777 finished with value: 5.157491945269911 and parameters: {'x': 0.7398510738104681, 'y': 0.7729857833525247}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:50,997] Trial 778 finished with value: 65.89635813992258 and parameters: {'x': 1.0007909153699535, 'y': 1.8133481707291672}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,005] Trial 779 finished with value: 52.45985387472556 and parameters: {'x': 1.1921617768282722, 'y': 0.6972129093756393}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,014] Trial 780 finished with value: 3.4026379136618417 and parameters: {'x': 0.7811559215974272, 'y': 0.7933642086741072}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,023] Trial 781 finished with value: 0.47666514867415566 and parameters: {'x': 0.9019437228184546, 'y': 0.8818435440325534}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,031] Trial 782 finished with value: 0.04092013286346743 and parameters: {'x': 0.8241647347962197, 'y': 0.6892485562140953}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,040] Trial 783 finished with value: 3.6829137038421327 and parameters: {'x': 1.0888998774403096, 'y': 0.9939997736938841}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,048] Trial 784 finished with value: 3.2518011662416573 and parameters: {'x': 0.7145981505149989, 'y': 0.6887051979427317}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,057] Trial 785 finished with value: 2.206338689083538 and parameters: {'x': 0.9702941416547725, 'y': 0.7929629353025922}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,065] Trial 786 finished with value: 0.12131294822735156 and parameters: {'x': 0.8183936201643205, 'y': 0.6400474057188547}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,074] Trial 787 finished with value: 0.921036303559475 and parameters: {'x': 0.8939834784276767, 'y': 0.8945897287121608}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,083] Trial 788 finished with value: 7.678741790089504 and parameters: {'x': 1.0199049350758045, 'y': 0.7631077982925817}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,091] Trial 789 finished with value: 24.764584596580498 and parameters: {'x': 0.7901884218049914, 'y': 1.121595526525711}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,100] Trial 790 finished with value: 3.4510178951349197 and parameters: {'x': 0.9407190693980202, 'y': 0.699277822520832}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,108] Trial 791 finished with value: 10.627267590828797 and parameters: {'x': 0.7074179422526893, 'y': 0.8251194226214505}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,117] Trial 792 finished with value: 1.483451285984712 and parameters: {'x': 0.8504090055630741, 'y': 0.6023205901712442}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,125] Trial 793 finished with value: 24.758660764949614 and parameters: {'x': 1.0987588979245988, 'y': 0.7097883779269502}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,134] Trial 794 finished with value: 3.8917662013376697 and parameters: {'x': 0.8882260581905779, 'y': 0.9859042263032594}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,143] Trial 795 finished with value: 9.601368348362673 and parameters: {'x': 0.7795829183155776, 'y': 0.916825320768716}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,151] Trial 796 finished with value: 1.6063894147478321 and parameters: {'x': 0.9838414162606596, 'y': 0.8412108145423434}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,160] Trial 797 finished with value: 66.50223523651597 and parameters: {'x': 1.2074850976429496, 'y': 0.6427952296993613}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,169] Trial 798 finished with value: 0.35868647147951754 and parameters: {'x': 0.8415155161422855, 'y': 0.765903808660714}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,177] Trial 799 finished with value: 36.291035819154324 and parameters: {'x': 0.6756086658764896, 'y': 1.0579934606483508}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,186] Trial 800 finished with value: 11.749416835317138 and parameters: {'x': 0.9613394831633681, 'y': 0.5814211810402485}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,195] Trial 801 finished with value: 14.69619693343235 and parameters: {'x': 1.0447363562451144, 'y': 0.7081439666439736}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,203] Trial 802 finished with value: 8.839647107968396 and parameters: {'x': 0.750298985560922, 'y': 0.859213592860855}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,212] Trial 803 finished with value: 1.4332266100796724 and parameters: {'x': 0.9065439924084223, 'y': 0.9411741188555076}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,221] Trial 804 finished with value: 121.96869607306859 and parameters: {'x': 0.8287651494360181, 'y': -0.4174099568538775}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,229] Trial 805 finished with value: 0.6233122446991384 and parameters: {'x': 0.9197964038751297, 'y': 0.7674837396068396}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,238] Trial 806 finished with value: 0.9317797204521202 and parameters: {'x': 0.7888602849117327, 'y': 0.528109268136369}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,247] Trial 807 finished with value: 30.711368710361693 and parameters: {'x': -0.3654655548773419, 'y': 0.6706579178610784}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,255] Trial 808 finished with value: 6.557988207231361 and parameters: {'x': 1.0388225264680604, 'y': 0.8230959777844088}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,264] Trial 809 finished with value: 64.8940513060048 and parameters: {'x': 0.6727428225494598, 'y': 1.2574863407784065}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,273] Trial 810 finished with value: 20.416392894342682 and parameters: {'x': 0.4466202257859391, 'y': 0.6479131980032758}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,281] Trial 811 finished with value: 11.27802473849505 and parameters: {'x': 1.1182760474654365, 'y': 0.9149219578222842}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,290] Trial 812 finished with value: 0.028902443483709753 and parameters: {'x': 0.8645075631321716, 'y': 0.7371048102496102}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,299] Trial 813 finished with value: 2.9409835216485534 and parameters: {'x': 0.9911935467476383, 'y': 0.8109739485900249}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,307] Trial 814 finished with value: 4.1282641058335825 and parameters: {'x': 0.8991418863246624, 'y': 1.0113869511558875}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,316] Trial 815 finished with value: 3.7433132465493797 and parameters: {'x': 0.9653933289519784, 'y': 0.7385387930812043}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,324] Trial 816 finished with value: 2.586435053970941 and parameters: {'x': 0.8480668151519197, 'y': 0.8793220187491727}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,333] Trial 817 finished with value: 8.628186762116302 and parameters: {'x': 1.0329043896104164, 'y': 0.7731721551972823}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,342] Trial 818 finished with value: 604.7542970056331 and parameters: {'x': 1.847424949751074, 'y': 0.9552642179039555}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,350] Trial 819 finished with value: 0.009700073845187828 and parameters: {'x': 0.9164647363816838, 'y': 0.845124828358703}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,359] Trial 820 finished with value: 4.077482398390312 and parameters: {'x': 1.1352635040067995, 'y': 1.0873490022786867}. Best is trial 748 with value: 0.0059042407468668226.\n",
      "[I 2025-06-17 13:59:51,368] Trial 821 finished with value: 0.003505305891520332 and parameters: {'x': 0.9486588072649302, 'y': 0.902902070917267}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,376] Trial 822 finished with value: 3.9471056402990254 and parameters: {'x': 1.084956433583345, 'y': 0.9786389504946047}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,385] Trial 823 finished with value: 17.1425165588742 and parameters: {'x': 1.1957899495891768, 'y': 1.0163415680414754}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,393] Trial 824 finished with value: 1.1016692509177326 and parameters: {'x': 1.00838510137752, 'y': 0.9118834290224668}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,402] Trial 825 finished with value: 1.0051204008080283 and parameters: {'x': 1.080166645102796, 'y': 1.0668253170454485}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,411] Trial 826 finished with value: 0.021227077498303812 and parameters: {'x': 0.9551280935562401, 'y': 0.9261309843857253}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,420] Trial 827 finished with value: 1.2888253522402042 and parameters: {'x': 1.0195384419645666, 'y': 1.152968264258199}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,429] Trial 828 finished with value: 8.887240905581331 and parameters: {'x': 1.141628342855992, 'y': 1.0055371289825392}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,437] Trial 829 finished with value: 315.7966368211336 and parameters: {'x': 1.649514680696861, 'y': 0.9450192729198509}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,446] Trial 830 finished with value: 3.9186845508671695 and parameters: {'x': 0.9631617149766596, 'y': 1.1256028853934639}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,455] Trial 831 finished with value: 0.08273480480748033 and parameters: {'x': 1.031880691972759, 'y': 1.0361913275211192}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,464] Trial 832 finished with value: 0.25460764401861713 and parameters: {'x': 0.9492611032356051, 'y': 0.9512995512323583}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,473] Trial 833 finished with value: 10.127236331571225 and parameters: {'x': 1.1036193703644552, 'y': 0.8999112658654604}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,481] Trial 834 finished with value: 52.84777700357149 and parameters: {'x': 1.2645579024569196, 'y': 0.8726234739956017}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,490] Trial 835 finished with value: 2.061071618229883 and parameters: {'x': 0.9446321151398989, 'y': 1.0357873533405868}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,499] Trial 836 finished with value: 5.97649529737877 and parameters: {'x': 1.0576995292779865, 'y': 0.8743276792254215}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,508] Trial 837 finished with value: 113.9926994155405 and parameters: {'x': -1.4061850720621432, 'y': 0.9371498773374597}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,516] Trial 838 finished with value: 8.04628731121011 and parameters: {'x': 0.9253758041567608, 'y': 1.1398819866974845}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,525] Trial 839 finished with value: 38.474216795610644 and parameters: {'x': 1.2148387987275515, 'y': 0.8559295959340099}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,534] Trial 840 finished with value: 0.04861746794962285 and parameters: {'x': 1.0002511588280174, 'y': 0.9784530259006823}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,543] Trial 841 finished with value: 0.010595753201210069 and parameters: {'x': 0.9146645948748036, 'y': 0.8423677278381161}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,552] Trial 842 finished with value: 0.008049887338705554 and parameters: {'x': 0.9125094216252605, 'y': 0.8346616247136034}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,561] Trial 843 finished with value: 5.381656378756802 and parameters: {'x': 1.0881977671739362, 'y': 0.9523581271129458}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,569] Trial 844 finished with value: 0.015803219463327335 and parameters: {'x': 0.9286393048092703, 'y': 0.8520216248130615}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,578] Trial 845 finished with value: 0.23158485753471422 and parameters: {'x': 0.9926866659828473, 'y': 1.0335445238187364}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,587] Trial 846 finished with value: 12.29218395395553 and parameters: {'x': 1.1154427301545216, 'y': 0.89380048488797}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,596] Trial 847 finished with value: 0.1417622513272508 and parameters: {'x': 1.020326774185284, 'y': 1.0786631453076785}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,605] Trial 848 finished with value: 0.18089083294000782 and parameters: {'x': 0.9487120940764597, 'y': 0.857833744082875}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,614] Trial 849 finished with value: 1.0805333020453909 and parameters: {'x': 0.9379789732876431, 'y': 0.9835680688370542}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,623] Trial 850 finished with value: 3.1224444111175185 and parameters: {'x': 1.047259822629058, 'y': 0.9201119483625907}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,631] Trial 851 finished with value: 26.870530335709496 and parameters: {'x': 1.1580368057213797, 'y': 0.822922283059296}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,640] Trial 852 finished with value: 12.974603631162317 and parameters: {'x': 0.9113087423474582, 'y': 1.19057718799771}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,649] Trial 853 finished with value: 1.7348889443073128 and parameters: {'x': 0.993640924832208, 'y': 0.8556086395194928}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,658] Trial 854 finished with value: 2.0366671241940635 and parameters: {'x': 0.8960983408587931, 'y': 0.9453253517309166}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,667] Trial 855 finished with value: 1.3453915335409143 and parameters: {'x': 1.0774050543964357, 'y': 1.0450692015502845}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,676] Trial 856 finished with value: 0.15180805562382876 and parameters: {'x': 0.8986568215397793, 'y': 0.8452055682246451}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,685] Trial 857 finished with value: 2.0224172272972285 and parameters: {'x': 0.9813726177447576, 'y': 0.8208926984068716}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,694] Trial 858 finished with value: 3.09183431793036 and parameters: {'x': 0.891196478039799, 'y': 0.9697303394355469}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,703] Trial 859 finished with value: 3.143143108474079 and parameters: {'x': 1.0257102740632686, 'y': 0.8748110924581906}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,712] Trial 860 finished with value: 4.16340618223399 and parameters: {'x': 1.1484470026382196, 'y': 1.1154269633631024}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,721] Trial 861 finished with value: 0.008171389232091188 and parameters: {'x': 0.9601992747187253, 'y': 0.9138664340760865}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,730] Trial 862 finished with value: 29.05580734582396 and parameters: {'x': 1.250034944456413, 'y': 1.0241331872239594}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,739] Trial 863 finished with value: 3.5991818124402806 and parameters: {'x': 1.0909309655458093, 'y': 1.0006333169408628}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,748] Trial 864 finished with value: 1.7211567943057184 and parameters: {'x': 1.0310543089544217, 'y': 0.9319168816287189}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,756] Trial 865 finished with value: 0.023790999751257105 and parameters: {'x': 0.9667624997545485, 'y': 0.919567769462887}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,765] Trial 866 finished with value: 14.018225747291828 and parameters: {'x': 1.1972728510111137, 'y': 1.0595731361769511}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,774] Trial 867 finished with value: 6.462656021092697 and parameters: {'x': 1.1010361736702405, 'y': 0.958263969020598}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,783] Trial 868 finished with value: 0.02903017971055558 and parameters: {'x': 1.042248414185728, 'y': 1.0697756212833311}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,792] Trial 869 finished with value: 19.469449281627703 and parameters: {'x': 1.2925048322960928, 'y': 1.2302973456094586}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,801] Trial 870 finished with value: 6.640964594107681 and parameters: {'x': 1.1645777710175387, 'y': 1.0990667601952384}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,810] Trial 871 finished with value: 0.33994580774139477 and parameters: {'x': 1.0976668450082019, 'y': 1.1473914627016417}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,819] Trial 872 finished with value: 1.4036918612303677 and parameters: {'x': 1.1704170162487257, 'y': 1.252630527116619}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,828] Trial 873 finished with value: 0.09206521706062722 and parameters: {'x': 1.0526267675959982, 'y': 1.0781407357169592}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,837] Trial 874 finished with value: 1.5464274884480236 and parameters: {'x': 1.021649796321479, 'y': 1.1681048968659755}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,846] Trial 875 finished with value: 27.451186643172313 and parameters: {'x': 1.2233900469846213, 'y': 0.9732208537816359}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,855] Trial 876 finished with value: 1.6413970680418646 and parameters: {'x': 1.0736455423193, 'y': 1.0248095746445525}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,864] Trial 877 finished with value: 2.5495284655505035 and parameters: {'x': 0.9665412911931298, 'y': 1.0938394372775877}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,873] Trial 878 finished with value: 2.4049016398702348 and parameters: {'x': 1.148013455412586, 'y': 1.1635654131171462}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,882] Trial 879 finished with value: 0.0487017788434444 and parameters: {'x': 0.981180807051333, 'y': 0.9847038676347664}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,891] Trial 880 finished with value: 1.5234281097094835 and parameters: {'x': 1.0744127937974566, 'y': 1.031160138606631}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,900] Trial 881 finished with value: 0.4589941173242563 and parameters: {'x': 0.993379239853734, 'y': 0.9190564447145814}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,909] Trial 882 finished with value: 15.685425090881195 and parameters: {'x': 0.9735391562033439, 'y': 1.3438179426884513}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,918] Trial 883 finished with value: 70.95160935511909 and parameters: {'x': 1.3264553048148828, 'y': 0.9177887410956173}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,927] Trial 884 finished with value: 1.9157776986501778 and parameters: {'x': 1.1079941500440755, 'y': 1.089661364374647}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,937] Trial 885 finished with value: 1.1247359729381619 and parameters: {'x': 1.0290243329509445, 'y': 0.9528772314908499}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,946] Trial 886 finished with value: 2.1517620965592372 and parameters: {'x': 0.9402653759955363, 'y': 1.030666158863194}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,955] Trial 887 finished with value: 0.10294384916236933 and parameters: {'x': 0.9373472544404141, 'y': 0.9100870777987132}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,963] Trial 888 finished with value: 0.9306854068905246 and parameters: {'x': 1.0465082964348018, 'y': 1.191539480906387}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,972] Trial 889 finished with value: 16.21194758028469 and parameters: {'x': 1.1392903602115108, 'y': 0.8955829004197962}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,982] Trial 890 finished with value: 0.9790174059822637 and parameters: {'x': 0.9514203070272016, 'y': 1.0040265799719268}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:51,991] Trial 891 finished with value: 2.383618718901117 and parameters: {'x': 1.0290895014571457, 'y': 0.9046628840749811}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,000] Trial 892 finished with value: 12.101578950200674 and parameters: {'x': 1.2007161025586264, 'y': 1.0944254504434907}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,009] Trial 893 finished with value: 0.0355115426555914 and parameters: {'x': 0.9060062598528584, 'y': 0.837180352250532}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,018] Trial 894 finished with value: 0.08697046114817396 and parameters: {'x': 0.9946699853911471, 'y': 0.9598824421570822}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,027] Trial 895 finished with value: 0.08167909496949537 and parameters: {'x': 0.9113504915774476, 'y': 0.8577296208953974}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,037] Trial 896 finished with value: 3.689655157865886 and parameters: {'x': 1.0997953217657879, 'y': 1.0177244112113004}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,046] Trial 897 finished with value: 9.972056424993374 and parameters: {'x': 0.9783051612184488, 'y': 1.2728591662903233}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,055] Trial 898 finished with value: 0.860206900397219 and parameters: {'x': 0.88213081948301, 'y': 0.870150095425486}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,064] Trial 899 finished with value: 0.17348540276713773 and parameters: {'x': 1.0577741492784556, 'y': 1.160135096376438}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,073] Trial 900 finished with value: 0.44291481365983615 and parameters: {'x': 0.9450121453410015, 'y': 0.9593722452264335}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,082] Trial 901 finished with value: 0.22350887725459168 and parameters: {'x': 0.8845723856953139, 'y': 0.8283142806154542}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,091] Trial 902 finished with value: 27.565314911843704 and parameters: {'x': 1.0098086774992072, 'y': 1.5447394569112798}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,101] Trial 903 finished with value: 2.6794951017956565 and parameters: {'x': 1.1075478982519003, 'y': 1.0633243981357283}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,110] Trial 904 finished with value: 1.5957818110302515 and parameters: {'x': 0.8810850608644203, 'y': 0.9020741958327899}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,119] Trial 905 finished with value: 1.141290314006438 and parameters: {'x': 0.970638403127449, 'y': 0.8353480761879322}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,128] Trial 906 finished with value: 92.11547890014545 and parameters: {'x': -0.22197045221334655, 'y': 1.0012281659604187}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,137] Trial 907 finished with value: 52.63806136676386 and parameters: {'x': 1.2400602136844237, 'y': 0.812625671967537}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,146] Trial 908 finished with value: 0.01785921731679417 and parameters: {'x': 1.0566321840723338, 'y': 1.1043670224283169}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,155] Trial 909 finished with value: 0.05162332579024579 and parameters: {'x': 1.0860230197747403, 'y': 1.1584166471703439}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,165] Trial 910 finished with value: 1.1917452277466243 and parameters: {'x': 1.1695022980961154, 'y': 1.2598924892309853}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,174] Trial 911 finished with value: 18.680115914227944 and parameters: {'x': 1.253034588970829, 'y': 1.1386320162790997}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,183] Trial 912 finished with value: 1.0330031614734645 and parameters: {'x': 1.1463233635490016, 'y': 1.2134792922783462}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,192] Trial 913 finished with value: 0.008144278373287857 and parameters: {'x': 1.0547046404426856, 'y': 1.1052243576293073}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,201] Trial 914 finished with value: 18.665635514755728 and parameters: {'x': 1.2901767738971706, 'y': 1.233494245120115}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,211] Trial 915 finished with value: 8.486872869137896 and parameters: {'x': 1.1802746488998699, 'y': 1.1022841857810146}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,220] Trial 916 finished with value: 75.87201948996162 and parameters: {'x': 1.4038585204048792, 'y': 1.1007100292010854}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,229] Trial 917 finished with value: 0.03191084024870938 and parameters: {'x': 1.1142134979041671, 'y': 1.2277363204301046}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,238] Trial 918 finished with value: 0.07952689517458134 and parameters: {'x': 1.0447005963001612, 'y': 1.1192433212325976}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,247] Trial 919 finished with value: 12.34172524915384 and parameters: {'x': 1.1955118068907118, 'y': 1.078485021906085}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,256] Trial 920 finished with value: 5.612570621681496 and parameters: {'x': 1.0661511741285554, 'y': 1.37349459757726}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,266] Trial 921 finished with value: 0.8996850417144064 and parameters: {'x': 1.116488886421192, 'y': 1.1524137317234058}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,275] Trial 922 finished with value: 2.677318908503588 and parameters: {'x': 1.0508415881338704, 'y': 1.2678141848965283}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,284] Trial 923 finished with value: 20.68377612808405 and parameters: {'x': 1.2375816123323424, 'y': 1.0774350301660265}. Best is trial 821 with value: 0.003505305891520332.\n",
      "[I 2025-06-17 13:59:52,293] Trial 924 finished with value: 0.0007716307643246495 and parameters: {'x': 1.010916402769129, 'y': 1.0193976380242071}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,302] Trial 925 finished with value: 1.2246111788250322 and parameters: {'x': 1.138587627906439, 'y': 1.1865908647469898}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,311] Trial 926 finished with value: 5.106966949624917 and parameters: {'x': 1.0457091162396837, 'y': 1.3194473182527415}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,321] Trial 927 finished with value: 13.59493485923746 and parameters: {'x': 1.1865072190163861, 'y': 1.0395582924066404}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,330] Trial 928 finished with value: 3.995118239052475 and parameters: {'x': 1.104236233229063, 'y': 1.0197317208197783}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,339] Trial 929 finished with value: 0.32647512436534676 and parameters: {'x': 1.0368672115239497, 'y': 1.132112552685528}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,348] Trial 930 finished with value: 0.04041891067969417 and parameters: {'x': 1.0186994900479753, 'y': 1.0177313485704675}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,358] Trial 931 finished with value: 6.347504893155526 and parameters: {'x': 1.137053171050728, 'y': 1.0413204140263637}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,367] Trial 932 finished with value: 32.046687916717964 and parameters: {'x': 1.2973136342569778, 'y': 1.117706006405185}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,376] Trial 933 finished with value: 0.010797211044389946 and parameters: {'x': 0.9978843043079835, 'y': 0.9853842759612068}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,386] Trial 934 finished with value: 0.009193716821082007 and parameters: {'x': 1.08759977754459, 'y': 1.1867719884604455}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,395] Trial 935 finished with value: 5.3013276827508715 and parameters: {'x': 1.2409518079930053, 'y': 1.3109795147365606}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,404] Trial 936 finished with value: 6.748328339503552 and parameters: {'x': 1.1221735107934296, 'y': 0.9997853929824673}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,414] Trial 937 finished with value: 3.3318576000104514 and parameters: {'x': 1.1722153066153396, 'y': 1.1923691749819167}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,423] Trial 938 finished with value: 1.3965072232170943 and parameters: {'x': 1.0663395962685487, 'y': 1.2550676882012226}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,432] Trial 939 finished with value: 1.195755249232145 and parameters: {'x': 1.2109232520995676, 'y': 1.3590380288075827}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,441] Trial 940 finished with value: 2.146737345836344 and parameters: {'x': 1.0123910079923162, 'y': 1.1714477985845855}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,451] Trial 941 finished with value: 6.015944959197299 and parameters: {'x': 1.110150169994327, 'y': 0.9874066279471359}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,460] Trial 942 finished with value: 1.5686746122426554 and parameters: {'x': 0.9867470836117493, 'y': 1.0989095360342789}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,469] Trial 943 finished with value: 5.641636322115119 and parameters: {'x': 0.9836764904172489, 'y': 1.205135118653514}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,479] Trial 944 finished with value: 77.56554642527 and parameters: {'x': 1.3627917403170176, 'y': 0.9772358248659401}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,488] Trial 945 finished with value: 1.580061472439501 and parameters: {'x': 1.084226180388391, 'y': 1.0501284122099437}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,497] Trial 946 finished with value: 3.348724285556383 and parameters: {'x': 0.9844607316459232, 'y': 1.1521515333468735}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,507] Trial 947 finished with value: 20.39466291950851 and parameters: {'x': 1.18781545233896, 'y': 0.9596917605133519}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,516] Trial 948 finished with value: 0.9040480590793073 and parameters: {'x': 1.0763098259077775, 'y': 1.063668115308082}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,525] Trial 949 finished with value: 0.013808095149116023 and parameters: {'x': 0.9695123142795741, 'y': 0.951302517808196}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,534] Trial 950 finished with value: 0.030578184200398425 and parameters: {'x': 1.142822380420562, 'y': 1.295953418446156}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,544] Trial 951 finished with value: 0.2681892835325515 and parameters: {'x': 1.0114333833167193, 'y': 0.9712231167253552}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,553] Trial 952 finished with value: 0.03491584072248231 and parameters: {'x': 1.0715669149544993, 'y': 1.130994709622166}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,562] Trial 953 finished with value: 1.3491349996948043 and parameters: {'x': 0.9647056923441861, 'y': 1.0467557081279102}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,572] Trial 954 finished with value: 55.96374869399353 and parameters: {'x': 1.2999764987299112, 'y': 0.9424513535799299}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,581] Trial 955 finished with value: 354.51293942679473 and parameters: {'x': 1.7580376557075414, 'y': 1.209371550967786}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,591] Trial 956 finished with value: 11.822775912752762 and parameters: {'x': 1.1549448539155858, 'y': 0.9904042676883821}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,600] Trial 957 finished with value: 2.5279845249810626 and parameters: {'x': 0.9721730023259013, 'y': 1.1040923623277843}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,609] Trial 958 finished with value: 4.268852591229882 and parameters: {'x': 1.0730278704150866, 'y': 0.9449058932010639}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,619] Trial 959 finished with value: 22.95670052846725 and parameters: {'x': 1.2282960160423428, 'y': 1.0301237916858943}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,628] Trial 960 finished with value: 0.002142166845060843 and parameters: {'x': 0.9640177577095302, 'y': 0.9322413281858075}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,637] Trial 961 finished with value: 0.1190013869262551 and parameters: {'x': 1.0325194374342637, 'y': 1.1004393461985726}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,647] Trial 962 finished with value: 5.974437586103151 and parameters: {'x': 1.1256773840912069, 'y': 1.0230462592458807}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,656] Trial 963 finished with value: 5.60680929038009 and parameters: {'x': 0.9790825829723061, 'y': 1.1953804851639303}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,665] Trial 964 finished with value: 3.978995552625271 and parameters: {'x': 1.064880689302657, 'y': 0.9346022277223129}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,675] Trial 965 finished with value: 0.10648554351057257 and parameters: {'x': 0.9502818806767055, 'y': 0.9352868003377788}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,684] Trial 966 finished with value: 10.99584101398192 and parameters: {'x': 1.1834106171651222, 'y': 1.0693685330755565}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,693] Trial 967 finished with value: 0.1511223539933396 and parameters: {'x': 1.0208422854024384, 'y': 1.003300425436771}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,703] Trial 968 finished with value: 107.21119572034488 and parameters: {'x': 1.5535934191112957, 'y': 1.3797050758790188}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,712] Trial 969 finished with value: 4.807664204389146 and parameters: {'x': 0.9520810618526979, 'y': 1.1256698439257216}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,722] Trial 970 finished with value: 5.409239752322787 and parameters: {'x': 1.0760228393774514, 'y': 0.9253717086371138}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,731] Trial 971 finished with value: 0.9029899641446003 and parameters: {'x': 0.9630222143464137, 'y': 1.0223655955437843}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,741] Trial 972 finished with value: 0.3731286322910208 and parameters: {'x': 1.1300718456370442, 'y': 1.217379049713297}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,750] Trial 973 finished with value: 2.8348474822850713 and parameters: {'x': 1.0422415340344375, 'y': 0.9179503592356593}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,759] Trial 974 finished with value: 1.060987600518597 and parameters: {'x': 0.936940011229138, 'y': 0.9806676267695843}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,769] Trial 975 finished with value: 4.958289249694767 and parameters: {'x': 1.2222618854623761, 'y': 1.2723639915420208}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,778] Trial 976 finished with value: 2.0800403755218957 and parameters: {'x': 0.9985325117753001, 'y': 1.1412905531942004}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,788] Trial 977 finished with value: 4.277899828172986 and parameters: {'x': 0.926592533300322, 'y': 1.0652742591002005}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,797] Trial 978 finished with value: 16.809995706994094 and parameters: {'x': 1.154316857639145, 'y': 0.9227379740302661}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,806] Trial 979 finished with value: 3.6934525583080564 and parameters: {'x': 1.0509256972777827, 'y': 0.912328733073285}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,816] Trial 980 finished with value: 4.2230166452383635 and parameters: {'x': 1.1001487808843977, 'y': 1.0050717222064038}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,825] Trial 981 finished with value: 3.9154947278482735 and parameters: {'x': 0.9429444800432898, 'y': 1.0869381092203365}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,835] Trial 982 finished with value: 1.3051368501677216 and parameters: {'x': 1.0101144873324723, 'y': 0.9060931688461489}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,844] Trial 983 finished with value: 1.4491585134747547 and parameters: {'x': 0.9249879046551439, 'y': 0.9757496877684978}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,854] Trial 984 finished with value: 40.839652810044925 and parameters: {'x': 1.3408889507205028, 'y': 1.1598339202840011}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,863] Trial 985 finished with value: 2.6100555677272412 and parameters: {'x': 1.1026032180922143, 'y': 1.054503333774342}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,872] Trial 986 finished with value: 7.302974080011186 and parameters: {'x': 1.0019547955245902, 'y': 1.2741534955115674}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,882] Trial 987 finished with value: 38.28619605337643 and parameters: {'x': 1.2306382488901335, 'y': 0.8961420913277826}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,891] Trial 988 finished with value: 2.1481283165309875 and parameters: {'x': 0.9215542507662949, 'y': 0.9956170997153915}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,901] Trial 989 finished with value: 640.6704970321791 and parameters: {'x': 1.0559567219696118, 'y': -1.4160961834202102}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,910] Trial 990 finished with value: 0.10077510756732591 and parameters: {'x': 0.9301989402559458, 'y': 0.8962382649822938}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,920] Trial 991 finished with value: 1.9449310669947224 and parameters: {'x': 1.1441581887903554, 'y': 1.1703842455907263}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,929] Trial 992 finished with value: 251.02606620356676 and parameters: {'x': -1.622142617922926, 'y': 1.0688152834536535}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,939] Trial 993 finished with value: 0.21791700785635668 and parameters: {'x': 1.005975791590546, 'y': 0.9653095364894457}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,948] Trial 994 finished with value: 0.8504896290556939 and parameters: {'x': 0.9007833763608558, 'y': 0.903097423573349}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,958] Trial 995 finished with value: 0.1429069694794036 and parameters: {'x': 1.0165717306542428, 'y': 0.9956513856394744}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,967] Trial 996 finished with value: 28.860806719915594 and parameters: {'x': 1.1102338061741375, 'y': 1.7697285459933751}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,977] Trial 997 finished with value: 8.141707886930254 and parameters: {'x': 0.9050700786257468, 'y': 1.1043306717698664}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,987] Trial 998 finished with value: 0.9750086874376217 and parameters: {'x': 0.9896642886723807, 'y': 0.8806982855941113}. Best is trial 924 with value: 0.0007716307643246495.\n",
      "[I 2025-06-17 13:59:52,996] Trial 999 finished with value: 8.457948514365642 and parameters: {'x': -1.1058845578677787, 'y': 1.022401525227112}. Best is trial 924 with value: 0.0007716307643246495.\n"
     ]
    }
   ],
   "source": [
    "# Optuna collects multiple trials as a *study*, so to create one we just pass the *objective()* function to study.optimize()\n",
    "import optuna\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6d5c793-aba1-4b84-88bc-25a7e4100c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1.010916402769129, 'y': 1.0193976380242071}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a55a31-842b-4d63-841b-095ac70d04d2",
   "metadata": {},
   "source": [
    "To use Optuna in Transformers, we use similar logic by first defining the hyperparameter space that we wish to optimize over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20d9783b-d265-4813-aac9-d0796b1a16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    return {\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "           \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
    "           \"temperature\": trial.suggest_int(\"temperature\", 2, 20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1211b-0d60-45cf-911e-d27c4c1716ad",
   "metadata": {},
   "source": [
    "Running the hyperparameter search with the Trainer is then quite simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a135d7f8-3299-4eb9-bff7-c3568cb89b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:40:58,516] A new study created in memory with name: no-name-fd0025b1-cec5-45b5-99f7-66e4d94c75aa\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–„â–‚â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–ˆâ–ˆâ–ˆâ–ƒ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–â–â–â–†</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–â–â–â–†</td></tr><tr><td>train/epoch</td><td>â–â–‚â–ƒâ–…â–…â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–…â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–„â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9171</td></tr><tr><td>eval/loss</td><td>0.8042</td></tr><tr><td>eval/runtime</td><td>1.3746</td></tr><tr><td>eval/samples_per_second</td><td>2255.16</td></tr><tr><td>eval/steps_per_second</td><td>47.286</td></tr><tr><td>total_flos</td><td>414689637990180.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1590</td></tr><tr><td>train/grad_norm</td><td>3.55729</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9376</td></tr><tr><td>train_loss</td><td>2.08835</td></tr><tr><td>train_runtime</td><td>113.0215</td></tr><tr><td>train_samples_per_second</td><td>674.65</td></tr><tr><td>train_steps_per_second</td><td>14.068</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distilbert-base-uncased-finetuned-clinc</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/m7rubdz7' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/m7rubdz7</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_102433-m7rubdz7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msergi-sanchez-bonilla\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_104100-s7a081du</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/s7a081du' target=\"_blank\">treasured-dawn-8</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/s7a081du' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/s7a081du</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2226 01:57, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.194458</td>\n",
       "      <td>0.572903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.098307</td>\n",
       "      <td>0.815484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.872903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>0.053797</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.898710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.042042</td>\n",
       "      <td>0.907419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.907097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:43:27,896] Trial 0 finished with value: 0.9070967741935484 and parameters: {'num_train_epochs': 7, 'alpha': 0.2102456437728586, 'temperature': 18.484731451118364}. Best is trial 0 with value: 0.9070967741935484.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–„â–‚â–‚â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–ƒâ–ƒâ–ƒâ–ˆâ–†â–„</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–†â–†â–†â–â–ƒâ–…</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–†â–†â–†â–â–ƒâ–…</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–‚â–ƒâ–„â–…â–…â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–‡â–‚â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–†â–ƒâ–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9071</td></tr><tr><td>eval/loss</td><td>0.04084</td></tr><tr><td>eval/runtime</td><td>1.3909</td></tr><tr><td>eval/samples_per_second</td><td>2228.717</td></tr><tr><td>eval/steps_per_second</td><td>46.731</td></tr><tr><td>total_flos</td><td>579993747211956.0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>2226</td></tr><tr><td>train/grad_norm</td><td>0.28898</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0624</td></tr><tr><td>train_loss</td><td>0.13199</td></tr><tr><td>train_runtime</td><td>118.1492</td></tr><tr><td>train_samples_per_second</td><td>903.518</td></tr><tr><td>train_steps_per_second</td><td>18.841</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">treasured-dawn-8</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/s7a081du' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/s7a081du</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_104100-s7a081du/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_104329-f35yax6h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/f35yax6h' target=\"_blank\">vital-music-9</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/f35yax6h' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/f35yax6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2544/2544 02:13, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.227921</td>\n",
       "      <td>0.605484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.106886</td>\n",
       "      <td>0.836774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.068952</td>\n",
       "      <td>0.882581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.052041</td>\n",
       "      <td>0.897419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>0.910323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>0.919032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.035463</td>\n",
       "      <td>0.919677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.034425</td>\n",
       "      <td>0.920323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:46:11,830] Trial 1 finished with value: 0.9203225806451613 and parameters: {'num_train_epochs': 8, 'alpha': 0.13856176911849827, 'temperature': 5.351581177838879}. Best is trial 1 with value: 0.9203225806451613.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–„â–‚â–‚â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–„â–‚â–‚â–ˆâ–„â–„â–‚</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–…â–†â–‡â–â–…â–…â–‡</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–…â–†â–‡â–â–…â–…â–‡</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–‡â–ƒâ–‚â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–†â–…â–ƒâ–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92032</td></tr><tr><td>eval/loss</td><td>0.03442</td></tr><tr><td>eval/runtime</td><td>1.392</td></tr><tr><td>eval/samples_per_second</td><td>2226.96</td></tr><tr><td>eval/steps_per_second</td><td>46.694</td></tr><tr><td>total_flos</td><td>662624011141428.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>2544</td></tr><tr><td>train/grad_norm</td><td>0.2532</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0544</td></tr><tr><td>train_loss</td><td>0.13463</td></tr><tr><td>train_runtime</td><td>134.1045</td></tr><tr><td>train_samples_per_second</td><td>909.738</td></tr><tr><td>train_steps_per_second</td><td>18.97</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-music-9</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/f35yax6h' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/f35yax6h</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_104329-f35yax6h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_104613-k1r7anov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/k1r7anov' target=\"_blank\">deft-music-10</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/k1r7anov' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/k1r7anov</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257896</td>\n",
       "      <td>0.606452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.125522</td>\n",
       "      <td>0.826452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.084854</td>\n",
       "      <td>0.870645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.884839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>0.889355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:48:07,831] Trial 2 finished with value: 0.8893548387096775 and parameters: {'num_train_epochs': 5, 'alpha': 0.5596358751872399, 'temperature': 4.147935406801489}. Best is trial 1 with value: 0.9203225806451613.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–ˆâ–…â–„â–ƒ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–â–„â–…â–†</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–â–„â–…â–†</td></tr><tr><td>train/epoch</td><td>â–â–‚â–ƒâ–…â–…â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–„â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.88935</td></tr><tr><td>eval/loss</td><td>0.0639</td></tr><tr><td>eval/runtime</td><td>1.3946</td></tr><tr><td>eval/samples_per_second</td><td>2222.867</td></tr><tr><td>eval/steps_per_second</td><td>46.609</td></tr><tr><td>total_flos</td><td>414689637990180.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1590</td></tr><tr><td>train/grad_norm</td><td>0.43845</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0989</td></tr><tr><td>train_loss</td><td>0.20824</td></tr><tr><td>train_runtime</td><td>85.032</td></tr><tr><td>train_samples_per_second</td><td>896.721</td></tr><tr><td>train_steps_per_second</td><td>18.699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-music-10</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/k1r7anov' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/k1r7anov</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_104613-k1r7anov/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_104809-szwjbppv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/szwjbppv' target=\"_blank\">fresh-aardvark-11</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/szwjbppv' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/szwjbppv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2544/2544 02:14, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261305</td>\n",
       "      <td>0.625806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.114829</td>\n",
       "      <td>0.842903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.070232</td>\n",
       "      <td>0.885806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.051794</td>\n",
       "      <td>0.901935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.042083</td>\n",
       "      <td>0.915806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.920323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.921935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>0.923548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:50:56,016] Trial 3 finished with value: 0.9235483870967742 and parameters: {'num_train_epochs': 8, 'alpha': 0.33239373328215194, 'temperature': 3.6504011372983163}. Best is trial 3 with value: 0.9235483870967742.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–‚â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–ƒâ–ˆâ–„â–„â–ˆâ–…â–…</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–†â–â–…â–…â–â–„â–„</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–†â–â–…â–…â–â–„â–„</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–‡â–ƒâ–‚â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–†â–…â–ƒâ–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92355</td></tr><tr><td>eval/loss</td><td>0.03394</td></tr><tr><td>eval/runtime</td><td>1.4048</td></tr><tr><td>eval/samples_per_second</td><td>2206.733</td></tr><tr><td>eval/steps_per_second</td><td>46.27</td></tr><tr><td>total_flos</td><td>662624011141428.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>2544</td></tr><tr><td>train/grad_norm</td><td>0.27051</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.055</td></tr><tr><td>train_loss</td><td>0.14754</td></tr><tr><td>train_runtime</td><td>135.187</td></tr><tr><td>train_samples_per_second</td><td>902.453</td></tr><tr><td>train_steps_per_second</td><td>18.818</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-aardvark-11</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/szwjbppv' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/szwjbppv</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_104809-szwjbppv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105057-gcxh2t30</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/gcxh2t30' target=\"_blank\">silvery-meadow-12</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/gcxh2t30' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/gcxh2t30</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212569</td>\n",
       "      <td>0.576129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.110757</td>\n",
       "      <td>0.804839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.079108</td>\n",
       "      <td>0.863871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.066093</td>\n",
       "      <td>0.876452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.881290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:52:55,472] Trial 4 finished with value: 0.8812903225806452 and parameters: {'num_train_epochs': 5, 'alpha': 0.40235295744847954, 'temperature': 9.445985531103101}. Best is trial 3 with value: 0.9235483870967742.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–‚â–ˆâ–ƒâ–ƒ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–â–…â–†</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‡â–â–…â–†</td></tr><tr><td>train/epoch</td><td>â–â–‚â–ƒâ–…â–…â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–ƒâ–„â–…â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–„â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.88129</td></tr><tr><td>eval/loss</td><td>0.06201</td></tr><tr><td>eval/runtime</td><td>1.4009</td></tr><tr><td>eval/samples_per_second</td><td>2212.855</td></tr><tr><td>eval/steps_per_second</td><td>46.399</td></tr><tr><td>total_flos</td><td>414689637990180.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1590</td></tr><tr><td>train/grad_norm</td><td>0.38333</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.091</td></tr><tr><td>train_loss</td><td>0.17815</td></tr><tr><td>train_runtime</td><td>85.2449</td></tr><tr><td>train_samples_per_second</td><td>894.482</td></tr><tr><td>train_steps_per_second</td><td>18.652</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-meadow-12</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/gcxh2t30' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/gcxh2t30</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105057-gcxh2t30/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105256-ptfwibud</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ptfwibud' target=\"_blank\">leafy-wind-13</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ptfwibud' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ptfwibud</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2862/2862 02:30, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229805</td>\n",
       "      <td>0.616774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>0.105601</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.884839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.049841</td>\n",
       "      <td>0.899032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.040213</td>\n",
       "      <td>0.913226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.035127</td>\n",
       "      <td>0.921935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.032423</td>\n",
       "      <td>0.922581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>0.926774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.926774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:55:53,543] Trial 5 finished with value: 0.9267741935483871 and parameters: {'num_train_epochs': 9, 'alpha': 0.7044024278776422, 'temperature': 5.040806279835347}. Best is trial 5 with value: 0.9267741935483871.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–„â–‚â–‚â–â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–â–„â–ˆâ–‚â–…â–‚â–ƒâ–‡</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–„â–â–‡â–„â–‡â–†â–‚</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‡â–„â–â–‡â–„â–‡â–†â–‚</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–‡â–ƒâ–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–†â–…â–ƒâ–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92677</td></tr><tr><td>eval/loss</td><td>0.03011</td></tr><tr><td>eval/runtime</td><td>1.4795</td></tr><tr><td>eval/samples_per_second</td><td>2095.312</td></tr><tr><td>eval/steps_per_second</td><td>43.934</td></tr><tr><td>total_flos</td><td>745151547572796.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>2862</td></tr><tr><td>train/grad_norm</td><td>0.24782</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0504</td></tr><tr><td>train_loss</td><td>0.12393</td></tr><tr><td>train_runtime</td><td>151.5315</td></tr><tr><td>train_samples_per_second</td><td>905.752</td></tr><tr><td>train_steps_per_second</td><td>18.887</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-wind-13</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ptfwibud' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ptfwibud</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105256-ptfwibud/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105554-rldiqke2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/rldiqke2' target=\"_blank\">crimson-sponge-14</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/rldiqke2' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/rldiqke2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2862/2862 02:30, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329301</td>\n",
       "      <td>0.657419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.125319</td>\n",
       "      <td>0.847742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.069007</td>\n",
       "      <td>0.893226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.049658</td>\n",
       "      <td>0.908710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.040406</td>\n",
       "      <td>0.920645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.926774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.033208</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>0.930645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.031165</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:58:54,875] Trial 6 finished with value: 0.93 and parameters: {'num_train_epochs': 9, 'alpha': 0.0963785264260546, 'temperature': 2.495762911696806}. Best is trial 6 with value: 0.93.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–‚â–„â–‚â–ƒâ–†â–„â–ƒâ–ˆ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–…â–‡â–†â–ƒâ–…â–†â–</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‡â–…â–‡â–†â–ƒâ–…â–†â–</td></tr><tr><td>train/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–‚â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–†â–…â–ƒâ–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.93</td></tr><tr><td>eval/loss</td><td>0.03117</td></tr><tr><td>eval/runtime</td><td>1.4682</td></tr><tr><td>eval/samples_per_second</td><td>2111.378</td></tr><tr><td>eval/steps_per_second</td><td>44.271</td></tr><tr><td>total_flos</td><td>745151547572796.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>2862</td></tr><tr><td>train/grad_norm</td><td>0.29711</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0522</td></tr><tr><td>train_loss</td><td>0.15659</td></tr><tr><td>train_runtime</td><td>151.4777</td></tr><tr><td>train_samples_per_second</td><td>906.074</td></tr><tr><td>train_steps_per_second</td><td>18.894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sponge-14</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/rldiqke2' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/rldiqke2</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105554-rldiqke2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105856-p52uq54x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/p52uq54x' target=\"_blank\">denim-sea-15</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/p52uq54x' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/p52uq54x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/2544 00:16 < 01:55, 19.23 it/s, Epoch 1/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.210728</td>\n",
       "      <td>0.592903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:59:13,200] Trial 7 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.5929</td></tr><tr><td>eval/loss</td><td>0.21073</td></tr><tr><td>eval/runtime</td><td>1.3908</td></tr><tr><td>eval/samples_per_second</td><td>2228.885</td></tr><tr><td>eval/steps_per_second</td><td>46.735</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sea-15</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/p52uq54x' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/p52uq54x</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105856-p52uq54x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105914-v0t7y4zd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/v0t7y4zd' target=\"_blank\">worldly-lake-16</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/v0t7y4zd' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/v0t7y4zd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/2544 00:16 < 01:56, 19.14 it/s, Epoch 1/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.211926</td>\n",
       "      <td>0.595484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:59:31,518] Trial 8 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.59548</td></tr><tr><td>eval/loss</td><td>0.21193</td></tr><tr><td>eval/runtime</td><td>1.4024</td></tr><tr><td>eval/samples_per_second</td><td>2210.559</td></tr><tr><td>eval/steps_per_second</td><td>46.35</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-lake-16</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/v0t7y4zd' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/v0t7y4zd</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105914-v0t7y4zd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105932-iub6xn8w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/iub6xn8w' target=\"_blank\">cosmic-pond-17</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/iub6xn8w' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/iub6xn8w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/2862 00:16 < 02:13, 19.07 it/s, Epoch 1/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196542</td>\n",
       "      <td>0.587419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 10:59:49,840] Trial 9 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.58742</td></tr><tr><td>eval/loss</td><td>0.19654</td></tr><tr><td>eval/runtime</td><td>1.4001</td></tr><tr><td>eval/samples_per_second</td><td>2214.106</td></tr><tr><td>eval/steps_per_second</td><td>46.425</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-pond-17</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/iub6xn8w' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/iub6xn8w</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105932-iub6xn8w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_105950-uqucv8qk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/uqucv8qk' target=\"_blank\">amber-resonance-18</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/uqucv8qk' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/uqucv8qk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/3180 00:16 < 02:30, 19.02 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.194249</td>\n",
       "      <td>0.586129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:00:08,241] Trial 10 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.58613</td></tr><tr><td>eval/loss</td><td>0.19425</td></tr><tr><td>eval/runtime</td><td>1.408</td></tr><tr><td>eval/samples_per_second</td><td>2201.677</td></tr><tr><td>eval/steps_per_second</td><td>46.164</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-resonance-18</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/uqucv8qk' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/uqucv8qk</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_105950-uqucv8qk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110009-449rheof</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/449rheof' target=\"_blank\">exalted-sound-19</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/449rheof' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/449rheof</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 02:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.664839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>0.125292</td>\n",
       "      <td>0.848387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>0.067447</td>\n",
       "      <td>0.893871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.048515</td>\n",
       "      <td>0.913226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>0.922903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.035086</td>\n",
       "      <td>0.928065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.931290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.030478</td>\n",
       "      <td>0.934516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.931935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.029130</td>\n",
       "      <td>0.932581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:03:13,007] Trial 11 finished with value: 0.9325806451612904 and parameters: {'num_train_epochs': 10, 'alpha': 0.6257487282434875, 'temperature': 2.3644717298298623}. Best is trial 11 with value: 0.9325806451612904.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–‚â–‡â–ƒâ–‚â–‚â–‚â–‚â–‚â–ˆ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–‚â–†â–‡â–‡â–‡â–‡â–‡â–</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‡â–‚â–†â–‡â–‡â–‡â–‡â–‡â–</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–‚â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–‡â–…â–„â–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.93258</td></tr><tr><td>eval/loss</td><td>0.02913</td></tr><tr><td>eval/runtime</td><td>1.4713</td></tr><tr><td>eval/samples_per_second</td><td>2106.961</td></tr><tr><td>eval/steps_per_second</td><td>44.178</td></tr><tr><td>total_flos</td><td>1159745721625344.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>3180</td></tr><tr><td>train/grad_norm</td><td>0.3119</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0463</td></tr><tr><td>train_loss</td><td>0.14769</td></tr><tr><td>train_runtime</td><td>168.953</td></tr><tr><td>train_samples_per_second</td><td>902.618</td></tr><tr><td>train_steps_per_second</td><td>18.822</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sound-19</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/449rheof' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/449rheof</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110009-449rheof/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110314-nr3c2xk4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/nr3c2xk4' target=\"_blank\">sweet-plant-20</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/nr3c2xk4' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/nr3c2xk4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 02:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307654</td>\n",
       "      <td>0.654194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.119699</td>\n",
       "      <td>0.851290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.066869</td>\n",
       "      <td>0.893226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.908387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.920968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>0.926774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.031244</td>\n",
       "      <td>0.930968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>0.932903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.932581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.028165</td>\n",
       "      <td>0.932581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:06:02,300] Trial 12 finished with value: 0.9325806451612904 and parameters: {'num_train_epochs': 10, 'alpha': 0.5696480041396725, 'temperature': 2.6974274451501774}. Best is trial 11 with value: 0.9325806451612904.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–â–‚â–…â–‚â–‚â–‚â–ˆâ–„â–‚</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–‡â–„â–‡â–‡â–‡â–â–…â–‡</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‡â–‡â–„â–‡â–‡â–‡â–â–…â–‡</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–‚â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–‡â–…â–„â–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.93258</td></tr><tr><td>eval/loss</td><td>0.02817</td></tr><tr><td>eval/runtime</td><td>1.4176</td></tr><tr><td>eval/samples_per_second</td><td>2186.77</td></tr><tr><td>eval/steps_per_second</td><td>45.852</td></tr><tr><td>total_flos</td><td>827728372450224.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>3180</td></tr><tr><td>train/grad_norm</td><td>0.29855</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0457</td></tr><tr><td>train_loss</td><td>0.13778</td></tr><tr><td>train_runtime</td><td>167.675</td></tr><tr><td>train_samples_per_second</td><td>909.497</td></tr><tr><td>train_steps_per_second</td><td>18.965</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-plant-20</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/nr3c2xk4' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/nr3c2xk4</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110314-nr3c2xk4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110603-4qc6ulia</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/4qc6ulia' target=\"_blank\">elated-forest-21</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/4qc6ulia' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/4qc6ulia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 02:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.404953</td>\n",
       "      <td>0.673548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>0.845161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.070388</td>\n",
       "      <td>0.897097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.050710</td>\n",
       "      <td>0.915161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.041634</td>\n",
       "      <td>0.924516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>0.928710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.034281</td>\n",
       "      <td>0.931935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.934839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.031597</td>\n",
       "      <td>0.933548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.031156</td>\n",
       "      <td>0.932903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:08:59,631] Trial 13 finished with value: 0.9329032258064516 and parameters: {'num_train_epochs': 10, 'alpha': 0.584342469918365, 'temperature': 2.002000458384341}. Best is trial 13 with value: 0.9329032258064516.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–‚â–‚â–‡â–†â–â–‚â–ƒâ–ˆâ–ƒ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–‡â–‚â–ƒâ–ˆâ–‡â–†â–â–†</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‡â–‡â–‚â–ƒâ–ˆâ–‡â–†â–â–†</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–…â–‚â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–‡â–…â–„â–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9329</td></tr><tr><td>eval/loss</td><td>0.03116</td></tr><tr><td>eval/runtime</td><td>1.4298</td></tr><tr><td>eval/samples_per_second</td><td>2168.145</td></tr><tr><td>eval/steps_per_second</td><td>45.461</td></tr><tr><td>total_flos</td><td>827728372450224.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>3180</td></tr><tr><td>train/grad_norm</td><td>0.33763</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0478</td></tr><tr><td>train_loss</td><td>0.16597</td></tr><tr><td>train_runtime</td><td>168.4968</td></tr><tr><td>train_samples_per_second</td><td>905.062</td></tr><tr><td>train_steps_per_second</td><td>18.873</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-forest-21</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/4qc6ulia' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/4qc6ulia</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110603-4qc6ulia/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110900-8yj14o2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/8yj14o2s' target=\"_blank\">wandering-sponge-22</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/8yj14o2s' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/8yj14o2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/3180 00:16 < 02:30, 18.98 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.190411</td>\n",
       "      <td>0.580968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:09:18,069] Trial 14 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.58097</td></tr><tr><td>eval/loss</td><td>0.19041</td></tr><tr><td>eval/runtime</td><td>1.4131</td></tr><tr><td>eval/samples_per_second</td><td>2193.685</td></tr><tr><td>eval/steps_per_second</td><td>45.997</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-sponge-22</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/8yj14o2s' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/8yj14o2s</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110900-8yj14o2s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110919-o54rd1t5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/o54rd1t5' target=\"_blank\">fresh-valley-23</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/o54rd1t5' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/o54rd1t5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/1908 00:16 < 01:23, 18.98 it/s, Epoch 1/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.219394</td>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:09:36,789] Trial 15 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.59</td></tr><tr><td>eval/loss</td><td>0.21939</td></tr><tr><td>eval/runtime</td><td>1.4133</td></tr><tr><td>eval/samples_per_second</td><td>2193.389</td></tr><tr><td>eval/steps_per_second</td><td>45.99</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-valley-23</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/o54rd1t5' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/o54rd1t5</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110919-o54rd1t5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110937-ka19uy98</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ka19uy98' target=\"_blank\">copper-planet-24</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ka19uy98' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ka19uy98</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/3180 00:16 < 02:30, 18.97 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.192399</td>\n",
       "      <td>0.581290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:09:55,163] Trial 16 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.58129</td></tr><tr><td>eval/loss</td><td>0.1924</td></tr><tr><td>eval/runtime</td><td>1.4122</td></tr><tr><td>eval/samples_per_second</td><td>2195.214</td></tr><tr><td>eval/steps_per_second</td><td>46.029</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-planet-24</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ka19uy98' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ka19uy98</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110937-ka19uy98/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_110956-owhn7sjd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/owhn7sjd' target=\"_blank\">jumping-terrain-25</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/owhn7sjd' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/owhn7sjd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/2862 00:16 < 02:14, 18.97 it/s, Epoch 1/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.201256</td>\n",
       "      <td>0.588387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:10:13,567] Trial 17 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–</td></tr><tr><td>train/global_step</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.58839</td></tr><tr><td>eval/loss</td><td>0.20126</td></tr><tr><td>eval/runtime</td><td>1.4113</td></tr><tr><td>eval/samples_per_second</td><td>2196.574</td></tr><tr><td>eval/steps_per_second</td><td>46.057</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jumping-terrain-25</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/owhn7sjd' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/owhn7sjd</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_110956-owhn7sjd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_111014-bo3prts2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/bo3prts2' target=\"_blank\">stellar-snowflake-26</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/bo3prts2' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/bo3prts2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 636/2226 00:34 < 01:26, 18.40 it/s, Epoch 2/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.400071</td>\n",
       "      <td>0.667097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>0.147547</td>\n",
       "      <td>0.835484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:10:49,834] Trial 18 pruned. \n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–</td></tr><tr><td>eval/runtime</td><td>â–â–ˆ</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–</td></tr><tr><td>train/epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–…â–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–</td></tr><tr><td>train/learning_rate</td><td>â–</td></tr><tr><td>train/loss</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83548</td></tr><tr><td>eval/loss</td><td>0.14755</td></tr><tr><td>eval/runtime</td><td>1.4242</td></tr><tr><td>eval/samples_per_second</td><td>2176.656</td></tr><tr><td>eval/steps_per_second</td><td>45.64</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>636</td></tr><tr><td>train/grad_norm</td><td>0.93834</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.6239</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-snowflake-26</strong> at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/bo3prts2' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/bo3prts2</a><br> View project at: <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250617_111014-bo3prts2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250617_111050-hixq6zn6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/hixq6zn6' target=\"_blank\">tough-rain-27</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/hixq6zn6' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/hixq6zn6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/3180 00:16 < 02:31, 18.89 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.219547</td>\n",
       "      <td>0.605484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 11:11:08,373] Trial 19 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_run = distilbert_trainer.hyperparameter_search(\n",
    "    n_trials=20, direction=\"maximize\", hp_space=hp_space\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "991584d5-b6f8-4f48-8da5-3648fb73c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='13', objective=0.9329032258064516, hyperparameters={'num_train_epochs': 10, 'alpha': 0.584342469918365, 'temperature': 2.002000458384341}, run_summary=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1592581ed52043c9b81ba43afc35d2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7854ddc8046343ebb54bb95e584dab93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3902159925244ecaa7753b4c61e1c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995b93005532405db75b064d90ce4e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 11 LFS files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75ab70d2e3d423f922c437f077344ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f08360b9584a7c8c94081cbdd0789f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53769bf2d2644c7da491160a82fc3a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61d409df91c44d0b5134bc5e7571c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8210c046998c426ba1a4e267d8212605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6feaa3ac234c1abfecff6d8fc1f120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7186cc1ec9e04aa594ea95dfffc70651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550fd9f9c5024f059c37da548390a21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbbb4b9f-6fee-452c-bd12-735167fcda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1349230/3053386859.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 02:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.098601</td>\n",
       "      <td>0.724839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.488300</td>\n",
       "      <td>1.078710</td>\n",
       "      <td>0.863548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.488300</td>\n",
       "      <td>0.615800</td>\n",
       "      <td>0.911935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.442281</td>\n",
       "      <td>0.932581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.377309</td>\n",
       "      <td>0.938387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.942581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.337622</td>\n",
       "      <td>0.944194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.329750</td>\n",
       "      <td>0.945484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.326323</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.324946</td>\n",
       "      <td>0.944194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's update our training arguments with these values and run the final training run\n",
    "for k,v in best_run.hyperparameters.items():\n",
    "    setattr(student_training_args, k, v)\n",
    "\n",
    "# define a new repository to store our distilled model\n",
    "distilled_ckpt = \"distilbert-base-uncased-distilled-clinc\"\n",
    "student_training_args.output_dir = distilled_ckpt\n",
    "\n",
    "# Create a new Trainer with optimal parameters\n",
    "distil_trainer = DistillationTrainer(model_init=student_init,\n",
    "                                    teacher_model=teacher_model, args=student_training_args,\n",
    "                                    train_dataset=clinc_enc[\"train\"],\n",
    "                                    eval_dataset=clinc_enc[\"validation\"],\n",
    "                                    compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distil_trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb923eb9-f920-4a27-a4e6-d11749628e34",
   "metadata": {},
   "source": [
    "**Remarkably, we've been able to train the student to match the accuracy of the teacher, despite it having almost half the number of parameters!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89994f50-c019-4225-a784-e746a8fa278b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6add734c31438180185cb9a9c6855c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sergi24sanchez/distilbert-base-uncased-distilled-clinc/commit/c0ff1085e2c724737da7359285dda7aca942311e', commit_message='Training Completed!', commit_description='', oid='c0ff1085e2c724737da7359285dda7aca942311e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sergi24sanchez/distilbert-base-uncased-distilled-clinc', endpoint='https://huggingface.co', repo_type='model', repo_id='sergi24sanchez/distilbert-base-uncased-distilled-clinc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_trainer.push_to_hub(\"Training Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4d5f5-d469-40a9-a318-a97fb7bceb87",
   "metadata": {},
   "source": [
    "### Benchmarking Our Distilled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "292cd262-d247-4676-ada6-236c215a4bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 255.88\n",
      "Average latency (ms) - 2.86 +\\- 0.06\n",
      "Accuracy on test set - 0.882\n"
     ]
    }
   ],
   "source": [
    "distilled_ckpt = \"sergi24sanchez/distilbert-base-uncased-distilled-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=distilled_ckpt, device=0)\n",
    "optim_type = \"Distillation\"\n",
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a3ed96b-4237-48d0-8607-c16adf53ae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1399227/2626924658.py:18: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  for handle in legend.legendHandles:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723df95-d1d3-49ca-b3be-b1576b00ec61",
   "metadata": {},
   "source": [
    "The model size and latency remain essentially unchanged compared to DistilBERT benchmark, but the accuracy has improved and even surpassed the performance of the teacher!!!\n",
    "One way to interpret this, is that the teacher has likely no tbeen fine-tuned as systematically as the student.\n",
    "\n",
    "This is great, but we can actually compress our distilled model even further using a technique known as quantization.\n",
    "\n",
    "## Making Models Faster with Quantization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a68f790-7245-4783-b980-abdb5a1fbbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "state_dict = pipe.model.state_dict()\n",
    "weights = state_dict[\"distilbert.transformer.layer.0.attention.out_lin.weight\"]\n",
    "plt.hist(weights.flatten().cpu().numpy(), bins=250, range=(-0.3, 0.3), edgecolor=\"C0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff042681-225c-4da6-b590-57f2322c4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point = 0\n",
    "scale = (weights.max() - weights.min()) / (127 - (-128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2b5eb-0d83-4b06-8e50-afbe1d551a84",
   "metadata": {},
   "source": [
    "to obtain the quantized tensor, we just need to invert the mapping $q = f/s + Z$, clamp de values, round them to the nearest integer, and represent the result in the *torch.int8* data type using the Tensor.char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0077825-0976-4331-918a-694b828010d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5,  -8,   0,  ...,  -6,  -4,   8],\n",
       "        [  9,   3,   1,  ...,  -4,   7,   0],\n",
       "        [ -9,  -5,   5,  ...,   0,   6,  -4],\n",
       "        ...,\n",
       "        [  6,   0,  13,  ...,   0,   6,  -1],\n",
       "        [  1,  -2, -12,  ...,  12,  -7, -13],\n",
       "        [-13,  -1,  -9,  ...,   8,   2,  -1]], device='cuda:0',\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights / scale + zero_point).clamp(-128, 127).round().char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a79eb20a-a2c7-4550-b645-33ef90de9154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5,  -8,   0,  ...,  -6,  -4,   8],\n",
       "        [  9,   3,   1,  ...,  -4,   7,   0],\n",
       "        [ -9,  -5,   5,  ...,   0,   6,  -4],\n",
       "        ...,\n",
       "        [  6,   0,  13,  ...,   0,   6,  -1],\n",
       "        [  1,  -2, -12,  ...,  12,  -7, -13],\n",
       "        [-13,  -1,  -9,  ...,   8,   2,  -1]], device='cuda:0',\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import quantize_per_tensor\n",
    "\n",
    "dtype = torch.qint8\n",
    "quantized_weights = quantize_per_tensor(weights, scale, zero_point, dtype)\n",
    "quantized_weights.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "845ee9db-ad3d-485a-8e99-2fb85510edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the quanitzed tensors we need the QFunctional wrapper class\n",
    "from torch.nn.quantized import QFunctional\n",
    "\n",
    "q_fn = QFunctional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "439c6ceb-042c-4f60-bf84-5ff0c76e35e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], size=(768, 768), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_fn.mul(quantized_weights.cpu(), quantized_weights.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca066c-a3ca-4938-83b9-4d7dd2ef9042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
