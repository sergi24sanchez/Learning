{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c689c-5e05-4854-8341-0223f4568068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaf8b6-901c-481f-bd1f-65f4e838b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, login\n",
    "token = \"\"\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f1210-324e-4224-95a4-267ad260f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list_datasets(search=\"emotion\", limit=10)\n",
    "for ds in datasets:\n",
    "    print(ds.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bdd469-86fc-4900-8232-fd1bac89ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "emotions_dataset = load_dataset('dair-ai/emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267cfc2-6f4d-41c3-be13-4e6ced83e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "text = \"Tokenizing text is a core task of NLP.\"\n",
    "\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14911395-5419-42f9-b9f8-d09386aa5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch['text'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d73988-d750-4468-967a-6b27790fa3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emotions_dataset.set_format(\"pandas\")\n",
    "df = emotions_dataset[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00771f-6779-46c3-80bc-af1720d8fe6a",
   "metadata": {},
   "source": [
    "# Looking at the Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac3a5c-fb9d-4233-ae97-e8aaeafc0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"label\"].value_counts().plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc1504-e1b6-4178-8a8b-6d47c8464892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Words per tweet\"] = df[\"text\"].str.split().apply(len)\n",
    "df.boxplot(\"Words per tweet\", by=\"label\", grid=False, showfliers=False, color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565378e9-adfc-44dd-9742-bf3fcbec90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba971a4-96fa-4249-8353-719e542fc966",
   "metadata": {},
   "source": [
    "# From Text to Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993e671-dffb-43e7-9396-579a99f78acd",
   "metadata": {},
   "source": [
    "## Character Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abf404-bf4f-4b60-bc5f-e5019fac9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenizing text is a core task of NLP.\"\n",
    "tokenized_text = list(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64564854-3baf-4c64-b192-ef3b69296952",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx = {ch : idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
    "input_ids = [token2idx[token] for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bd888-d573-4335-8afe-e2325f9034b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 2D tensor of one-hot vectors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\n",
    "print(one_hot_encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b820f8a-0f48-4142-a5ec-b17b35ffb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Token: {tokenized_text[0]}\")\n",
    "print(f\"Tensor index: {input_ids[0]}\")\n",
    "print(f\"One-hot: {one_hot_encodings[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07bf14-67f2-4942-9fb0-4dce90b41ea5",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0c962-d4cf-40ec-999c-0aec1f031a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = text.split()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4d566-353c-4f78-93cf-dec354b4a521",
   "metadata": {},
   "source": [
    "## Subword Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64070ac7-7bf2-4a08-adc0-a976441ef28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)\n",
    "\n",
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f64a9b-7a2c-4f26-96ae-251e8e7f02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.vocab_size, tokenizer.model_max_length, tokenizer.model_input_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99aa82b-4cfd-4434-b6da-f9e62ea72da9",
   "metadata": {},
   "source": [
    "## Tokenizing the Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7195c1b-5265-4837-8092-7a5cd87d9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "print(tokenize(emotions_dataset[\"train\"][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbacde-e8be-4112-8bea-298cfe14b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_encoded = emotions_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452548d-7d88-444c-9b9c-d577bc608778",
   "metadata": {},
   "source": [
    "# Training a TEXT CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dacd7-d8af-4136-b2ba-be873ed75196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b0d2a-f1d4-4238-ab64-156c12b0ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd234d-9ec0-4790-a0b1-2b51456a09b2",
   "metadata": {},
   "source": [
    "## Transformers as Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eefa26-829c-4cf1-8a99-00f7f5df9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodings as a tensor\n",
    "text = \"this is a test\"\n",
    "inputs  = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")\n",
    "# [batch_size, n_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4d249-a0f8-408c-a7f1-0777a57291f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf9991-4b1b-4a98-bb06-e3fcbed4dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.size()\n",
    "# [bs, n_tok, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944b51c-85c1-4c9e-8a1b-725bf70726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "  # Place model inputs on the GPU\n",
    "  inputs = {k: v.to(device) for k, v in batch.items()\n",
    "            if k in tokenizer.model_input_names}\n",
    "  # Extract last hidden states\n",
    "  with torch.no_grad():\n",
    "    last_hidden_state = model(**inputs).last_hidden_state\n",
    "  # return vector for [CLS] token\n",
    "  return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32aca8-0e83-4f6d-9af4-8dee959dee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4546b-f9af-4be7-bfe4-d3a84f6bfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hidden states across all splits in one go\n",
    "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5dbcf5-f7f6-419b-96c4-863d7d1308c7",
   "metadata": {},
   "source": [
    "## Creating a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f24bff-0bb8-432c-9a97-1a5c19589d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
    "X_valid = np.array(emotions_hidden[\"test\"][\"hidden_state\"])\n",
    "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
    "y_valid = np.array(emotions_hidden[\"test\"][\"label\"])\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231deafd-9ff8-46cd-aa84-616a215e91e8",
   "metadata": {},
   "source": [
    "## Visualizing the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d564c9e-7825-46a5-8c45-f5cbd378d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Scale features to [0,1] range\n",
    "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "# Initialize and fit UMAP\n",
    "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
    "# Create a DataFrame of 2D embeddings\n",
    "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
    "df_emb[\"label\"] = y_train\n",
    "df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f50370-b056-4784-841d-6013ea05f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(5, 5))\n",
    "axes = axes.flatten()\n",
    "cmaps = ['Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds', 'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu']\n",
    "labels = emotions_dataset[\"train\"].features[\"label\"].names\n",
    "print(\"Unique classes:\", labels)\n",
    "\n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "  df_emb_sub = df_emb.query(f\"label == {i}\")\n",
    "  axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap, gridsize=20, linewidths=(0,))\n",
    "  axes[i].set_title(label)\n",
    "  axes[i].set_xticks([]), axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b86df-f2f0-4bfd-822a-37ae90b56ca0",
   "metadata": {},
   "source": [
    "## Training a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6490dd-70e9-4ca1-a829-1b22bb64ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# we increase 'max_iter' to guarantee convergence\n",
    "lr_clf = LogisticRegression(max_iter=3000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735e5ed-59ba-4cb0-adc7-853d1b050e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ddbc0-19ec-4925-86b2-44b69e954347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "  fig, ax = plt.subplots(figsize=(6, 6))\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "  plt.title(\"Normalized confusion matrix\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22275459-2c14-4801-9706-16014d9797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = lr_clf.predict(X_valid)\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf94ea-1f1f-4eb5-b596-768b4f2823a3",
   "metadata": {},
   "source": [
    "# Fine-tuning Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110b70f-3bbf-41c6-b769-0d7c9482437b",
   "metadata": {},
   "source": [
    "## Loading a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7d96a-bda4-47ca-bd41-330a326b1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 6\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d515c54-4667-4a56-a2cb-a16479c143cd",
   "metadata": {},
   "source": [
    "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "\n",
    "Classification head has not yet been trained. Some parts of the model are randomly initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1f8c3-bc06-4e3c-b0c7-7d2cfe012a66",
   "metadata": {},
   "source": [
    "## Defining the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cc6f8-9c30-4058-9986-9899ff934575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b1405-3e89-430f-83ab-1401a045e534",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57029ff6-e406-40a0-bc71-24f39b141359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "token = \"\"\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a0c05-fe54-47b9-80f0-346b2c5848ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "bs = 64\n",
    "logging_steps = len(emotions_encoded[\"train\"]) // bs\n",
    "model_name = f\"{model_ckpt}-finetuned_emotion\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=5,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=bs,\n",
    "                                  per_device_eval_batch_size=bs,\n",
    "                                  weight_decay=0.01,\n",
    "                                  logging_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True,\n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa5121-a0da-46b3-a24d-0eef985cfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotions_encoded[\"train\"],\n",
    "                  eval_dataset=emotions_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46ad30-56f1-4800-83e7-cff511fa013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_outputs = trainer.predict(emotions_encoded[\"validation\"])\n",
    "print(preds_outputs.metrics, preds_outputs.predictions.shape, preds_outputs.predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39e70d-b5ee-4b86-b083-bf2ffb32a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds_outputs.predictions, axis=1)\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d8804-36ef-40b7-92f0-e97dcfb67a05",
   "metadata": {},
   "source": [
    "y_train = np.array(emotions_encoded[\"train\"][\"label\"])\n",
    "y_valid = np.array(emotions_encoded[\"validation\"][\"label\"])\n",
    "labels = emotions_dataset[\"train\"].features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14102123-e43f-4994-8c65-4a32a01ea93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20beaa0-9c17-4f90-a9e0-061142cbbdef",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077a853-af33-475e-adb1-a5bec956ff96",
   "metadata": {},
   "source": [
    "A simple yet powerful technique is to sort validaions samples by the model loss. when we pass the label during the forward pass, the loss is automatically calculated and returned. Here's a loss that returns the loss along with the predicted label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc18a6-0f06-4968-b95f-b2a418883769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "  # Place all input tensors on the same device as the model\n",
    "  inputs = {k:v.to(device) for k,v in batch.items()\n",
    "            if k in tokenizer.model_input_names}\n",
    "\n",
    "  with torch.no_grad():\n",
    "    output = model(**inputs)\n",
    "    pred_label = torch.argmax(output.logits, axis=-1)\n",
    "    loss = cross_entropy(output.logits, batch[\"label\"].to(device), reduction=\"none\")\n",
    "  return {\"loss\": loss.cpu().numpy(),\n",
    "          \"predicted_label\": pred_label.cpu().numpy()}\n",
    "\n",
    "def label_int2str(row):\n",
    "  return emotions_dataset[\"train\"].features[\"label\"].int2str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78550b-2966-49e1-a10b-3f5d83f25f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using map() function to apply this function to get the losses for all the samples\n",
    "#Convert our dataset back to PyTorch tensors\n",
    "emotions_encoded.set_format(\"torch\",\n",
    "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "#Compute loss values\n",
    "emotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(\n",
    "    forward_pass_with_label, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11a902-97b8-4b15-b46b-9bbb39b333eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with texts, losses, and predicted/true labels\n",
    "emotions_encoded.set_format(\"pandas\")\n",
    "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\n",
    "df_test = emotions_encoded[\"validation\"][:][cols]\n",
    "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str)\n",
    "df_test[\"predicted_label\"] = df_test[\"predicted_label\"].apply(label_int2str)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d344c24-72b5-4959-ab00-9ea904f1800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data samples with highest losses\n",
    "df_test.sort_values(\"loss\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664145d-9376-43ed-8c08-bfdaf9b84feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data samples with smallest losses\n",
    "df_test.sort_values(\"loss\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4fa9b-33e1-4276-914c-581cd876df60",
   "metadata": {},
   "source": [
    "## Saving and sharing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab83e6-3b1d-4c63-9075-5aca93106a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb60d78-6777-4ade-92eb-f44e05b9aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Change 'transformersbook' to you Hub username\n",
    "model_id = \"sergi24sanchez/distilbert-base-uncased-finetuned_emotion\"\n",
    "classifier = pipeline(\"text-classification\", model=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df68d9e-005f-4d3d-b6ff-c978dd48e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_tweet = \"I saw a movie last Sunday which really moved me and inspired me to live my life a different way.\"\n",
    "custom_tweet = \"i should have taken more photos\"\n",
    "preds = classifier(custom_tweet, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0157b-e5c4-465c-a37c-72304c71815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds[0])\n",
    "plt.bar(labels, 100 * preds_df[\"score\"], color='C0')\n",
    "plt.title(f'\"{custom_tweet}\"\\n')\n",
    "plt.ylabel(\"Class probability (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fea6a-5220-479c-9e92-821405f95c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
