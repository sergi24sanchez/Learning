{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba62793-8e05-48ef-9d21-270c9c199b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, login\n",
    "token = \"\"\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a783b4-6edb-4885-920f-34f6ad163dc8",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b25b661-da70-4445-bed0-73c637869749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f11670a-b33e-46cd-9f4d-425b3f1cb407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a7300b-17aa-4cc8-bf41-07ff01e6e565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35e188-d00b-40c8-a506-7dc10d0bf093",
   "metadata": {},
   "source": [
    "To make a realistic Swiss corpus, we'll sample the German (de), French (fr), Italian (it), and English (en) corpora from PAN-X according to their spoken proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a42509-ac92-49d8-a0e1-10528a53a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = ['de', 'fr', 'it', 'en']\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fd9e5d-6a6d-4d61-9b5f-253d3dcbad6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "             index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fab7a-a4ca-4d98-b554-d714b110ac0c",
   "metadata": {},
   "source": [
    "Let's inspect one of the examples in German corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31db28dc-3be6-4567-8d5d-672bee13f847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef75086-dc20-4bf3-8995-4f4ee1c467c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d746e8ac-d2f8-4e60-93a3-181e87da4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb2ebd4-d20d-4c03-8d42-b7714fe6664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d712a5a-6fbe-4060-b7c0-a68892668ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], ['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a043d19-b064-4d8f-afff-60e71e55cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate frequencies of each entity across each split\n",
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split('-')[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da1876-4cfe-43ce-8ef7-623fa6b0d810",
   "metadata": {},
   "source": [
    "# A Closer Look at Tokenization\n",
    "\n",
    "XLM-R uses a tokenizer called SentencePiece that is trained on the raw text of all one hundred languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de737b6-28bc-42f7-8524-5d90f423b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc32d281-a2c2-4b35-a967-ba5d27b28398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n",
      "['<s>', '‚ñÅJack', '‚ñÅSpar', 'row', '‚ñÅlove', 's', '‚ñÅNew', '‚ñÅYork', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
    "print(bert_tokens)\n",
    "print(xlmr_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a15d1-d782-4922-833b-eb9cf6af11ba",
   "metadata": {},
   "source": [
    "## The SentencePiece Tokenizer\n",
    "\n",
    "Based on a type of subword segmentation called Unigram and encodes each input text as a sequence of Unicode characters. SentencePiece is agnostic about accents, punctuation, and the fact that many languages do not have whitespace characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f338416-8cd1-4dd6-9c5d-8d5bd1070de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens).replace(u'\\u2581', \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f87f99-0d44-44bd-a510-9074e6e3e34a",
   "metadata": {},
   "source": [
    "# Transformers for Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90084d-a5ed-4578-aa78-e2f434c4e606",
   "metadata": {},
   "source": [
    "# Creating a Custom Model for Token Classification\n",
    "\n",
    "To get started, we need a data structure that will represent out XLM-R NER tagger. We'll need a configuration object to initialize the model and a *forward()* function to generate the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf98822-03c2-4c93-a9fe-6e0d655fc4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaFortokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representations\n",
    "        sequence_output = self.dropout(outputs[0]) # get tensor of output\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states= outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072eb9aa-b8c8-4d26-a518-1b96cad0a6f5",
   "metadata": {},
   "source": [
    "## Loading a Custom Model\n",
    "\n",
    "We'll need to provide some additional information beyond the model name, including the tags that we will use to label each entity and the mapping of each tag to an ID and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7eb2783-003a-4bec-a001-14f16090446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a9680d6-9b93-49e7-9b87-f1f8e342808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b1826-9f94-41f5-a4eb-9dc1f119c8b7",
   "metadata": {},
   "source": [
    "The *AutoConfig* class contains the blueprint of a model's architecture. If we want to modify something like the number of classes or label names, then we can load the configuration first with the parameters we would like to customize.\n",
    "\n",
    "Now, we can load the model weights as useual with the *from_pretained()* with the additional *config* argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "801f499d-a8b0-4a2a-855c-a5a820296534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaFortokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaFortokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2251a30e-52d4-4c53-912e-1f1f5ea0c0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅJack</td>\n",
       "      <td>‚ñÅSpar</td>\n",
       "      <td>row</td>\n",
       "      <td>‚ñÅlove</td>\n",
       "      <td>s</td>\n",
       "      <td>‚ñÅNew</td>\n",
       "      <td>‚ñÅYork</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "tokens     <s>  ‚ñÅJack  ‚ñÅSpar    row  ‚ñÅlove  s  ‚ñÅNew  ‚ñÅYork   !  </s>\n",
       "input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"tokens\", \"input IDs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df2267-5769-4dc6-b7fd-5eebaf11e7b4",
   "metadata": {},
   "source": [
    "Finally, we need to pass the inputs to the model and extract the predictions by taking the argmax to get the most likely class per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb324bb8-ca51-46da-82a2-7c7a6100f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75d14796-5c6f-4cf5-b78b-fa39b09a6084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅJack</td>\n",
       "      <td>‚ñÅSpar</td>\n",
       "      <td>row</td>\n",
       "      <td>‚ñÅlove</td>\n",
       "      <td>s</td>\n",
       "      <td>‚ñÅNew</td>\n",
       "      <td>‚ñÅYork</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2    3      4  5     6      7  8      9\n",
       "Tokens    <s>  ‚ñÅJack  ‚ñÅSpar  row  ‚ñÅlove  s  ‚ñÅNew  ‚ñÅYork  !   </s>\n",
       "Tags    I-ORG      O      O    O      O  O     O      O  O  I-ORG"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\",\"Tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63957996-ead0-477e-bd18-ffb6e0e7810f",
   "metadata": {},
   "source": [
    "Unsurprisingly, our token classification layer with random weights leaves a lot to be desired; let's fine-tune on some **labeled data** to make it better! Before doing so, let0s wrap the preceding steps into a helper function for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b3c2f9b-7852-4f67-8991-af843e7841e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # Get tokenizer with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    inputs = xlmr_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    outputs = model(inputs)[0]\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # Convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\",\"Tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b0428-1a47-4a55-8662-6f3e4080fd01",
   "metadata": {},
   "source": [
    "Before we can train the model we also need to tokenize the inputs and prepare the labels.\n",
    "\n",
    "## Tokenizing Texts for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1cc441-693a-445b-b800-f533c466ba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅ2.000</td>\n",
       "      <td>‚ñÅEinwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>‚ñÅan</td>\n",
       "      <td>‚ñÅder</td>\n",
       "      <td>‚ñÅDan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>‚ñÅBuch</td>\n",
       "      <td>...</td>\n",
       "      <td>‚ñÅWo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>‚ñÅPo</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ‚ñÅ2.000  ‚ñÅEinwohner  n  ‚ñÅan  ‚ñÅder  ‚ñÅDan  zi  ger  ‚ñÅBuch  ...  ‚ñÅWo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ‚ñÅPo  mmer  n  ‚ñÅ  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n",
    "print(words)\n",
    "print(labels)\n",
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "966f8b72-6cf3-4924-aa4c-d7380459241b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅ2.000</td>\n",
       "      <td>‚ñÅEinwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>‚ñÅan</td>\n",
       "      <td>‚ñÅder</td>\n",
       "      <td>‚ñÅDan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>‚ñÅBuch</td>\n",
       "      <td>...</td>\n",
       "      <td>‚ñÅWo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>‚ñÅPo</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ‚ñÅ2.000  ‚ñÅEinwohner  n  ‚ñÅan  ‚ñÅder  ‚ñÅDan  zi  ger  ‚ñÅBuch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ‚ñÅWo  i  wod  schaft  ‚ñÅPo  mmer   n   ‚ñÅ   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\",\"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37b45c59-b701-4e75-8d89-9f7c84868c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅ2.000</td>\n",
       "      <td>‚ñÅEinwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>‚ñÅan</td>\n",
       "      <td>‚ñÅder</td>\n",
       "      <td>‚ñÅDan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>‚ñÅBuch</td>\n",
       "      <td>...</td>\n",
       "      <td>‚ñÅWo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>‚ñÅPo</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ‚ñÅ2.000  ‚ñÅEinwohner     n  ‚ñÅan  ‚ñÅder   ‚ñÅDan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ‚ñÅBuch  ...    ‚ñÅWo     i   wod  schaft    ‚ñÅPo  mmer     n   ‚ñÅ     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l !=-100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d67a3dc-cba0-475b-ba00-e2b1a56e893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function that wraps all the logic\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a70474-349f-45b9-a873-8e0d399c316b",
   "metadata": {},
   "source": [
    "Now we have all the ingredients we need to encode each split, so let's write a function we can iterate over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceedb2f5-06e8-46a7-a2df-a2cd226ffb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True,\n",
    "                      remove_columns=['langs','ner_tags','tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07c2fec3-9fc3-4746-87d8-c560b5e83f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10f310c137a4e139336dd81cc7d5279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b5e08-2d40-4f01-b515-90d124484b4a",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "The only subtlety is that *all* words of an enity need to be predicted correctly in order for a prediction to be counted as correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bb00238-06ea-4dae-b6d5-218807066442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b36678e5-6050-488c-8cd7-7867f0878f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx, seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx, seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb25a68-4e82-4d24-acce-cf55a3853335",
   "metadata": {},
   "source": [
    "## Fine-tuning XLM-RoBERTa\n",
    "\n",
    "Our first strategy will be to fine-tune our base model on the German subset of PAN-X and then evaluate its zero-shot cross-lingual performance on French, Italian and English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51d4d81c-ca7a-4cad-8942-7aa695123694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssanchez/env/transformers/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=1e-2, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae920d1-d1a3-4a8a-a846-2998960b0ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3c129287914c73883d7a21cd41991f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0053b-15dc-480e-b349-3f962130d506",
   "metadata": {},
   "source": [
    "We also need to tell the *Trainer* how to compute metrics on the validation set, se here we can use the *align_predictions()* function to extract the predictions and labels in the format needed by *seqeval* to calculate the F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9be9ad7b-a952-44c8-a314-bf64a33b75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "from pprint import pprint\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions,\n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21d885-2e3c-418b-8219-4ade45272931",
   "metadata": {},
   "source": [
    "The final step is to define a **data collator** so we can pad each input sequence to the largest sequence length in a batch.\n",
    "\n",
    "Padding the labels is necessary because, unlike in a text classification task, the labels are also sequences. One important detail here is that the label sequences are padded with the value -100, which is **ignored by Pytorch loss functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4de55ff5-47a3-4c13-868e-f31e5c8e9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d539f3cc-3953-4319-94b0-6411ac7068b1",
   "metadata": {},
   "source": [
    "We'll avoid inititlizing a new model for every *Trainer* by creating a *model_init()* method. This method loads an untrained model and is called at the beginning of the *train()* call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71dfb6bf-9fdc-46e5-ab8d-9eebde2a137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaFortokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4abc70ae-c1ca-48d6-91e6-e848dcaed473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/3874884814.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"],\n",
    "                  tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "babef276-e66b-4636-9ebd-707720b29a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msergi-sanchez-bonilla\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ssanchez/repositories/Learning/NLPTransformers/wandb/run-20250603_135104-ioy7mjo8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ioy7mjo8' target=\"_blank\">xlm-roberta-base-finetuned-panx-de</a></strong> to <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ioy7mjo8' target=\"_blank\">https://wandb.ai/sergi-sanchez-bonilla/huggingface/runs/ioy7mjo8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1575' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1575/1575 02:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.156135</td>\n",
       "      <td>0.816176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>0.141753</td>\n",
       "      <td>0.848825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.139702</td>\n",
       "      <td>0.862832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sergi24sanchez/xlm-roberta-base-finetuned-panx-de/commit/2e1db36b300f9555d227aab8b91eb51022d7b916', commit_message='Training completed!', commit_description='', oid='2e1db36b300f9555d227aab8b91eb51022d7b916', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sergi24sanchez/xlm-roberta-base-finetuned-panx-de', endpoint='https://huggingface.co', repo_type='model', repo_id='sergi24sanchez/xlm-roberta-base-finetuned-panx-de'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb05988-be77-446a-8564-ee14d0c358a5",
   "metadata": {},
   "source": [
    "Let's test it on the German translation of our simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c793e4-d989-4930-9fd2-86dc97554a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅJeff</td>\n",
       "      <td>‚ñÅD</td>\n",
       "      <td>wan</td>\n",
       "      <td>‚ñÅis</td>\n",
       "      <td>‚ñÅein</td>\n",
       "      <td>‚ñÅInformati</td>\n",
       "      <td>ker</td>\n",
       "      <td>‚ñÅbei</td>\n",
       "      <td>‚ñÅGoogle</td>\n",
       "      <td>‚ñÅin</td>\n",
       "      <td>‚ñÅKaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3    4     5           6    7     8        9   \\\n",
       "Tokens  <s>  ‚ñÅJeff     ‚ñÅD    wan  ‚ñÅis  ‚ñÅein  ‚ñÅInformati  ker  ‚ñÅbei  ‚ñÅGoogle   \n",
       "Tags      O  B-PER  I-PER  I-PER    O     O           O    O     O    B-ORG   \n",
       "\n",
       "         10          11     12    13  \n",
       "Tokens  ‚ñÅin  ‚ñÅKaliforni     en  </s>  \n",
       "Tags      O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_de = \"Jeff Dwan is ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169a1f3-e3ab-4efd-9d8f-5b5230bbdd83",
   "metadata": {},
   "source": [
    "It works! But we should never get too confident about performance based on a single example.\n",
    "We should conduct a proper and thorough investigation of the model's errors.\n",
    "\n",
    "## Error Analysis\n",
    "\n",
    "Examples where training can fail include:\n",
    "\n",
    "- We might accidentally mask too many tokens and also mask some of our labels to get a really promissing loss drop.\n",
    "- The *compute_metrics()* function might have a bug that overestimates the true performance.\n",
    "- We might include the zero class or *O* entity in NER as a normal class, which will heavily skew the accuracy and F1-score since it is the majority class by a large margin.\n",
    "\n",
    "When the model performs much worse than expected, looking at the errors can yield useful insights and reveal bugs that would be hard to spot ny just looking at the code.\n",
    "These are aspects we always need to keep in mind when we deploy a model in a production environment.\n",
    "\n",
    "We will look at the validation examples with the highest loss. We'll now calculate a loss per token in the sample sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f842d985-8d4e-473f-b141-46360b960e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size: [BS, SEQ_LEN, CLASSES]\n",
    "        num_classes = output.logits.shape[-1]\n",
    "        # predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, num_classes), # 7 because is the number of classes [\"O\", \"B-PER\", \"I-PER\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\"]\n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    return {\"loss\": loss,\n",
    "            \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8151bf95-48da-46fd-92fb-c6b440948e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5d09a6b0c24222a2e7f9fd5490cf05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe9146-04c4-4a3f-9c06-001d561436b7",
   "metadata": {},
   "source": [
    "Tokens and labels are still encoded with their IDs.\n",
    "For the padding tokens -100 we assign a special label, IGN, so we can filter them later.\n",
    "We also get rid of all the padding in the *loss* and *predicted_label* fields by truncating them to the length of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f97a0bdd-3f3b-441f-a0a7-0193a09d5846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.007227821, 0.0, 0.009881509, 0.0081332...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ‚ñÅHam, a, ‚ñÅ(, ‚ñÅUnternehmen, ‚ñÅ), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 56530, 25216, 30121, 152385, 19229, 83982,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...</td>\n",
       "      <td>[0.0, 0.0052162027, 0.0, 0.0, 0.0, 0.0, 1.3796...</td>\n",
       "      <td>[O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC,...</td>\n",
       "      <td>[&lt;s&gt;, ‚ñÅWE, ITE, RL, EIT, UNG, ‚ñÅLuz, ky, j, ‚ñÅa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 159093, 165, 38506, 122, 153080, 29088, 57...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...</td>\n",
       "      <td>[0.0, 0.0001296913, 8.093983e-05, 0.0001144343...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, O, I-ORG, O, O, O, O, O...</td>\n",
       "      <td>[&lt;s&gt;, ‚ñÅentdeckt, ‚ñÅund, ‚ñÅgeh√∂rt, ‚ñÅder, ‚ñÅSpek, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, O, O, B-LOC, IGN, O, O, IGN]</td>\n",
       "      <td>[0.0, 0.00015603278, 0.00012444676, 0.00014292...</td>\n",
       "      <td>[B-LOC, O, O, O, B-LOC, I-LOC, O, O, B-LOC]</td>\n",
       "      <td>[&lt;s&gt;, ‚ñÅ**, ‚ñÅ', ‚ñÅ'', ‚ñÅ, Bretagne, ‚ñÅ'', ‚ñÅ', &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, O, O, O, O, O, O, IGN, O, O, O, B-ORG...</td>\n",
       "      <td>[0.0, 8.7972585e-05, 9.083335e-05, 9.6078074e-...</td>\n",
       "      <td>[B-ORG, O, O, O, O, O, O, O, O, O, O, O, B-ORG...</td>\n",
       "      <td>[&lt;s&gt;, ‚ñÅNach, ‚ñÅeinem, ‚ñÅJahr, ‚ñÅbei, ‚ñÅdiesem, ‚ñÅVe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0                 [0, 10699, 11, 15, 16104, 1388, 2]   \n",
       "1  [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n",
       "2  [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n",
       "3     [0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]   \n",
       "4  [0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0                              [1, 1, 1, 1, 1, 1, 1]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                              labels  \\\n",
       "0        [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "1  [IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...   \n",
       "2  [IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...   \n",
       "3              [IGN, O, O, O, B-LOC, IGN, O, O, IGN]   \n",
       "4  [IGN, O, O, O, O, O, O, O, IGN, O, O, O, B-ORG...   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.007227821, 0.0, 0.009881509, 0.0081332...   \n",
       "1  [0.0, 0.0052162027, 0.0, 0.0, 0.0, 0.0, 1.3796...   \n",
       "2  [0.0, 0.0001296913, 8.093983e-05, 0.0001144343...   \n",
       "3  [0.0, 0.00015603278, 0.00012444676, 0.00014292...   \n",
       "4  [0.0, 8.7972585e-05, 9.083335e-05, 9.6078074e-...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "1  [O, O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-LOC,...   \n",
       "2  [O, O, O, O, O, B-ORG, O, I-ORG, O, O, O, O, O...   \n",
       "3        [B-LOC, O, O, O, B-LOC, I-LOC, O, O, B-LOC]   \n",
       "4  [B-ORG, O, O, O, O, O, O, O, O, O, O, O, B-ORG...   \n",
       "\n",
       "                                        input_tokens  \n",
       "0         [<s>, ‚ñÅHam, a, ‚ñÅ(, ‚ñÅUnternehmen, ‚ñÅ), </s>]  \n",
       "1  [<s>, ‚ñÅWE, ITE, RL, EIT, UNG, ‚ñÅLuz, ky, j, ‚ñÅa,...  \n",
       "2  [<s>, ‚ñÅentdeckt, ‚ñÅund, ‚ñÅgeh√∂rt, ‚ñÅder, ‚ñÅSpek, t...  \n",
       "3    [<s>, ‚ñÅ**, ‚ñÅ', ‚ñÅ'', ‚ñÅ, Bretagne, ‚ñÅ'', ‚ñÅ', </s>]  \n",
       "4  [<s>, ‚ñÅNach, ‚ñÅeinem, ‚ñÅJahr, ‚ñÅbei, ‚ñÅdiesem, ‚ñÅVe...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "# truncate to the length of the inputs\n",
    "df[\"loss\"] = df.apply(\n",
    "    lambda x: x[\"loss\"][:len(x['input_ids'])], axis=1)\n",
    "df[\"predicted_label\"] = df.apply(\n",
    "    lambda x: x[\"predicted_label\"][:len(x['input_ids'])], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a682eea-2427-4c69-815a-1e393235cef1",
   "metadata": {},
   "source": [
    "Let's have a look at the tokens individually by unpacking these lists. The *pandas.Series.explode()* function allows us to do exactly that in one line by creating a row for each element in the original rows list.\n",
    "We also drop the padding tokens we named IGN, since their loss is zero anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "707db56d-25b2-45ee-a940-62451b289fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>‚ñÅHam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>‚ñÅUnternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.01</td>\n",
       "      <td>O</td>\n",
       "      <td>‚ñÅWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1.38</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>‚ñÅLuz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1.38</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>‚ñÅa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.01           B-ORG          ‚ñÅHam\n",
       "0        15              1  I-ORG  0.01           I-ORG            ‚ñÅ(\n",
       "0     16104              1  I-ORG  0.01           I-ORG  ‚ñÅUnternehmen\n",
       "0      1388              1  I-ORG  0.01           I-ORG            ‚ñÅ)\n",
       "1     56530              1      O  0.01               O           ‚ñÅWE\n",
       "1     83982              1  B-ORG  1.38           B-LOC          ‚ñÅLuz\n",
       "1        10              1  I-ORG  1.38           I-LOC            ‚ñÅa"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f994ef-91a9-4c02-9d62-defa153e8855",
   "metadata": {},
   "source": [
    "With the data in this shape, we can now group it by the input tokens and aggregate the losses for each token with the count, mean, and sum. Finally, we sort the aggregated data by the sum of the losses and see which tokens have accumulated the most loss in the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37399b2b-1450-405d-a6b5-ed5e34b1831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>‚ñÅder</td>\n",
       "      <td>‚ñÅin</td>\n",
       "      <td>‚ñÅvon</td>\n",
       "      <td>‚ñÅ/</td>\n",
       "      <td>‚ñÅund</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>‚ñÅA</td>\n",
       "      <td>‚ñÅdie</td>\n",
       "      <td>‚ñÅdes</td>\n",
       "      <td>‚ñÅWest</td>\n",
       "      <td>‚ñÅD</td>\n",
       "      <td>‚ñÅOber</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅI</td>\n",
       "      <td>‚ñÅde</td>\n",
       "      <td>‚ñÅFrauen</td>\n",
       "      <td>‚ñÅT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>1388</td>\n",
       "      <td>989</td>\n",
       "      <td>808</td>\n",
       "      <td>163</td>\n",
       "      <td>1171</td>\n",
       "      <td>2898</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>125</td>\n",
       "      <td>860</td>\n",
       "      <td>366</td>\n",
       "      <td>48</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>2133</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>222.05</td>\n",
       "      <td>133.15</td>\n",
       "      <td>127.78</td>\n",
       "      <td>122.97</td>\n",
       "      <td>112.25</td>\n",
       "      <td>97.15</td>\n",
       "      <td>77.97</td>\n",
       "      <td>76.29</td>\n",
       "      <td>71.62</td>\n",
       "      <td>62.17</td>\n",
       "      <td>53.49</td>\n",
       "      <td>47.41</td>\n",
       "      <td>45.44</td>\n",
       "      <td>42.36</td>\n",
       "      <td>38.11</td>\n",
       "      <td>36.48</td>\n",
       "      <td>35.84</td>\n",
       "      <td>33.66</td>\n",
       "      <td>32.74</td>\n",
       "      <td>31.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4      5      6      7   \\\n",
       "input_tokens       ‚ñÅ    ‚ñÅder     ‚ñÅin    ‚ñÅvon      ‚ñÅ/   ‚ñÅund    ‚ñÅ''     ‚ñÅ(   \n",
       "count           6066    1388     989     808     163   1171   2898    246   \n",
       "mean            0.04     0.1    0.13    0.15    0.69   0.08   0.03   0.31   \n",
       "sum           222.05  133.15  127.78  122.97  112.25  97.15  77.97  76.29   \n",
       "\n",
       "                 8      9      10     11     12     13     14     15     16  \\\n",
       "input_tokens     ‚ñÅ)     ‚ñÅA   ‚ñÅdie   ‚ñÅdes  ‚ñÅWest     ‚ñÅD  ‚ñÅOber     ‚ñÅ'     ‚ñÅI   \n",
       "count           246    125    860    366     48     89     27   2133     94   \n",
       "mean           0.29    0.5   0.06   0.13   0.95   0.48   1.41   0.02   0.38   \n",
       "sum           71.62  62.17  53.49  47.41  45.44  42.36  38.11  36.48  35.84   \n",
       "\n",
       "                 17       18     19  \n",
       "input_tokens    ‚ñÅde  ‚ñÅFrauen     ‚ñÅT  \n",
       "count           139       15     37  \n",
       "mean           0.24     2.18   0.85  \n",
       "sum           33.66    32.74  31.36  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1) # get rid of the multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(20)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e764b2-f0cd-4e12-90f6-5738d45b767a",
   "metadata": {},
   "source": [
    "We can observe several patterns in this list:\n",
    "\n",
    "- The whitespace token has the highest total loss, which is not surprising since it is also the most common token in the list.\n",
    "- Words like \"in\", \"von\", \"der\" and \"und\" appear relatively frequently. They often appear together with named entities and are sometimes part of them, which explains why the model might mix them up.\n",
    "- Parentheses, slashes, and capital letters at the beginning of words are rarer but have a relatively high average loss. We will investigate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f835eb89-24c5-4d08-8f93-1edc1e6c7947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3820</td>\n",
       "      <td>2683</td>\n",
       "      <td>43648</td>\n",
       "      <td>3172</td>\n",
       "      <td>1462</td>\n",
       "      <td>4139</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1941.2</td>\n",
       "      <td>1689.14</td>\n",
       "      <td>1372.92</td>\n",
       "      <td>1054.5</td>\n",
       "      <td>911.25</td>\n",
       "      <td>840.11</td>\n",
       "      <td>782.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2       3       4       5       6\n",
       "labels   I-ORG    B-ORG        O   B-LOC   I-LOC   I-PER   B-PER\n",
       "count     3820     2683    43648    3172    1462    4139    2893\n",
       "mean      0.51     0.63     0.03    0.33    0.62     0.2    0.27\n",
       "sum     1941.2  1689.14  1372.92  1054.5  911.25  840.11  782.29"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1) # get rid of the multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20095004-3761-452b-911a-c205384c255b",
   "metadata": {},
   "source": [
    "*B-ORG* has the highest average loss, which means that detemining the beginning of an organization poses a challenge to our model.\n",
    "\n",
    "Confusion matrix of the token classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "458564f3-4279-4335-9aef-2175d4ec25a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_preds, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      tags.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab425841-d015-4023-b059-ec81d8e50c29",
   "metadata": {},
   "source": [
    "Let's look at sequences with high losses.\n",
    "\n",
    "Calculate the total loss by summing over the loss per token. Let's write a function that helps us display the token sequences with the labels and the losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c328c3c-d552-4a83-b2fc-49b9fbe67203",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels,\n",
    "                              \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbd75e59-6973-4cc2-ad9c-8d66e02dee87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅŒ§</td>\n",
       "      <td>Œö</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅT</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>ri</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>k</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.40</td>\n",
       "      <td>9.78</td>\n",
       "      <td>6.70</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.28</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2      3     4     5      6      7      8      9   \\\n",
       "tokens    ‚ñÅ'   ‚ñÅ''     ‚ñÅŒ§      Œö   ‚ñÅ''    ‚ñÅ'     ‚ñÅ'    ‚ñÅ''     ‚ñÅT    ‚ñÅ''   \n",
       "labels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG  B-ORG     O     O      O      O      O      O   \n",
       "losses  0.00  0.00   2.40   0.00  0.00  0.00  11.40   9.78   6.70   7.93   \n",
       "\n",
       "           10    11     12     13    14     15     16    17    18  \n",
       "tokens     ‚ñÅ'    ri    ‚ñÅ''     ‚ñÅ'     k    ‚ñÅ''     ‚ñÅ'   ala  </s>  \n",
       "labels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \n",
       "preds       O     O      O      O     O      O      O     O     O  \n",
       "losses   7.62  0.00   8.51   8.60  0.00   9.28   8.84  0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>‚ñÅJuli</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ:</td>\n",
       "      <td>‚ñÅProtest</td>\n",
       "      <td>camp</td>\n",
       "      <td>‚ñÅauf</td>\n",
       "      <td>‚ñÅdem</td>\n",
       "      <td>‚ñÅGel√§nde</td>\n",
       "      <td>‚ñÅder</td>\n",
       "      <td>‚ñÅRepublika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>‚ñÅGar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>9.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.21</td>\n",
       "      <td>9.92</td>\n",
       "      <td>10.01</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>8.43</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2      3      4      5         6     7      8      9   \\\n",
       "tokens    ‚ñÅ''     8     .  ‚ñÅJuli    ‚ñÅ''     ‚ñÅ:  ‚ñÅProtest  camp   ‚ñÅauf   ‚ñÅdem   \n",
       "labels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \n",
       "preds       O     O     O      O      O      O         O     O      O      O   \n",
       "losses   9.47  0.00  0.00   9.21   9.92  10.01      7.29  0.00   6.55   8.43   \n",
       "\n",
       "              10     11          12     13      14     15     16    17  \n",
       "tokens  ‚ñÅGel√§nde   ‚ñÅder  ‚ñÅRepublika      n  ischen   ‚ñÅGar     de  </s>  \n",
       "labels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \n",
       "preds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \n",
       "losses      7.32   5.94        5.10   0.00    0.00   0.01   0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅUnited</td>\n",
       "      <td>‚ñÅNations</td>\n",
       "      <td>‚ñÅMulti</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>‚ñÅIntegra</td>\n",
       "      <td>ted</td>\n",
       "      <td>‚ñÅStabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>‚ñÅMission</td>\n",
       "      <td>‚ñÅin</td>\n",
       "      <td>‚ñÅthe</td>\n",
       "      <td>‚ñÅCentral</td>\n",
       "      <td>‚ñÅAfrican</td>\n",
       "      <td>‚ñÅRepublic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>6.78</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.20</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.79</td>\n",
       "      <td>5.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6   \\\n",
       "tokens  ‚ñÅUnited  ‚ñÅNations  ‚ñÅMulti  dimensional  ‚ñÅIntegra    ted  ‚ñÅStabil   \n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     6.78      6.61    6.35         0.00      6.40   0.00     6.41   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ‚ñÅMission    ‚ñÅin   ‚ñÅthe  ‚ñÅCentral  ‚ñÅAfrican  ‚ñÅRepublic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses     0.00      6.20   5.83   5.79      5.85      6.29       5.95   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad3b71-ff31-4dcc-a24c-d5334cdc9d82",
   "metadata": {},
   "source": [
    "Another thing we can notice is that parentheses and slashes have a relatively high loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "271b180d-9bbc-4a01-8c61-dbdb1cacdbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅHam</td>\n",
       "      <td>a</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅUnternehmen</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2             3      4      5\n",
       "tokens   ‚ñÅHam      a     ‚ñÅ(  ‚ñÅUnternehmen     ‚ñÅ)   </s>\n",
       "labels  B-ORG    IGN  I-ORG         I-ORG  I-ORG    IGN\n",
       "preds   B-ORG  I-ORG  I-ORG         I-ORG  I-ORG  I-ORG\n",
       "losses   0.01   0.00   0.01          0.01   0.01   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅKesk</td>\n",
       "      <td>k√ºl</td>\n",
       "      <td>a</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅMart</td>\n",
       "      <td>na</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7\n",
       "tokens  ‚ñÅKesk    k√ºl      a     ‚ñÅ(  ‚ñÅMart     na     ‚ñÅ)   </s>\n",
       "labels  B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC    IGN\n",
       "preds   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "losses   0.02   0.00   0.00   0.02   0.02   0.00   0.02   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅPik</td>\n",
       "      <td>e</td>\n",
       "      <td>‚ñÅTown</td>\n",
       "      <td>ship</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅBrown</td>\n",
       "      <td>‚ñÅCounty</td>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>,</td>\n",
       "      <td>‚ñÅOhio</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4       5        6      7      8   \\\n",
       "tokens   ‚ñÅPik      e  ‚ñÅTown   ship     ‚ñÅ(  ‚ñÅBrown  ‚ñÅCounty      ‚ñÅ      ,   \n",
       "labels  B-LOC    IGN  I-LOC    IGN  I-LOC   I-LOC    I-LOC  I-LOC    IGN   \n",
       "preds   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC   I-LOC    I-LOC  I-LOC  I-LOC   \n",
       "losses   0.02   0.00   0.01   0.00   0.01    0.01     0.01   0.01   0.00   \n",
       "\n",
       "           9      10     11  \n",
       "tokens  ‚ñÅOhio     ‚ñÅ)   </s>  \n",
       "labels  I-LOC  I-LOC    IGN  \n",
       "preds   I-LOC  I-LOC  I-LOC  \n",
       "losses   0.01   0.01   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅBad</td>\n",
       "      <td>‚ñÅGrund</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅHar</td>\n",
       "      <td>z</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1      2      3      4      5      6\n",
       "tokens   ‚ñÅBad  ‚ñÅGrund     ‚ñÅ(   ‚ñÅHar      z     ‚ñÅ)   </s>\n",
       "labels  B-LOC   I-LOC  I-LOC  I-LOC    IGN  I-LOC    IGN\n",
       "preds   B-LOC   I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "losses   0.03    0.02   0.02   0.02   0.00   0.02   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅAl</td>\n",
       "      <td>fon</td>\n",
       "      <td>s</td>\n",
       "      <td>‚ñÅVI</td>\n",
       "      <td>.</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅLe√≥n</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8\n",
       "tokens    ‚ñÅAl    fon      s    ‚ñÅVI      .     ‚ñÅ(  ‚ñÅLe√≥n     ‚ñÅ)   </s>\n",
       "labels  B-PER    IGN    IGN  I-PER    IGN  I-PER  I-PER  I-PER    IGN\n",
       "preds   B-PER  I-PER  I-PER  I-PER  I-PER  I-PER  I-PER  I-PER  I-PER\n",
       "losses   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(5)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b5770-0fef-46b1-ae3e-e7dd833fbe9a",
   "metadata": {},
   "source": [
    "We've identified some weaknesses in both our model and the dataset. In a real use case we would iterate on this step, cleaning up the dataset, retraining the model, and analyzing the new errors until we were satisfied with the performance.\n",
    "\n",
    "We'll perform some experiments to see how well the cross-lingual transfer in XLM-R works.\n",
    "\n",
    "# Cross-Lingual Transfer\n",
    "\n",
    "Now that we have fine-tuned XLM-R on German, we can evaluate its ability to transfer to other languages via the *predict()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47248ffb-8f45-42dc-961e-5e6c06502a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fcc7481-81ad-4d75-a654-e73aab5c635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [de] dataset: 0.863\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16e9cb12-11d7-4a20-be1c-24b3f5c32be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅJeff</td>\n",
       "      <td>‚ñÅDe</td>\n",
       "      <td>an</td>\n",
       "      <td>‚ñÅest</td>\n",
       "      <td>‚ñÅinformatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>‚ñÅchez</td>\n",
       "      <td>‚ñÅGoogle</td>\n",
       "      <td>‚ñÅen</td>\n",
       "      <td>‚ñÅCali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4            5    6      7        8    9   \\\n",
       "Tokens  <s>  ‚ñÅJeff    ‚ñÅDe     an  ‚ñÅest  ‚ñÅinformatic  ien  ‚ñÅchez  ‚ñÅGoogle  ‚ñÅen   \n",
       "Tags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n",
       "\n",
       "           10     11     12    13  \n",
       "Tokens  ‚ñÅCali    for    nie  </s>  \n",
       "Tags    B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fine-tuned on German on French:\n",
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "262f6e65-be57-4b62-8691-3b9227e1ec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4d3b45a1a74324b4687d1af99a901c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.698\n"
     ]
    }
   ],
   "source": [
    "# German model on whole French test set\n",
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])\n",
    "\n",
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae54e580-ce73-4486-bc29-3edd01247c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.670\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "599a1277-377a-44b3-b34e-c580721afd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [en] dataset: 0.584\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e50774-689b-4aaa-b592-4e75a41a7b15",
   "metadata": {},
   "source": [
    "# When Does Zero-Shot Transfer Make Sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e320d695-45b5-4a3d-a9b6-38246ef240a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                     data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                     train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    trainer.train()\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40adacf0-fe94-402e-98f7-4567b129b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode French corpus into IDs\n",
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d650fb79-f2cc-45bf-8551-42a7b98fcb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.626900</td>\n",
       "      <td>1.301510</td>\n",
       "      <td>0.015905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>0.200309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.926600</td>\n",
       "      <td>0.889560</td>\n",
       "      <td>0.349954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.359977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  f1_score\n",
       "0          250  0.359977"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b631c83-b17b-408d-ac92-43de9f2f2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.436900</td>\n",
       "      <td>0.929560</td>\n",
       "      <td>0.350160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.602746</td>\n",
       "      <td>0.608884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.528100</td>\n",
       "      <td>0.517416</td>\n",
       "      <td>0.666772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 00:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.093500</td>\n",
       "      <td>0.560990</td>\n",
       "      <td>0.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.420323</td>\n",
       "      <td>0.737734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.372421</td>\n",
       "      <td>0.779006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.431334</td>\n",
       "      <td>0.707871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.373198</td>\n",
       "      <td>0.762550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.343487</td>\n",
       "      <td>0.801942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/501 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.344700</td>\n",
       "      <td>0.802541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.818441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.288018</td>\n",
       "      <td>0.832635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_df = pd.concat(\n",
    "    [\n",
    "        metrics_df,\n",
    "        *[train_on_subset(panx_fr_encoded, num_samples) for num_samples in [500, 1000, 2000, 4000]]\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b2e13cb-2b61-48e6-840a-59dec5a072a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axhline(f1_scores[\"de\"][\"fr\"], ls=\"--\", color=\"r\")\n",
    "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
    "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
    "plt.ylim((0,1))\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f19ce0-b8f2-400f-8743-c6f9ebff9d71",
   "metadata": {},
   "source": [
    "From the plot we can see that zero-shot transfer remains competitive until about 750 training examples. Nevertheless, this result is not to be sniffed at! Getting domain experts to label even hundreds of documents can be costly, especially for NER, where the labelling process is fine-grained and time-consuming.\n",
    "\n",
    "There is one final technique we can try to evaulate multilingual learining; **fine-tuning on multiple languages at once!**\n",
    "\n",
    "## Fine-Tuning on Muliple Languages at Once\n",
    "\n",
    "One way of mitigating the drop in performance is by fine-tuning on multiple languages at the same time. *concatenate_datasets()* function to concatenate the German and French corpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a8618ea-fbb8-40a7-a1d0-b5912a53360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    multi_corpus = DatasetDict()\n",
    "    for split in corpora[0].keys():\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "            [corpus[split] for corpus in corpora]\n",
    "        ).shuffle(seed=42)\n",
    "    return multi_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "559f33c5-ab97-4fc0-b6b6-640e62141624",
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c5bfaf6-d8c5-43b8-bb01-0ce8e737a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/3938588869.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2145/2145 03:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.176874</td>\n",
       "      <td>0.825428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.164877</td>\n",
       "      <td>0.847113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.162401</td>\n",
       "      <td>0.859845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sergi24sanchez/xlm-roberta-base-finetuned-panx-de-fr/commit/b7e96476e1e07460ae3ee8b3e794971ae8cd8323', commit_message='Training completed!', commit_description='', oid='b7e96476e1e07460ae3ee8b3e794971ae8cd8323', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sergi24sanchez/xlm-roberta-base-finetuned-panx-de-fr', endpoint='https://huggingface.co', repo_type='model', repo_id='sergi24sanchez/xlm-roberta-base-finetuned-panx-de-fr'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_fr_encoded[\"validation\"]\n",
    "                 )\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fea05d56-e969-4312-9c7c-7650f43a4c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.869\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [fr] dataset: 0.862\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [it] dataset: 0.792\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [en] dataset: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at how the model perfroms on the test set of each language\n",
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b52272-92d0-4e84-be2c-4c80d301725b",
   "metadata": {},
   "source": [
    "Comparing the performance of fine-tuning on each language separately against multilingual learning on all the corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1881964-bebe-4aed-b008-6c4a52307ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [573/573 00:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.335840</td>\n",
       "      <td>0.781302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.277782</td>\n",
       "      <td>0.815062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.279908</td>\n",
       "      <td>0.841981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>0.323580</td>\n",
       "      <td>0.740566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.258414</td>\n",
       "      <td>0.789686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.266015</td>\n",
       "      <td>0.816878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/284266965.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>0.510650</td>\n",
       "      <td>0.579459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.416828</td>\n",
       "      <td>0.649394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.385773</td>\n",
       "      <td>0.685144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpora = [panx_de_encoded]\n",
    "\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3fe9d1-88ff-4b65-ba9a-b9a969c09cc3",
   "metadata": {},
   "source": [
    "Now that we've fine-tuned on each language's corpus, the next step is to concatenate all the splits together to create a multilingual corpus of all four languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52b70c46-1d7f-410d-832b-29adc602eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3dbfe5c-af3b-4daf-8459-9d2c03fb0e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821402/2911492552.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model_init=model_init, args=training_args,\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2505' max='2505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2505/2505 03:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.200548</td>\n",
       "      <td>0.807489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.170836</td>\n",
       "      <td>0.840577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.176252</td>\n",
       "      <td>0.855366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sergi24sanchez/xlm-roberta-base-finetuned-panx-all/commit/c9887112915afc82b14cd6a01d1f8eafbea3939e', commit_message='Training completed!', commit_description='', oid='c9887112915afc82b14cd6a01d1f8eafbea3939e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sergi24sanchez/xlm-roberta-base-finetuned-panx-all', endpoint='https://huggingface.co', repo_type='model', repo_id='sergi24sanchez/xlm-roberta-base-finetuned-panx-all'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                 data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                 tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "                 eval_dataset=corpora_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1aed6f2f-c016-4373-8f77-ee95b0d0f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the predictions from the trainer on eac language's test set\n",
    "for idx, lang in enumerate(langs):\n",
    "    f1_scores[\"all\"][lang] = get_f1_score(trainer, corpora[idx][\"test\"])\n",
    "\n",
    "scores_data = {\"de\": f1_scores[\"de\"],\n",
    "               \"each\": {lang: f1_scores[lang][lang] for lang in langs},\n",
    "              \"all\": f1_scores[\"all\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "928b416d-79a2-44c1-bed2-610cb7e97390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluated on</th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine-tune on</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.6703</td>\n",
       "      <td>0.5840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>0.7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluated on      de      fr      it      en\n",
       "Fine-tune on                                \n",
       "de            0.8635  0.6980  0.6703  0.5840\n",
       "each          0.8635  0.8448  0.8150  0.6845\n",
       "all           0.8644  0.8672  0.8713  0.7503"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
    "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",\n",
    "                        inplace=True)\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b751029-e39d-44c9-b445-ded5203f24ac",
   "metadata": {},
   "source": [
    "- Multilingual learning can provide significant gains in performance, especially if the low-resource languages for cross-lingual transfer belong to similar language families.\n",
    "- As a general strategy, focus the attention on cross-lingual transfer *within* language families."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3536261-20ab-44cd-894e-cc2f46ab823f",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b5d07-c8f6-4101-b377-d646dd2505d8",
   "metadata": {},
   "source": [
    "- NLP task on a multilingual corpus using a single transformer pretrained on 100 languages: XLM-R\n",
    "- Cross-lingual transfer from German to French is competitive when only a small number of labeled examples ara available for fine-tuning. This good performance generally does not occur if the target language is significantly different from the one the base model was fine-tuned.\n",
    "- So far we have looked at two tasks: sequence classification and token classification. Both fall into the domain of Natural Language Understanding, where text is synthetized into predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
